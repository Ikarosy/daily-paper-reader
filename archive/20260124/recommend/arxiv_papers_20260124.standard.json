{
  "mode": "standard",
  "generated_at": "2026-01-24T15:30:26.279961+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 3,
    "deep_cap": 8,
    "deep_selected": 3,
    "quick_candidates": 9,
    "quick_skim_target": 13,
    "quick_selected": 9
  },
  "deep_dive": [
    {
      "id": "2601.15717v1",
      "title": "Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling",
      "abstract": "Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.",
      "authors": [
        "Luyao Zhu",
        "Fangfang Zhang",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 07:38:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15717v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 9.0,
      "llm_evidence_en": "Genetic Programming for automatic evolution of scheduling heuristics",
      "llm_evidence_cn": "遗传编程用于自动演化调度启发式算法",
      "llm_evidence": "遗传编程用于自动演化调度启发式算法",
      "llm_tldr_en": "Investigates the generalization of GP-evolved scheduling rules in dynamic flexible job shop environments.",
      "llm_tldr_cn": "研究遗传编程演化的调度规则在动态柔性作业车间环境中的泛化能力。",
      "llm_tldr": "研究遗传编程演化的调度规则在动态柔性作业车间环境中的泛化能力。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15738v1",
      "title": "LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling",
      "abstract": "Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.",
      "authors": [
        "Junhao Qiu",
        "Haoyang Zhuang",
        "Fei Liu",
        "Jianjun Liu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-22 08:06:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15738v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 9.0,
      "llm_evidence_en": "LLM-assisted automatic heuristic design for scheduling",
      "llm_evidence_cn": "大模型辅助的调度启发式算法自动设计",
      "llm_evidence": "大模型辅助的调度启发式算法自动设计",
      "llm_tldr_en": "Uses LLMs to automatically design dispatching rules for dynamic flexible assembly flow shop scheduling.",
      "llm_tldr_cn": "利用大语言模型自动设计动态柔性装配流水线调度的派工规则。",
      "llm_tldr": "利用大语言模型自动设计动态柔性装配流水线调度的派工规则。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16175v1",
      "title": "Learning to Discover at Test Time",
      "abstract": "How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.",
      "authors": [
        "Mert Yuksekgonul",
        "Daniel Koceja",
        "Xinhao Li",
        "Federico Bianchi",
        "Jed McCaleb",
        "Xiaolong Wang",
        "Jan Kautz",
        "Yejin Choi",
        "James Zou",
        "Carlos Guestrin",
        "Yu Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 18:24:00+00:00",
      "link": "https://arxiv.org/pdf/2601.16175v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Automated discovery of state-of-the-art solutions via test-time search and reinforcement learning",
      "llm_evidence_cn": "通过测试时搜索和强化学习自动发现最先进的解决方案",
      "llm_evidence": "通过测试时搜索和强化学习自动发现最先进的解决方案",
      "llm_tldr_en": "Proposes TTT-Discover to find optimal scientific solutions using test-time reinforcement learning and search.",
      "llm_tldr_cn": "提出 TTT-Discover，利用测试时强化学习和搜索来发现科学问题的最优解。",
      "llm_tldr": "提出 TTT-Discover，利用测试时强化学习和搜索来发现科学问题的最优解。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.15127v1",
      "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",
      "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS",
      "authors": [
        "Bostan Khan",
        "Masoud Daneshtalab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.DC"
      ],
      "published": "2026-01-21 16:03:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15127v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "architectural heuristics and automated model design",
      "llm_evidence_cn": "架构启发式与自动模型设计",
      "llm_evidence": "架构启发式与自动模型设计",
      "llm_tldr_en": "DeepFedNAS automates model design using architectural heuristics and multi-objective fitness functions.",
      "llm_tldr_cn": "DeepFedNAS利用架构启发式和多目标适应度函数实现自动模型设计。",
      "llm_tldr": "DeepFedNAS利用架构启发式和多目标适应度函数实现自动模型设计。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15131v1",
      "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding",
      "abstract": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.",
      "authors": [
        "Ayan Maity",
        "Sudeshna Sarkar"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-21 16:05:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15131v1",
      "tags": [
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "vehicle routing optimization with RL",
      "llm_evidence_cn": "利用强化学习进行车辆路径优化",
      "llm_evidence": "利用强化学习进行车辆路径优化",
      "llm_tldr_en": "Uses DRL and network embedding to solve vehicle routing problems, relevant to heuristic search optimization.",
      "llm_tldr_cn": "利用深度强化学习和网络嵌入解决车辆路径问题，与启发式搜索优化相关。",
      "llm_tldr": "利用深度强化学习和网络嵌入解决车辆路径问题，与启发式搜索优化相关。",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.15212v1",
      "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization",
      "abstract": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.",
      "authors": [
        "Dhrubo Saha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-21 17:36:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15212v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Automated optimization using temporal evolution of training history",
      "llm_evidence_cn": "利用训练历史的时间演化进行自动优化",
      "llm_evidence": "利用训练历史的时间演化进行自动优化",
      "llm_tldr_en": "Introduces ZENITH, an optimizer that automatically adapts learning rates using gradient norm evolution.",
      "llm_tldr_cn": "引入 ZENITH 优化器，利用梯度范数演化自动调整学习率。",
      "llm_tldr": "引入 ZENITH 优化器，利用梯度范数演化自动调整学习率。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15482v1",
      "title": "Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding",
      "abstract": "Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.",
      "authors": [
        "Huayu Li",
        "ZhengXiao He",
        "Siyuan Tian",
        "Jinghao Wen",
        "Ao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 21:34:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15482v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Principled search space pruning and path valuation for LLM decoding",
      "llm_evidence_cn": "LLM 解码中原则性的搜索空间剪枝和路径评估",
      "llm_evidence": "LLM 解码中原则性的搜索空间剪枝和路径评估",
      "llm_tldr_en": "Proposes Martingale Foresight Sampling for theoretically-grounded, optimal search in LLM decoding.",
      "llm_tldr_cn": "提出鞅前瞻采样，为 LLM 解码提供有理论依据的最优搜索。",
      "llm_tldr": "提出鞅前瞻采样，为 LLM 解码提供有理论依据的最优搜索。",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.15561v1",
      "title": "Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems",
      "abstract": "This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.",
      "authors": [
        "Naoya Onizawa",
        "Takahiro Hanyu"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.LG"
      ],
      "published": "2026-01-22 01:01:35+00:00",
      "link": "https://arxiv.org/pdf/2601.15561v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "simulated annealing for combinatorial optimization",
      "llm_evidence_cn": "组合优化的模拟退火算法",
      "llm_evidence": "组合优化的模拟退火算法",
      "llm_tldr_en": "Analyzes and improves simulated annealing for large-scale combinatorial optimization by reducing oscillations.",
      "llm_tldr_cn": "通过减少振荡，分析并改进了用于大规模组合优化的模拟退火算法。",
      "llm_tldr": "通过减少振荡，分析并改进了用于大规模组合优化的模拟退火算法。",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EOH"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15640v1",
      "title": "An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types",
      "abstract": "Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.",
      "authors": [
        "Natasha Trinkle",
        "Huong Ha",
        "Jeffrey Chan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-22 04:41:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15640v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Efficient automatic algorithm selection and transfer learning for optimization",
      "llm_evidence_cn": "高效自动算法选择与优化迁移学习",
      "llm_evidence": "高效自动算法选择与优化迁移学习",
      "llm_tldr_en": "Analyzes ensemble-based transfer learning for Bayesian optimization to improve sample efficiency.",
      "llm_tldr_cn": "分析贝叶斯优化的集成迁移学习方法，以提高样本效率。",
      "llm_tldr": "分析贝叶斯优化的集成迁移学习方法，以提高样本效率。",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.15808v1",
      "title": "Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification",
      "abstract": "Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.",
      "authors": [
        "Yuxuan Wan",
        "Tianqing Fang",
        "Zaitang Li",
        "Yintong Huo",
        "Wenxuan Wang",
        "Haitao Mi",
        "Dong Yu",
        "Michael R. Lyu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 09:47:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15808v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Self-evolving agents via iterative feedback and refinement",
      "llm_evidence_cn": "通过迭代反馈和细化实现自我进化的智能体",
      "llm_evidence": "通过迭代反馈和细化实现自我进化的智能体",
      "llm_tldr_en": "A self-evolving agent framework that improves through iterative verification and rubric-guided feedback.",
      "llm_tldr_cn": "一种通过迭代验证和准则引导反馈实现自我进化的智能体框架。",
      "llm_tldr": "一种通过迭代验证和准则引导反馈实现自我进化的智能体框架。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15876v1",
      "title": "EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience",
      "abstract": "The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.",
      "authors": [
        "Taofeng Xue",
        "Chong Peng",
        "Mianqiu Huang",
        "Linsen Guo",
        "Tiancheng Han",
        "Haozhe Wang",
        "Jianing Wang",
        "Xiaocheng Zhang",
        "Xin Yang",
        "Dengchang Zhao",
        "Jinrui Ding",
        "Xiandi Ma",
        "Yuchen Xie",
        "Peng Pei",
        "Xunliang Cai",
        "Xipeng Qiu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 11:36:43+00:00",
      "link": "https://arxiv.org/pdf/2601.15876v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "evolutionary cycle for policy optimization",
      "llm_evidence_cn": "策略优化的进化循环",
      "llm_evidence": "策略优化的进化循环",
      "llm_tldr_en": "Introduces EvoCUA, which integrates data generation and policy optimization into a self-sustaining evolutionary cycle.",
      "llm_tldr_cn": "引入EvoCUA，将数据生成和策略优化整合进一个自持的进化循环中。",
      "llm_tldr": "引入EvoCUA，将数据生成和策略优化整合进一个自持的进化循环中。",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.16056v1",
      "title": "Designing faster mixed integer linear programming algorithm via learning the optimal path",
      "abstract": "Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.",
      "authors": [
        "Ruizhi Liu",
        "Liming Xu",
        "Xulin Huang",
        "Jingyan Sui",
        "Shizhe Ding",
        "Boyang Xia",
        "Chungong Yu",
        "Dongbo Bu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 15:41:22+00:00",
      "link": "https://arxiv.org/pdf/2601.16056v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "learning heuristics for MILP optimization",
      "llm_evidence_cn": "学习MILP优化的启发式策略",
      "llm_evidence": "学习MILP优化的启发式策略",
      "llm_tldr_en": "Introduces DeepBound, a deep learning approach to replace hand-crafted heuristics in MILP branch-and-bound solvers.",
      "llm_tldr_cn": "引入DeepBound，一种深度学习方法，用于替代MILP分支定界求解器中的手工启发式策略。",
      "llm_tldr": "引入DeepBound，一种深度学习方法，用于替代MILP分支定界求解器中的手工启发式策略。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    }
  ]
}