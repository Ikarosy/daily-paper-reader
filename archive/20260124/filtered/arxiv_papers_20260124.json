{
  "top_k": 200,
  "generated_at": "2026-01-24T15:26:10.110636+00:00",
  "papers": [
    {
      "id": "2601.16212v1",
      "title": "Point Bridge: 3D Representations for Cross Domain Policy Learning",
      "abstract": "Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/",
      "authors": [
        "Siddhant Haldar",
        "Lars Johannsmeier",
        "Lerrel Pinto",
        "Abhishek Gupta",
        "Dieter Fox",
        "Yashraj Narang",
        "Ajay Mandlekar"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-22 18:59:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16212v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16208v1",
      "title": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders",
      "abstract": "Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.",
      "authors": [
        "Shengbang Tong",
        "Boyang Zheng",
        "Ziteng Wang",
        "Bingda Tang",
        "Nanye Ma",
        "Ellis Brown",
        "Jihan Yang",
        "Rob Fergus",
        "Yann LeCun",
        "Saining Xie"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 18:58:16+00:00",
      "link": "https://arxiv.org/pdf/2601.16208v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16199v1",
      "title": "PAL*M: Property Attestation for Large Generative Models",
      "abstract": "Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.",
      "authors": [
        "Prach Chantasantitam",
        "Adam Ilyas Caulfield",
        "Vasisht Duddu",
        "Lachlan J. Gunn",
        "N. Asokan"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-22 18:51:13+00:00",
      "link": "https://arxiv.org/pdf/2601.16199v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16194v1",
      "title": "A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows",
      "abstract": "This paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B&P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B&P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation.",
      "authors": [
        "El Mehdi Er Raqabi",
        "Kevin Dalmeijer",
        "Pascal Van Hentenryck"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-22 18:46:46+00:00",
      "link": "https://arxiv.org/pdf/2601.16194v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16187v1",
      "title": "Average Unfairness in Routing Games",
      "abstract": "We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.",
      "authors": [
        "Pan-Yang Su",
        "Arwa Alanqary",
        "Bryce L. Ferguson",
        "Manxi Wu",
        "Alexandre M. Bayen",
        "Shankar Sastry"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.GT",
        "eess.SY"
      ],
      "published": "2026-01-22 18:40:57+00:00",
      "link": "https://arxiv.org/pdf/2601.16187v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16175v1",
      "title": "Learning to Discover at Test Time",
      "abstract": "How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.",
      "authors": [
        "Mert Yuksekgonul",
        "Daniel Koceja",
        "Xinhao Li",
        "Federico Bianchi",
        "Jed McCaleb",
        "Xiaolong Wang",
        "Jan Kautz",
        "Yejin Choi",
        "James Zou",
        "Carlos Guestrin",
        "Yu Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 18:24:00+00:00",
      "link": "https://arxiv.org/pdf/2601.16175v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16163v1",
      "title": "Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning",
      "abstract": "Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on the target platform, with no architectural modifications. Cosmos Policy learns to directly generate robot actions encoded as latent frames within the video model's latent diffusion process, harnessing the model's pretrained priors and core learning algorithm to capture complex action distributions. Additionally, Cosmos Policy generates future state images and values (expected cumulative rewards), which are similarly encoded as latent frames, enabling test-time planning of action trajectories with higher likelihood of success. In our evaluations, Cosmos Policy achieves state-of-the-art performance on the LIBERO and RoboCasa simulation benchmarks (98.5% and 67.1% average success rates, respectively) and the highest average score in challenging real-world bimanual manipulation tasks, outperforming strong diffusion policies trained from scratch, video model-based policies, and state-of-the-art vision-language-action models fine-tuned on the same robot demonstrations. Furthermore, given policy rollout data, Cosmos Policy can learn from experience to refine its world model and value function and leverage model-based planning to achieve even higher success rates in challenging tasks. We release code, models, and training data at https://research.nvidia.com/labs/dir/cosmos-policy/",
      "authors": [
        "Moo Jin Kim",
        "Yihuai Gao",
        "Tsung-Yi Lin",
        "Yen-Chen Lin",
        "Yunhao Ge",
        "Grace Lam",
        "Percy Liang",
        "Shuran Song",
        "Ming-Yu Liu",
        "Chelsea Finn",
        "Jinwei Gu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-22 18:09:30+00:00",
      "link": "https://arxiv.org/pdf/2601.16163v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16158v1",
      "title": "Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems",
      "abstract": "Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\\% accuracy on clean data and maintaining robust performance (exceeding 94\\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.",
      "authors": [
        "Prakash Dhungana",
        "Sayed Ahmad Salehi"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "published": "2026-01-22 17:59:31+00:00",
      "link": "https://arxiv.org/pdf/2601.16158v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16156v1",
      "title": "All ascents exponential from valued constraint graphs of pathwidth three",
      "abstract": "Many combinatorial optimization problems can be formulated as finding as assignment that maximized some pseudo-Boolean function (that we call the fitness function). Strict local search starts with some assignment and follows some update rule to proceed to an adjacent assignment of strictly higher fitness. This means that strict local search algorithms follow ascents in the fitness landscape of the pseudo-Boolean function. The complexity of the pseudo-Boolean function (and the fitness landscapes that it represents) can be parameterized by properties of the valued constraint satisfaction problem (VCSP) that encodes the pseudo-Boolean function. We focus on properties of the constraint graphs of the VCSP, with the intuition that spare graphs are less complex than dense ones. Specifically, we argue that pathwidth is the natural sparsity parameter for understanding limits on the power of strict local search. We show that prior constructions of sparse VCSPs where all ascents are exponentially long had pathwidth greater than or equal to four. We improve this this with our controlled doubling construction: a valued constraint satisfaction problem of pathwidth three where all ascents are exponentially long from a designated initial assignment. From this, we conclude that all strict local search algorithms can be forced to take an exponential number of steps even on simple valued constraint graphs of pathwidth three.",
      "authors": [
        "Artem Kaznatcheev",
        "Willemijn Volgering"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM",
        "cs.DS"
      ],
      "published": "2026-01-22 17:57:54+00:00",
      "link": "https://arxiv.org/pdf/2601.16156v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16146v1",
      "title": "Low-altitude Multi-UAV-assisted Data Collection and Semantic Forwarding for Post-Disaster Relief",
      "abstract": "The low-altitude economy (LAE) is an emerging economic paradigm which fosters integrated development across multiple fields. As a pivotal component of the LAE, low-altitude uncrewed aerial vehicles (UAVs) can restore communication by serving as aerial relays between the post-disaster areas and remote base stations (BSs). However, conventional approaches face challenges from vulnerable long-distance links between the UAVs and remote BSs, and data bottlenecks arising from massive data volumes and limited onboard UAV resources. In this work, we investigate a low-altitude multi-UAV-assisted data collection and semantic forwarding network, in which multiple UAVs collect data from ground users, form clusters, perform intra-cluster data aggregation with semantic extraction, and then cooperate as virtual antenna array (VAAs) to transmit the extracted semantic information to a remote BS via collaborative beamforming (CB). We formulate a data collection and semantic forwarding multi-objective optimization problem (DCSFMOP) that jointly maximizes both the user and semantic transmission rates while minimizing UAV energy consumption. The formulated DCSFMOP is a mixed-integer nonlinear programming (MINLP) problem that is inherently NP-hard and characterized by dynamically varying decision variable dimensionality. To address these challenges, we propose a large language model-enabled alternating optimization approach (LLM-AOA), which effectively handles the complex search space and variable dimensionality by optimizing different subsets of decision variables through tailored optimization strategies. Simulation results demonstrate that LLM-AOA outperforms AOA by approximately 26.8\\% and 22.9\\% in transmission rate and semantic rate, respectively.",
      "authors": [
        "Xiaoya Zheng",
        "Geng Sun",
        "Jiahui Li",
        "Jiacheng Wang",
        "Weijie Yuan",
        "Qingqing Wu",
        "Dusit Niyato",
        "Abbas Jamalipour"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-22 17:38:12+00:00",
      "link": "https://arxiv.org/pdf/2601.16146v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16139v1",
      "title": "On the Intrinsic Dimensions of Data in Kernel Learning",
      "abstract": "The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\\to \\int_ΩK(\\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\\left(ε^{-d_ρ}\\log\\frac{1}ε\\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.",
      "authors": [
        "Rustem Takhanov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 17:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16139v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16138v1",
      "title": "Automatic Classification of Arabic Literature into Historical Eras",
      "abstract": "The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.",
      "authors": [
        "Zainab Alhathloul",
        "Irfan Ahmad"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-22 17:32:19+00:00",
      "link": "https://arxiv.org/pdf/2601.16138v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16117v1",
      "title": "Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks",
      "abstract": "Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\\%$ and $2.25\\%$ for high and no dropping cases with $33.3\\%$ reduction in training time.",
      "authors": [
        "Abdul Hannan",
        "Daniele Falavigna",
        "Shah Nawaz",
        "Mubashir Noman",
        "Markus Schedl",
        "Alessio Brutti"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.CV"
      ],
      "published": "2026-01-22 17:11:44+00:00",
      "link": "https://arxiv.org/pdf/2601.16117v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16112v1",
      "title": "Variable Splitting Binary Tree Models Based on Bayesian Context Tree Models for Time Series Segmentation",
      "abstract": "We propose a variable splitting binary tree (VSBT) model based on Bayesian context tree (BCT) models for time series segmentation. Unlike previous applications of BCT models, the tree structure in our model represents interval partitioning on the time domain. Moreover, interval partitioning is represented by recursive logistic regression models. By adjusting logistic regression coefficients, our model can represent split positions at arbitrary locations within each interval. This enables more compact tree representations. For simultaneous estimation of both split positions and tree depth, we develop an effective inference algorithm that combines local variational approximation for logistic regression with the context tree weighting (CTW) algorithm. We present numerical examples on synthetic data demonstrating the effectiveness of our model and algorithm.",
      "authors": [
        "Yuta Nakahara",
        "Shota Saito",
        "Kohei Horinouchi",
        "Koshi Shimada",
        "Naoki Ichijo",
        "Manabu Kobayashi",
        "Toshiyasu Matsushima"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 16:58:34+00:00",
      "link": "https://arxiv.org/pdf/2601.16112v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16107v1",
      "title": "Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets",
      "abstract": "Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.",
      "authors": [
        "Adithya Sineesh",
        "Akshita Kamsali"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 16:54:53+00:00",
      "link": "https://arxiv.org/pdf/2601.16107v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16098v1",
      "title": "Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification",
      "abstract": "Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.",
      "authors": [
        "Zack Dewis",
        "Yimin Zhu",
        "Zhengsen Xu",
        "Mabel Heffring",
        "Saeid Taleghanidoozdoozan",
        "Quinn Ledingham",
        "Lincoln Linlin Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-22 16:47:07+00:00",
      "link": "https://arxiv.org/pdf/2601.16098v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16096v1",
      "title": "Neural Particle Automata: Learning Self-Organizing Particle Dynamics",
      "abstract": "We introduce Neural Particle Automata (NPA), a Lagrangian generalization of Neural Cellular Automata (NCA) from static lattices to dynamic particle systems. Unlike classical Eulerian NCA where cells are pinned to pixels or voxels, NPA model each cell as a particle with a continuous position and internal state, both updated by a shared, learnable neural rule. This particle-based formulation yields clear individuation of cells, allows heterogeneous dynamics, and concentrates computation only on regions where activity is present. At the same time, particle systems pose challenges: neighborhoods are dynamic, and a naive implementation of local interactions scale quadratically with the number of particles. We address these challenges by replacing grid-based neighborhood perception with differentiable Smoothed Particle Hydrodynamics (SPH) operators backed by memory-efficient, CUDA-accelerated kernels, enabling scalable end-to-end training. Across tasks including morphogenesis, point-cloud classification, and particle-based texture synthesis, we show that NPA retain key NCA behaviors such as robustness and self-regeneration, while enabling new behaviors specific to particle systems. Together, these results position NPA as a compact neural model for learning self-organizing particle dynamics.",
      "authors": [
        "Hyunsoo Kim",
        "Ehsan Pajouheshgar",
        "Sabine Süsstrunk",
        "Wenzel Jakob",
        "Jinah Park"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.CV"
      ],
      "published": "2026-01-22 16:46:28+00:00",
      "link": "https://arxiv.org/pdf/2601.16096v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16091v1",
      "title": "Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals",
      "abstract": "Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points' locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.",
      "authors": [
        "Saar Cohen"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 16:42:05+00:00",
      "link": "https://arxiv.org/pdf/2601.16091v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16083v1",
      "title": "Probably Approximately Correct Maximum A Posteriori Inference",
      "abstract": "Computing the conditional mode of a distribution, better known as the $\\mathit{maximum\\ a\\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\\mathit{probably\\ approximately\\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.",
      "authors": [
        "Matthew Shorvon",
        "Frederik Mallmann-Trenn",
        "David S. Watson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 16:28:01+00:00",
      "link": "https://arxiv.org/pdf/2601.16083v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16079v1",
      "title": "Masked Modeling for Human Motion Recovery Under Occlusions",
      "abstract": "Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.",
      "authors": [
        "Zhiyin Qian",
        "Siwei Zhang",
        "Bharat Lal Bhatnagar",
        "Federica Bogo",
        "Siyu Tang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 16:22:20+00:00",
      "link": "https://arxiv.org/pdf/2601.16079v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16076v1",
      "title": "DNF formulas are efficiently testable with relative error",
      "abstract": "We give a poly$(s,1/ε)$-query algorithm for testing whether an unknown and arbitrary function $f: \\{0,1\\}^n \\to \\{0,1\\}$ is an $s$-term DNF, in the challenging relative-error framework for Boolean function property testing that was recently introduced and studied in a number of works [CDH+25b, CPPS25a, CPPS25b, CDH+25a]. This gives the first example of a rich and natural class of functions which may depend on a super-constant number of variables and yet is efficiently testable in the relative-error model with constant query complexity.   A crucial new ingredient enabling our approach is a novel decomposition of any $s$-term DNF formula into ``local clusters'' of terms. Our results demonstrate that this new decomposition can be usefully exploited for algorithms even when the $s$-term DNF is not explicitly given; we believe that this decomposition may have applications in other contexts.",
      "authors": [
        "Xi Chen",
        "William Pires",
        "Toniann Pitassi",
        "Rocco A. Servedio"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "cs.DS"
      ],
      "published": "2026-01-22 16:20:19+00:00",
      "link": "https://arxiv.org/pdf/2601.16076v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16074v1",
      "title": "Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems",
      "abstract": "Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.",
      "authors": [
        "Annemarie Jutte",
        "Uraz Odyurt"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 16:18:22+00:00",
      "link": "https://arxiv.org/pdf/2601.16074v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16072v1",
      "title": "CLASP: An online learning algorithm for Convex Losses And Squared Penalties",
      "abstract": "We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\\left(T^{\\max\\{β,1-β\\}}\\right)$ and cumulative squared penalty $O\\left(T^{1-β}\\right)$ for any $β\\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \\log T )$ and the cumulative squared penalty is also upper bounded by $O( \\log T )$.",
      "authors": [
        "Ricardo N. Ferreira",
        "Cláudia Soares",
        "João Xavier"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-22 16:13:52+00:00",
      "link": "https://arxiv.org/pdf/2601.16072v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16056v1",
      "title": "Designing faster mixed integer linear programming algorithm via learning the optimal path",
      "abstract": "Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.",
      "authors": [
        "Ruizhi Liu",
        "Liming Xu",
        "Xulin Huang",
        "Jingyan Sui",
        "Shizhe Ding",
        "Boyang Xia",
        "Chungong Yu",
        "Dongbo Bu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 15:41:22+00:00",
      "link": "https://arxiv.org/pdf/2601.16056v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16045v1",
      "title": "AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress",
      "abstract": "Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.",
      "authors": [
        "Yue Shi",
        "Liangxiu Han",
        "Xin Zhang",
        "Tam Sobeih",
        "Thomas Gaiser",
        "Nguyen Huu Thuy",
        "Dominik Behrend",
        "Amit Kumar Srivastava",
        "Krishnagopal Halder",
        "Frank Ewert"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 15:20:00+00:00",
      "link": "https://arxiv.org/pdf/2601.16045v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16041v1",
      "title": "Risk reversal for least squares estimators under nested convex constraints",
      "abstract": "In constrained stochastic optimization, one naturally expects that imposing a stricter feasible set does not increase the statistical risk of an estimator defined by projection onto that set. In this paper, we show that this intuition can fail even in canonical settings.   We study the Gaussian sequence model, a deliberately austere test best, where for a compact, convex set $Θ\\subset \\mathbb{R}^d$ one observes \\[ Y = θ^\\star + σZ, \\qquad Z \\sim N(0, I_d), \\] and seeks to estimate an unknown parameter $θ^\\star \\in Θ$. The natural estimator is the least squares estimator (LSE), which coincides with the Euclidean projection of $Y$ onto $Θ$. We construct an explicit example exhibiting \\emph{risk reversal}: for sufficiently large noise, there exist nested compact convex sets $Θ_S \\subset Θ_L$ and a parameter $θ^\\star \\in Θ_S$ such that the LSE constrained to $Θ_S$ has strictly larger risk than the LSE constrained to $Θ_L$. We further show that this phenomenon can persist at the level of worst-case risk, with the supremum risk over the smaller constraint set exceeding that over the larger one.   We clarify this behavior by contrasting noise regimes. In the vanishing-noise limit, the risk admits a first-order expansion governed by the statistical dimension of the tangent cone at $θ^\\star$, and tighter constraints uniformly reduce risk. In contrast, in the diverging-noise regime, the risk is determined by global geometric interactions between the constraint set and random noise directions. Here, the embedding of $Θ_S$ within $Θ_L$ can reverse the risk ordering.   These results reveal a previously unrecognized failure mode of projection-based estimators: in sufficiently noisy settings, tightening a constraint can paradoxically degrade statistical performance.",
      "authors": [
        "Omar Al-Ghattas"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-22 15:18:36+00:00",
      "link": "https://arxiv.org/pdf/2601.16041v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16038v1",
      "title": "Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval",
      "abstract": "Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.",
      "authors": [
        "Olga Bunkova",
        "Lorenzo Di Fruscia",
        "Sophia Rupprecht",
        "Artur M. Schweidtmann",
        "Marcel J. T. Reinders",
        "Jana M. Weber"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 15:11:02+00:00",
      "link": "https://arxiv.org/pdf/2601.16038v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16036v1",
      "title": "Tri-Hybrid Beamforming Design for integrated Sensing and Communications",
      "abstract": "Tri-hybrid beamforming architectures have been proposed to enable energy-efficient communications systems in extra-largescale antenna arrays using low-cost programmable metasurface antennas. We study the tri-hybrid beamforming design for integrated sensing and communications (ISAC) to improve both communications and sensing performances. Specifically, we formulate a multi-objective optimization problem that balances communications signal-to-noise ratio (SNR) and the sensing power at a target direction, subject to constraints on the total power consumption and physical limitations inherent to the trihybrid beamforming architecture. We develop an efficient iterative algorithm in which the variables are updated in a closed form at each iteration, leading to a low-complexity and fast-execution design. Numerical results show that the tri-hybrid architecture improves spatial gain and energy efficiency, though with reduced beam alignment capability compared to conventional hybrid beamforming architectures.",
      "authors": [
        "Tianyu Fang",
        "Mengyuan Ma",
        "Markku Juntti",
        "Nhan Thanh Nguyen"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 15:09:38+00:00",
      "link": "https://arxiv.org/pdf/2601.16036v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16033v1",
      "title": "RIS-Aided Cooperative ISAC Network for Imaging-Based Low-Altitude Surveillance",
      "abstract": "The low-altitude economy is integral to the advancement of numerous sectors, necessitating the development of advanced low-altitude surveillance techniques. Nevertheless, conventional methods encounter limitations of high deployment costs and low signal strength. This study proposes a reconfigurable intelligent surface (RIS)-aided cooperative integrated sensing and communication (ISAC) network for low-altitude surveillance. This network employs RISs to reflect ISAC signals into low-altitude space for sensing. To enhance signal strength, we employ active RIS (ARIS) to amplify the signals. Moreover, in order to avoid error propagation and data association in traditional sensing methods, we model low-altitude surveillance as an imaging problem based on compressed sensing theory, which can be solved through the subspace pursuit algorithm. We derive the Cramer-Rao lower bound (CRLB) of the proposed RIS-aided low-altitude imaging system and analyze the impacts of various system parameters on sensing performance, providing guidance for ISAC system configuration. Numerical results show that ARIS outperforms passive RIS under identical power constraints, achieving effective imaging and target detection at altitudes up to 300 meters.",
      "authors": [
        "Zhixin Chen",
        "Yixuan Huang",
        "Zhengze Ji",
        "Jie Yang",
        "Shi Jin"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 15:07:36+00:00",
      "link": "https://arxiv.org/pdf/2601.16033v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16032v1",
      "title": "Sawtooth Wavefront Reordering: Enhanced CuTile FlashAttention on NVIDIA GB10",
      "abstract": "High-performance attention kernels are essential for Large Language Models. This paper presents analysis of CuTile-based Flash Attention memory behavior and a technique to improve its cache performance. In particular, our analysis on the NVIDIA GB10 (Grace Blackwell) identifies the main cause of L2 cache miss. Leveraging this insight, we introduce a new programming technique called Sawtooth Wavefront Reordering that reduces L2 misses. We validate it in both CUDA and CuTile, observing 50\\% or greater reduction in L2 misses and up to 60\\% increase in throughput on GB10.",
      "authors": [
        "Yifan Zhu",
        "Yekai Pan",
        "Chen Ding"
      ],
      "primary_category": "cs.PF",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.LG",
        "cs.OS"
      ],
      "published": "2026-01-22 15:05:31+00:00",
      "link": "https://arxiv.org/pdf/2601.16032v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16030v1",
      "title": "Stacked Intelligent Metasurface-Aided Wave-Domain Signal Processing: From Communications to Sensing and Computing",
      "abstract": "Neural networks possess incredible capabilities for extracting abstract features from data. Electromagnetic computing harnesses wave propagation to execute computational operations. Metasurfaces, composed of subwavelength meta-atoms, are capable of engineering electromagnetic waves in unprecedented ways. What happens when combining these three cutting-edge technologies? This question has sparked a surge of interest in designing physical neural networks using stacked intelligent metasurface (SIM) technology, with the aim of implementing various computational tasks by directly processing electromagnetic waves. SIMs open up an exciting avenue toward high-speed, massively parallel, and low-power signal processing in the electromagnetic domain. This article provides a comprehensive overview of SIM technology, commencing with its evolutionary development. We subsequently examine its theoretical foundations and existing SIM prototypes in depth. Furthermore, the optimization/training strategies conceived to configure SIMs for achieving the desired functionalities are discussed from two different perspectives. Additionally, we explore the diverse applications of SIM technology across the communication, sensing, and computing domains, presenting experimental evidence that highlights its distinctive advantages in supporting multiple functions within a single device. Finally, we identify critical technical challenges that must be addressed to deploy SIMs in next-generation wireless networks and shed light on promising research directions to unlock their full potential.",
      "authors": [
        "Jiancheng An",
        "Chau Yuen",
        "Marco Di Renzo",
        "Mehdi Bennis",
        "Merouane Debbah",
        "Lajos Hanzo"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 14:58:43+00:00",
      "link": "https://arxiv.org/pdf/2601.16030v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16027v1",
      "title": "Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment",
      "abstract": "The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.",
      "authors": [
        "Yiran Qiao",
        "Xiang Ao",
        "Jing Chen",
        "Yang Liu",
        "Qiwei Zhong",
        "Qing He"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 14:55:51+00:00",
      "link": "https://arxiv.org/pdf/2601.16027v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16025v1",
      "title": "EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery",
      "abstract": "Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.",
      "authors": [
        "Yajuan Xu",
        "Xixian Han",
        "Xiaolong Wan"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-22 14:52:36+00:00",
      "link": "https://arxiv.org/pdf/2601.16025v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16020v1",
      "title": "Keyframe-Based Feed-Forward Visual Odometry",
      "abstract": "The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.",
      "authors": [
        "Weichen Dai",
        "Wenhan Su",
        "Da Kong",
        "Yuhang Ming",
        "Wanzeng Kong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-01-22 14:45:42+00:00",
      "link": "https://arxiv.org/pdf/2601.16020v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16008v1",
      "title": "Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking",
      "abstract": "Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.",
      "authors": [
        "Federico Bruzzone",
        "Walter Cazzola",
        "Luca Favini"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-01-22 14:34:09+00:00",
      "link": "https://arxiv.org/pdf/2601.16008v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16007v1",
      "title": "PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models",
      "abstract": "Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.",
      "authors": [
        "Chak-Wing Mak",
        "Guanyu Zhu",
        "Boyi Zhang",
        "Hongji Li",
        "Xiaowei Chi",
        "Kevin Zhang",
        "Yichen Wu",
        "Yangfan He",
        "Chun-Kai Fan",
        "Wentao Lu",
        "Kuangzhi Ge",
        "Xinyu Fang",
        "Hongyang He",
        "Kuan Lu",
        "Tianxiang Xu",
        "Li Zhang",
        "Yongxin Ni",
        "Youhua Li",
        "Shanghang Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-22 14:33:01+00:00",
      "link": "https://arxiv.org/pdf/2601.16007v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15992v1",
      "title": "Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs",
      "abstract": "With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub",
      "authors": [
        "Shidan Ma",
        "Peng Peng",
        "Xu Zhou",
        "M. Tamer Özsu",
        "Lei Zou",
        "Guo Chen"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-22 14:14:37+00:00",
      "link": "https://arxiv.org/pdf/2601.15992v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15984v1",
      "title": "Partially Lazy Gradient Descent for Smoothed Online Learning",
      "abstract": "We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\\mathcal{O}(\\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $Θ(\\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.",
      "authors": [
        "Naram Mhaisen",
        "George Iosifidis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 14:05:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15984v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15975v1",
      "title": "Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory",
      "abstract": "Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.",
      "authors": [
        "Chen Xu",
        "Zhipeng Yi",
        "Ruizi Wang",
        "Wenjie Wang",
        "Jun Xu",
        "Maarten de Rijke"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-22 13:54:06+00:00",
      "link": "https://arxiv.org/pdf/2601.15975v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15968v1",
      "title": "HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models",
      "abstract": "Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.",
      "authors": [
        "Xin Xie",
        "Jiaxian Guo",
        "Dong Gong"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 13:49:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15968v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15951v1",
      "title": "EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis",
      "abstract": "Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.",
      "authors": [
        "Sheng Miao",
        "Sijin Li",
        "Pan Wang",
        "Dongfeng Bai",
        "Bingbing Liu",
        "Yue Wang",
        "Andreas Geiger",
        "Yiyi Liao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 13:39:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15951v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15943v1",
      "title": "An Efficient Algorithm to Generate all Labeled Triangle-free Graphs with a given Graphical Degree Sequence",
      "abstract": "We extend our previous algorithm that generates all labeled graphs with a given graphical degree sequence to generate all labeled triangle-free graphs with a given graphical degree sequence. The algorithm uses various pruning techniques to avoid having to first generate all labeled realizations of the input sequence and then testing whether each labeled realization is triangle-free. It can be further extended to generate all labeled bipartite graphs with a given graphical degree sequence by adding a simple test whether each generated triangle-free realization is a bipartite graph. All output graphs are generated in the lexicographical ordering as in the original algorithm. The algorithms can also be easily parallelized.",
      "authors": [
        "Kai Wang"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.CC"
      ],
      "published": "2026-01-22 13:24:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15943v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15931v1",
      "title": "ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search",
      "abstract": "Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on \"Passive Observation\" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.",
      "authors": [
        "Xiangyu Wang",
        "Zhixin Lv",
        "Yongjiao Sun",
        "Anrui Han",
        "Ye Yuan",
        "Hangxu Ji"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 13:09:22+00:00",
      "link": "https://arxiv.org/pdf/2601.15931v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15918v1",
      "title": "A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery",
      "abstract": "Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.   Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.   Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.   Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.",
      "authors": [
        "Valery Fischer",
        "Alan Magdaleno",
        "Anna-Katharina Calek",
        "Nicola Cavalcanti",
        "Nathan Hoffman",
        "Christoph Germann",
        "Joschua Wüthrich",
        "Max Krähenmann",
        "Mazda Farshad",
        "Philipp Fürnstahl",
        "Lilian Calvet"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 12:48:24+00:00",
      "link": "https://arxiv.org/pdf/2601.15918v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15915v1",
      "title": "Progressive Power Homotopy for Non-convex Optimization",
      "abstract": "We propose a novel first-order method for non-convex optimization of the form $\\max_{\\bm{w}\\in\\mathbb{R}^d}\\mathbb{E}_{\\bm{x}\\sim\\mathcal{D}}[f_{\\bm{w}}(\\bm{x})]$, termed Progressive Power Homotopy (Prog-PowerHP). The method applies stochastic gradient ascent to a surrogate objective obtained by first performing a power transformation and then Gaussian smoothing, $F_{N,σ}(\\bmμ):=\\mathbb{E}_{\\bm{w}\\sim\\mathcal{N}(\\bmμ,σ^2I_d),\\bm{x}\\sim\\mathcal{D}}[e^{Nf_w(\\bm{x})}]$, while progressively increasing the power parameter $N$ and decreasing the smoothing scale $σ$ along the optimization trajectory. We prove that, under mild regularity conditions, Prog-PowerHP converges to a small neighborhood of the global optimum with an iteration complexity scaling nearly as $O(d^2\\varepsilon^{-2})$. Empirically, Prog-PowerHP demonstrates clear advantages in phase retrieval when the samples-to-dimension ratio approaches the information-theoretic limit, and in training two-layer neural networks in under-parameterized regimes. These results suggest that Prog-PowerHP is particularly effective for navigating cluttered non-convex landscapes where standard first-order methods struggle.",
      "authors": [
        "Chen Xu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 12:44:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15915v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15912v1",
      "title": "TeNet: Text-to-Network for Compact Policy Synthesis",
      "abstract": "Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.",
      "authors": [
        "Ariyan Bighashdel",
        "Kevin Sebastian Luck"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-22 12:42:30+00:00",
      "link": "https://arxiv.org/pdf/2601.15912v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15889v1",
      "title": "A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering",
      "abstract": "The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.",
      "authors": [
        "Zhengding Luo",
        "Haozhe Ma",
        "Boxiang Wang",
        "Ziyi Yang",
        "Dongyuan Shi",
        "Woon-Seng Gan"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-01-22 12:11:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15889v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15879v1",
      "title": "Evaluating and Achieving Controllable Code Completion in Code LLM",
      "abstract": "Code completion has become a central task, gaining significant attention with the rise of large language model (LLM)-based tools in software engineering. Although recent advances have greatly improved LLMs' code completion abilities, evaluation methods have not advanced equally. Most current benchmarks focus solely on functional correctness of code completions based on given context, overlooking models' ability to follow user instructions during completion-a common scenario in LLM-assisted programming. To address this limitation, we present the first instruction-guided code completion benchmark, Controllable Code Completion Benchmark (C3-Bench), comprising 2,195 carefully designed completion tasks. Through comprehensive evaluation of over 40 mainstream LLMs across C3-Bench and conventional benchmarks, we reveal substantial gaps in instruction-following capabilities between open-source and advanced proprietary models during code completion tasks. Moreover, we develop a straightforward data synthesis pipeline that leverages Qwen2.5-Coder to generate high-quality instruction-completion pairs for supervised fine-tuning (SFT). The resulting model, Qwen2.5-Coder-C3, achieves state-of-the-art performance on C3-Bench. Our findings provide valuable insights for enhancing LLMs' code completion and instruction-following capabilities, establishing new directions for future research in code LLMs. To facilitate reproducibility and foster further research in code LLMs, we open-source all code, datasets, and models.",
      "authors": [
        "Jiajun Zhang",
        "Zeyu Cui",
        "Lei Zhang",
        "Jian Yang",
        "Jiaxi Yang",
        "Qiang Liu",
        "Zilei Wang",
        "Binyuan Hui",
        "Liang Wang",
        "Junyang Lin"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CL"
      ],
      "published": "2026-01-22 11:40:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15879v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15871v1",
      "title": "Why Inference in Large Models Becomes Decomposable After Training",
      "abstract": "Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.",
      "authors": [
        "Jidong Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 11:20:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15871v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15865v1",
      "title": "A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies",
      "abstract": "Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.",
      "authors": [
        "Jingsong Xia",
        "Siqi Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-22 11:14:37+00:00",
      "link": "https://arxiv.org/pdf/2601.15865v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15864v1",
      "title": "Minimum Envy Graphical House Allocation Beyond Identical Valuations",
      "abstract": "House allocation is an extremely well-studied problem in the field of fair allocation, where the goal is to assign $n$ houses to $n$ agents while satisfying certain fairness criterion, e.g., envy-freeness. To model social interactions, the Graphical House Allocation framework introduces a social graph $G$, in which each vertex corresponds to an agent, and an edge $(u, v)$ corresponds to the potential of agent $u$ to envy the agent $v$, based on their allocations and valuations. In undirected social graphs, the potential for envy is in both the directions. In the Minimum Envy Graphical House Allocation (ME-GHA) problem, given a set of $n$ agents, $n$ houses, a social graph, and agent's valuation functions, the goal is to find an allocation that minimizes the total envy summed up over all the edges of $G$. Recent work, [Hosseini et al., AAMAS 2023, AAMAS 2024] studied ME-GHA in the regime of polynomial-time algorithms, and designed exact and approximation algorithms, for certain graph classes under identical agent valuations. We initiate the study of \\gha with non-identical valuations, a setting that has so far remained unexplored. We investigate the multivariate (parameterized) complexity of \\gha by identifying structural restrictions on the social graph and valuation functions that yield tractability. We also design moderately exponential-time algorithms for several graph classes, and a polynomial-time algorithm for {binary valuations that returns an allocation with envy at most one when the social graph has maximum degree at most one.",
      "authors": [
        "Tanmay Inamdar",
        "Pallavi Jain",
        "Pranjal Pandey"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.DS"
      ],
      "published": "2026-01-22 11:12:09+00:00",
      "link": "https://arxiv.org/pdf/2601.15864v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15861v1",
      "title": "Finding large sparse induced subgraphs in graphs of small (but not very small) tree-independence number",
      "abstract": "The independence number of a tree decomposition is the size of a largest independent set contained in a single bag. The tree-independence number of a graph $G$ is the minimum independence number of a tree decomposition of $G$. As shown recently by Lima et al. [ESA~2024], a large family of optimization problems asking for a maximum-weight induced subgraph of bounded treewidth, satisfying a given \\textsf{CMSO}$_2$ property, can be solved in polynomial time in graphs whose tree-independence number is bounded by some constant~$k$.   However, the complexity of the algorithm of Lima et al. grows rapidly with $k$, making it useless if the tree-independence number is superconstant. In this paper we present a refined version of the algorithm. We show that the same family of problems can be solved in time~$n^{\\mathcal{O}(k)}$, where $n$ is the number of vertices of the instance, $k$ is the tree-independence number, and the $\\mathcal{O}(\\cdot)$-notation hides factors depending on the treewidth bound of the solution and the considered \\textsf{CMSO}$_2$ property.   This running time is quasipolynomial for classes of graphs with polylogarithmic tree-independence number; several such classes were recently discovered. Furthermore, the running time is subexponential for many natural classes of geometric intersection graphs -- namely, ones that admit balanced clique-based separators of sublinear size.",
      "authors": [
        "Daniel Lokshtanov",
        "Michał Pilipczuk",
        "Paweł Rzążewski"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-22 11:08:49+00:00",
      "link": "https://arxiv.org/pdf/2601.15861v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15860v1",
      "title": "STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion",
      "abstract": "Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.",
      "authors": [
        "Shui-Hsiang Hsu",
        "Tsung-Hsiang Chou",
        "Chen-Jui Yu",
        "Yao-Chung Fan"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-22 11:08:46+00:00",
      "link": "https://arxiv.org/pdf/2601.15860v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15849v1",
      "title": "CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval",
      "abstract": "General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.",
      "authors": [
        "Tsung-Hsiang Chou",
        "Chen-Jui Yu",
        "Shui-Hsiang Hsu",
        "Yao-Chung Fan"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-22 10:58:56+00:00",
      "link": "https://arxiv.org/pdf/2601.15849v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15838v1",
      "title": "TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing",
      "abstract": "With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.",
      "authors": [
        "Toan Gian",
        "Dung T. Tran",
        "Viet Quoc Pham",
        "Francesco Restuccia",
        "Van-Dinh Nguyen"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 10:44:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15838v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15830v1",
      "title": "An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics",
      "abstract": "The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \\$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.",
      "authors": [
        "Abdul Hasib",
        "A. S. M. Ahsanul Sarkar Akib"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 10:33:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15830v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15829v1",
      "title": "Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion",
      "abstract": "Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).",
      "authors": [
        "Yonghao Xu",
        "Pedram Ghamisi",
        "Qihao Weng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 10:30:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15829v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15816v1",
      "title": "Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents",
      "abstract": "Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability.",
      "authors": [
        "Shiqi Wei",
        "Qiqing Wang",
        "Kaidi Yang"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "published": "2026-01-22 10:04:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15816v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15814v1",
      "title": "Improved Approximation Ratios for the Shortest Common Superstring Problem with Reverse Complements",
      "abstract": "The Shortest Common Superstring (SCS) problem asks for the shortest string that contains each of a given set of strings as a substring. Its reverse-complement variant, the Shortest Common Superstring problem with Reverse Complements (SCS-RC), naturally arises in bioinformatics applications, where for each input string, either the string itself or its reverse complement must appear as a substring of the superstring. The well-known MGREEDY algorithm for the standard SCS constructs a superstring by first computing an optimal cycle cover on the overlap graph and then concatenating the strings corresponding to the cycles, while its refined variant, TGREEDY, further improves the approximation ratio. Although the original 4- and 3-approximation bounds of these algorithms have been successively improved for the standard SCS, no such progress has been made for the reverse-complement setting. A previous study extended MGREEDY to SCS-RC with a 4-approximation guarantee and briefly suggested that extending TGREEDY to the reverse-complement setting could achieve a 3-approximation. In this work, we strengthen these results by proving that the extensions of MGREEDY and TGREEDY to the reverse-complement setting achieve 3.75- and 2.875-approximation ratios, respectively. Our analysis extends the classical proofs for the standard SCS to handle the bidirectional overlaps introduced by reverse complements. These results provide the first formal improvement of approximation guarantees for SCS-RC, with the 2.875-approximate algorithm currently representing the best known bound for this problem.",
      "authors": [
        "Ryosuke Yamano",
        "Tetsuo Shibuya"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-22 10:01:56+00:00",
      "link": "https://arxiv.org/pdf/2601.15814v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15810v1",
      "title": "A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks",
      "abstract": "A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.",
      "authors": [
        "Mustafa Yurdakul",
        "Enes Ayan",
        "Fahrettin Horasan",
        "Sakir Tasdemir"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-22 09:52:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15810v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15808v1",
      "title": "Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification",
      "abstract": "Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.",
      "authors": [
        "Yuxuan Wan",
        "Tianqing Fang",
        "Zaitang Li",
        "Yintong Huo",
        "Wenxuan Wang",
        "Haitao Mi",
        "Dong Yu",
        "Michael R. Lyu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 09:47:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15808v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15804v1",
      "title": "Entangled Life and Code: A Computational Design Taxonomy for Synergistic Bio-Digital Systems",
      "abstract": "Bio-digital systems that merge microbial life with technology promise new modes of computation, combining biological adaptability with digital precision. Yet realizing this potential symbiotically -- where biological and digital agents co-adapt and co-process -- remains elusive, largely due to the absence of a shared vocabulary bridging biology and computing. Consequently, microbes are often constrained to uni-directional roles, functioning as sensors or actuators rather than as active, computational partners in bio-digital systems. In response, we propose a taxonomy and pathways that articulate and expand the roles of biological and digital entities for synergetic bio-digital computation. Using this taxonomy, we analysed 70 systems across HCI, design, and engineering, identifying how biological mechanisms can be mapped onto computational abstractions. We argue that such mappings enable computationally actionable directions that foster richer and reciprocal relationships in bio-digital systems, supporting regenerative ecologies across time and scale while inspiring new paradigms for computation in HCI.",
      "authors": [
        "Zoë Breed",
        "Elvin Karana",
        "Alessandro Bozzon",
        "Katherine W. Song"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-22 09:41:11+00:00",
      "link": "https://arxiv.org/pdf/2601.15804v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15793v1",
      "title": "HumanLLM: Towards Personalized Understanding and Simulation of Human Nature",
      "abstract": "Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.",
      "authors": [
        "Yuxuan Lei",
        "Tianfu Wang",
        "Jianxun Lian",
        "Zhengyu Hu",
        "Defu Lian",
        "Xing Xie"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-22 09:27:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15793v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15779v1",
      "title": "Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation",
      "abstract": "Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.",
      "authors": [
        "Liuyun Jiang",
        "Yanchao Zhang",
        "Jinyue Guo",
        "Yizhuo Lu",
        "Ruining Zhou",
        "Hua Han"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 09:12:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15779v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15757v1",
      "title": "White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification",
      "abstract": "In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.",
      "authors": [
        "Yimin Zhu",
        "Lincoln Linlin Xu",
        "Zhengsen Xu",
        "Zack Dewis",
        "Mabel Heffring",
        "Saeid Taleghanidoozdoozan",
        "Motasem Alkayid",
        "Quinn Ledingham",
        "Megan Greenwood"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 08:48:01+00:00",
      "link": "https://arxiv.org/pdf/2601.15757v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15754v1",
      "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
      "abstract": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
      "authors": [
        "Ajvad Haneef K",
        "Karan Kuwar Singh",
        "Madhu Kumar S D"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 08:43:15+00:00",
      "link": "https://arxiv.org/pdf/2601.15754v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15751v1",
      "title": "Tabular Incremental Inference",
      "abstract": "Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.",
      "authors": [
        "Xinda Chen",
        "Xing Zhen",
        "Hanyu Zhang",
        "Weimin Tan",
        "Bo Yan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 08:24:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15751v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15738v1",
      "title": "LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling",
      "abstract": "Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.",
      "authors": [
        "Junhao Qiu",
        "Haoyang Zhuang",
        "Fei Liu",
        "Jianjun Liu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-22 08:06:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15738v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15731v1",
      "title": "FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging",
      "abstract": "An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.",
      "authors": [
        "Linyong Zou",
        "Liang Zhang",
        "Xiongfei Wang",
        "Jia-Hong Gao",
        "Yi Sun",
        "Shurong Sheng",
        "Kuntao Xiao",
        "Wanli Yang",
        "Pengfei Teng",
        "Guoming Luan",
        "Zhao Lv",
        "Zikang Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-22 07:57:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15731v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15727v1",
      "title": "Towards Automated Kernel Generation in the Era of LLMs",
      "abstract": "The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.",
      "authors": [
        "Yang Yu",
        "Peiyu Zang",
        "Chi Hsu Tsai",
        "Haiming Wu",
        "Yixin Shen",
        "Jialing Zhang",
        "Haoyu Wang",
        "Zhiyou Xiao",
        "Jingze Shi",
        "Yuyu Luo",
        "Wentao Zhang",
        "Chunlei Men",
        "Guang Liu",
        "Yonghua Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-22 07:53:52+00:00",
      "link": "https://arxiv.org/pdf/2601.15727v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15724v1",
      "title": "VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning",
      "abstract": "Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.",
      "authors": [
        "Chenglin Li",
        "Qianglong Chen",
        "Feng Han",
        "Yikun Wang",
        "Xingxi Yin",
        "Yan Gong",
        "Ruilin Li",
        "Yin Zhang",
        "Jiaqi Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-22 07:47:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15724v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15717v1",
      "title": "Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling",
      "abstract": "Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.",
      "authors": [
        "Luyao Zhu",
        "Fangfang Zhang",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 07:38:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15717v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15715v1",
      "title": "Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind",
      "abstract": "Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.",
      "authors": [
        "Zhitao He",
        "Zongwei Lyu",
        "Yi R Fung"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-22 07:36:48+00:00",
      "link": "https://arxiv.org/pdf/2601.15715v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15711v1",
      "title": "Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework",
      "abstract": "Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, \"outer fabric\" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.",
      "authors": [
        "Shubham Shukla",
        "Kunal Sonalkar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 07:33:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15711v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15709v1",
      "title": "AgentSM: Semantic Memory for Agentic Text-to-SQL",
      "abstract": "Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.",
      "authors": [
        "Asim Biswal",
        "Chuan Lei",
        "Xiao Qin",
        "Aodong Li",
        "Balakrishnan Narayanaswamy",
        "Tim Kraska"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "published": "2026-01-22 07:31:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15709v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15707v1",
      "title": "D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot",
      "abstract": "Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.",
      "authors": [
        "Qifan Hu",
        "Branko Celler",
        "Weidong Mu",
        "Steven W. Su"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-22 07:20:55+00:00",
      "link": "https://arxiv.org/pdf/2601.15707v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15690v1",
      "title": "From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models",
      "abstract": "While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \\textbf{advanced reasoning} to optimize computation and trigger self-correction; in \\textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \\textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.",
      "authors": [
        "Jiaxin Zhang",
        "Wendi Cui",
        "Zhuohang Li",
        "Lifu Huang",
        "Bradley Malin",
        "Caiming Xiong",
        "Chien-Sheng Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "published": "2026-01-22 06:21:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15690v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15687v1",
      "title": "FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation",
      "abstract": "Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.",
      "authors": [
        "Khusrav Badalov",
        "Young Yoon"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-22 06:12:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15687v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15686v1",
      "title": "Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing",
      "abstract": "Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit \"hard writes\" can accumulate interference over time, while null-space-style \"hard preservation\" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.",
      "authors": [
        "Xinyu Wang",
        "Sicheng Lyu",
        "Yu Gu",
        "Jerry Huang",
        "Peng Lu",
        "Yufei Cui",
        "Xiao-Wen Chang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 06:11:44+00:00",
      "link": "https://arxiv.org/pdf/2601.15686v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15678v1",
      "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
      "abstract": "Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.",
      "authors": [
        "Mengyu Yao",
        "Ziqi Zhang",
        "Ning Luo",
        "Shaofei Li",
        "Yifeng Cai",
        "Xiangqun Chen",
        "Yao Guo",
        "Ding Li"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-22 05:59:42+00:00",
      "link": "https://arxiv.org/pdf/2601.15678v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15657v1",
      "title": "Integrating Knowledge Distillation Methods: A Sequential Multi-Stage Framework",
      "abstract": "Knowledge distillation (KD) transfers knowledge from large teacher models to compact student models, enabling efficient deployment on resource constrained devices. While diverse KD methods, including response based, feature based, and relation based approaches, capture different aspects of teacher knowledge, integrating multiple methods or knowledge sources is promising but often hampered by complex implementation, inflexible combinations, and catastrophic forgetting, which limits practical effectiveness.   This work proposes SMSKD (Sequential Multi Stage Knowledge Distillation), a flexible framework that sequentially integrates heterogeneous KD methods. At each stage, the student is trained with a specific distillation method, while a frozen reference model from the previous stage anchors learned knowledge to mitigate forgetting. In addition, we introduce an adaptive weighting mechanism based on the teacher true class probability (TCP) that dynamically adjusts the reference loss per sample to balance knowledge retention and integration.   By design, SMSKD supports arbitrary method combinations and stage counts with negligible computational overhead. Extensive experiments show that SMSKD consistently improves student accuracy across diverse teacher student architectures and method combinations, outperforming existing baselines. Ablation studies confirm that stage wise distillation and reference model supervision are primary contributors to performance gains, with TCP based adaptive weighting providing complementary benefits. Overall, SMSKD is a practical and resource efficient solution for integrating heterogeneous KD methods.",
      "authors": [
        "Yinxi Tian",
        "Changwu Huang",
        "Ke Tang",
        "Xin Yao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 05:13:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15657v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15645v1",
      "title": "Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation",
      "abstract": "Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.",
      "authors": [
        "Zhiyao Ren",
        "Yibing Zhan",
        "Siyuan Liang",
        "Guozheng Ma",
        "Baosheng Yu",
        "Dacheng Tao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-22 04:51:39+00:00",
      "link": "https://arxiv.org/pdf/2601.15645v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15641v1",
      "title": "Machine Failure Detection Based on Projected Quantum Models",
      "abstract": "Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.",
      "authors": [
        "Larry Bowden",
        "Qi Chu",
        "Bernard Cena",
        "Kentaro Ohno",
        "Bob Parney",
        "Deepak Sharma",
        "Mitsuharu Takeori"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-01-22 04:43:53+00:00",
      "link": "https://arxiv.org/pdf/2601.15641v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15640v1",
      "title": "An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types",
      "abstract": "Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.",
      "authors": [
        "Natasha Trinkle",
        "Huong Ha",
        "Jeffrey Chan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-22 04:41:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15640v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15635v1",
      "title": "Community-Size Biases in Statistical Inference of Communities in Temporal Networks",
      "abstract": "In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison.",
      "authors": [
        "Theodore Y. Faust",
        "Arash A. Amini",
        "Mason A. Porter"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "physics.soc-ph",
        "stat.ME"
      ],
      "published": "2026-01-22 04:17:00+00:00",
      "link": "https://arxiv.org/pdf/2601.15635v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15633v1",
      "title": "Advancing RT Core-Accelerated Fixed-Radius Nearest Neighbor Search",
      "abstract": "In this work we introduce three ideas that can further improve particle FRNN physics simulations running on RT Cores; i) a real-time update/rebuild ratio optimizer for the bounding volume hierarchy (BVH) structure, ii) a new RT core use, with two variants, that eliminates the need of a neighbor list and iii) a technique that enables RT cores for FRNN with periodic boundary conditions (BC). Experimental evaluation using the Lennard-Jones FRNN interaction model as a case study shows that the proposed update/rebuild ratio optimizer is capable of adapting to the different dynamics that emerge during a simulation, leading to a RT core pipeline up to $\\sim 3.4\\times$ faster than with other known approaches to manage the BVH. In terms of simulation step performance, the proposed variants can significantly improve the speedup and EE of the base RT core idea; from $\\sim1.3\\times$ at small radius to $\\sim2.0\\times$ for log normal radius distributions. Furthermore, the proposed variants manage to simulate cases that would otherwise not fit in memory because of the use of neighbor lists, such as clusters of particles with log normal radius distribution. The proposed RT Core technique to support periodic BC is indeed effective as it does not introduce any significant penalty in performance. In terms of scaling, the proposed methods scale both their performance and EE across GPU generations. Throughout the experimental evaluation, we also identify the simulation cases were regular GPU computation should still be preferred, contributing to the understanding of the strengths and limitations of RT cores.",
      "authors": [
        "Enzo Meneses",
        "Hugo Bec",
        "Cristóbal A. Navarroa",
        "Benoît Crespin",
        "Felipe A. Quezada",
        "Nancy Hitschfeld",
        "Heinich Porro",
        "Maxime Maria"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-01-22 04:14:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15633v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15624v1",
      "title": "Explainable Deepfake Detection with RL Enhanced Self-Blended Images",
      "abstract": "Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.",
      "authors": [
        "Ning Jiang",
        "Dingheng Zeng",
        "Yanhong Liu",
        "Haiyang Yi",
        "Shijie Yu",
        "Minghe Weng",
        "Haifeng Shen",
        "Ying Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 03:55:46+00:00",
      "link": "https://arxiv.org/pdf/2601.15624v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15620v1",
      "title": "Closing the Gap on the Sample Complexity of 1-Identification",
      "abstract": "1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $μ_0$, or to output \\textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-δ$, while making expected total pulling times $\\mathbb{E}τ$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\\mathbb{E}τ$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\\mathbb{E}τ$ when there are multiple qualified arms, which is an open problem left by history literature.",
      "authors": [
        "Zitian Li",
        "Wang Chi Cheung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 03:50:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15620v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15615v1",
      "title": "Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition",
      "abstract": "Cross-subject EEG-based emotion recognition (EER) remains challenging due to strong inter-subject variability, which induces substantial distribution shifts in EEG signals, as well as the high complexity of emotion-related neural representations in both spatial organization and temporal evolution. Existing approaches typically improve spatial modeling, temporal modeling, or generalization strategies in isolation, which limits their ability to align representations across subjects while capturing multi-scale dynamics and suppressing subject-specific bias within a unified framework. To address these gaps, we propose a Region-aware Spatiotemporal Modeling framework with Collaborative Domain Generalization (RSM-CoDG) for cross-subject EEG emotion recognition. RSM-CoDG incorporates neuroscience priors derived from functional brain region partitioning to construct region-level spatial representations, thereby improving cross-subject comparability. It also employs multi-scale temporal modeling to characterize the dynamic evolution of emotion-evoked neural activity. In addition, the framework employs a collaborative domain generalization strategy, incorporating multidimensional constraints to reduce subject-specific bias in a fully unseen target subject setting, which enhances the generalization to unknown individuals. Extensive experimental results on SEED series datasets demonstrate that RSM-CoDG consistently outperforms existing competing methods, providing an effective approach for improving robustness. The source code is available at https://github.com/RyanLi-X/RSM-CoDG.",
      "authors": [
        "Weiwei Wu",
        "Yueyang Li",
        "Yuhu Shi",
        "Weiming Zeng",
        "Lang Qin",
        "Yang Yang",
        "Ke Zhou",
        "Zhiguo Zhang",
        "Wai Ting Siok",
        "Nizhuan Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-22 03:35:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15615v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15614v1",
      "title": "AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning",
      "abstract": "Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.",
      "authors": [
        "Zichen Yan",
        "Yuchen Hou",
        "Shenao Wang",
        "Yichao Gao",
        "Rui Huang",
        "Lin Zhao"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-22 03:35:34+00:00",
      "link": "https://arxiv.org/pdf/2601.15614v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15603v1",
      "title": "On the Nonasymptotic Scaling Guarantee of Hyperparameter Estimation in Inhomogeneous, Weakly-Dependent Complex Network Dynamical Systems",
      "abstract": "Hierarchical Bayesian models are increasingly used in large, inhomogeneous complex network dynamical systems by modeling parameters as draws from a hyperparameter-governed distribution. However, theoretical guarantees for these estimates as the system size grows have been lacking. A critical concern is that hyperparameter estimation may diverge for larger networks, undermining the model's reliability. Formulating the system's evolution in a measure transport perspective, we propose a theoretical framework for estimating hyperparameters with mean-type observations, which are prevalent in many scientific applications. Our primary contribution is a nonasymptotic bound for the deviation of estimate of hyperparameters in inhomogeneous complex network dynamical systems with respect to network population size, which is established for a general family of optimization algorithms within a fixed observation duration. While we firstly establish a consistency result for systems with independent nodes, our main result extends this guarantee to the more challenging and realistic setting of weakly-dependent nodes. We validate our theoretical findings with numerical experiments on two representative models: a Susceptible-Infected-Susceptible model and a Spiking Neuronal Network model. In both cases, the results confirm that the estimation error decreases as the network population size increases, aligning with our theoretical guarantees. This research proposes the foundational theory to ensure that hierarchical Bayesian methods are statistically consistent for large-scale inhomogeneous systems, filling a gap in this area of theoretical research and justifying their application in practice.",
      "authors": [
        "Yi Yu",
        "Yubo Hou",
        "Yinchong Wang",
        "Nan Zhang",
        "Jianfeng Feng",
        "Wenlian Lu"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.IT",
        "stat.ML"
      ],
      "published": "2026-01-22 03:05:39+00:00",
      "link": "https://arxiv.org/pdf/2601.15603v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15597v1",
      "title": "Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization",
      "abstract": "This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard & Poor's 500 Index (S&P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.",
      "authors": [
        "Liusha Yang",
        "Siqi Zhao",
        "Shuqi Chai"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "published": "2026-01-22 02:44:33+00:00",
      "link": "https://arxiv.org/pdf/2601.15597v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15593v1",
      "title": "Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow",
      "abstract": "Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require \"backward information\" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.",
      "authors": [
        "Yangyang Zhong",
        "Yanmei Gu",
        "Zhengqing Zang",
        "Xiaomeng Li",
        "Yuqi Ding",
        "Xibei Jia",
        "Yuting Shen",
        "Zhenzhong Lan",
        "Liwang Zhu",
        "Weiping Liu",
        "Junlin Zhou",
        "Haisheng Liu",
        "Zhong Xin Yu",
        "Pengxin Luo",
        "Donglian Qi",
        "Yunfeng Yan",
        "Junbo Zhao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 02:39:36+00:00",
      "link": "https://arxiv.org/pdf/2601.15593v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15578v1",
      "title": "MapViT: A Two-Stage ViT-Based Framework for Real-Time Radio Quality Map Prediction in Dynamic Environments",
      "abstract": "Recent advancements in mobile and wireless networks are unlocking the full potential of robotic autonomy, enabling robots to take advantage of ultra-low latency, high data throughput, and ubiquitous connectivity. However, for robots to navigate and operate seamlessly, efficiently and reliably, they must have an accurate understanding of both their surrounding environment and the quality of radio signals. Achieving this in highly dynamic and ever-changing environments remains a challenging and largely unsolved problem. In this paper, we introduce MapViT, a two-stage Vision Transformer (ViT)-based framework inspired by the success of pre-train and fine-tune paradigm for Large Language Models (LLMs). MapViT is designed to predict both environmental changes and expected radio signal quality. We evaluate the framework using a set of representative Machine Learning (ML) models, analyzing their respective strengths and limitations across different scenarios. Experimental results demonstrate that the proposed two-stage pipeline enables real-time prediction, with the ViT-based implementation achieving a strong balance between accuracy and computational efficiency. This makes MapViT a promising solution for energy- and resource-constrained platforms such as mobile robots. Moreover, the geometry foundation model derived from the self-supervised pre-training stage improves data efficiency and transferability, enabling effective downstream predictions even with limited labeled data. Overall, this work lays the foundation for next-generation digital twin ecosystems, and it paves the way for a new class of ML foundation models driving multi-modal intelligence in future 6G-enabled systems.",
      "authors": [
        "Cyril Shih-Huan Hsu",
        "Xi Li",
        "Lanfranco Zanzi",
        "Zhiheng Yang",
        "Chrysa Papagianni",
        "Xavier Costa Pérez"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-22 01:57:48+00:00",
      "link": "https://arxiv.org/pdf/2601.15578v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15563v1",
      "title": "Stabilizing Welfare-Maximizing Decisions via Endogenous Transfers",
      "abstract": "Many multiagent systems rely on collective decision-making among self-interested agents, which raises deep questions about coalition formation and stability. We study social choice with endogenous, outcome-contingent transfers, where agents voluntarily form contracts that redistribute utility depending on the collective decision, allowing fully strategic, incentive-aligned coalition formation. We show that under consensus rules, individually rational strong Nash equilibria (IR-SNE) always exist, implementing welfare-maximizing outcomes with feasible transfers, and provide a simple, efficient algorithm to construct them. For more general anonymous, monotonic, and resolute rules, we identify necessary conditions for profitable deviations, sharply limiting destabilizing coalitions. By bridging cooperative and noncooperative perspectives, our approach shows that transferable utility can achieve core-like stability, restoring efficiency and budget balance even where classical impossibility results apply. Overall, this framework offers a practical and robust way to coordinate large-scale strategic multiagent systems.",
      "authors": [
        "Joshua Kavner"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH",
        "cs.GT"
      ],
      "published": "2026-01-22 01:05:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15563v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15561v1",
      "title": "Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems",
      "abstract": "This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.",
      "authors": [
        "Naoya Onizawa",
        "Takahiro Hanyu"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.LG"
      ],
      "published": "2026-01-22 01:01:35+00:00",
      "link": "https://arxiv.org/pdf/2601.15561v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15552v1",
      "title": "BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations",
      "abstract": "We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.",
      "authors": [
        "Phuc Nguyen",
        "Benjamin Zelditch",
        "Joyce Chen",
        "Rohit Patra",
        "Changshuai Wei"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-22 00:48:45+00:00",
      "link": "https://arxiv.org/pdf/2601.15552v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15539v1",
      "title": "A Machine Vision Approach to Preliminary Skin Lesion Assessments",
      "abstract": "Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.",
      "authors": [
        "Ali Khreis",
        "Ro'Yah Radaideh",
        "Quinn McGill"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-21 23:48:59+00:00",
      "link": "https://arxiv.org/pdf/2601.15539v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15532v1",
      "title": "Resource Allocation and Sharing for UAV-Assisted Integrated TN-NTN with Multi-Connectivity",
      "abstract": "Unmanned aerial vehicles (UAVs) with multi- connectivity (MC) capabilities efficiently and reliably transfer data between terrestrial networks (TNs) and non-terrestrial networks (NTNs). However, optimally sharing and allocating spectrum and power resources to maintain MC while ensuring reliable connectivity and optimal performance remains challeng- ing in such networks. Channel variations induced by mobility in UAV networks, coupled with the varying quality of service (QoS) demands of heterogeneous devices, resource sharing, and fairness requirements in capacity distribution pose challenges to optimal resource allocation. Thus, this paper investigates resource allocation for QoS-constrained, MC-enabled, dynamic UAVs in an integrated TN-NTN environment with spectrum sharing and fairness considerations. To this end, we consider three types of links: UAV-to-radio base station (RBS), UAV-to-UAV, and UAV-to-HAP. We also assume two types of UAVs with diverse QoS requirements to reflect a practical scenario. Consequently, we propose two algorithms. The first algorithm maximizes the capacity of UAVs-RBS and UAVs-HAP links while ensuring the reliability of the UAV-UAV link. To achieve this, the algorithm maximizes the collective throughput of the UAVs by optimizing the sum capacity of all the UAV-RBS and UAV-HAP links. Next, to provide constant capacity to all links and ensure fairness, we propose another algorithm that maximizes the minimum capacity across all links. We validate the performance of both algorithms through simulation",
      "authors": [
        "Abd Ullah Khan",
        "Wali Ullah Khan",
        "Haejoon Jung",
        "Hyundong Shin"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-21 23:34:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15532v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15528v1",
      "title": "Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform",
      "abstract": "Large Language Model (LLM)-based question-answering systems offer significant potential for automating customer support and internal knowledge access in small businesses, yet their practical deployment remains challenging due to infrastructure costs, engineering complexity, and security risks, particularly in retrieval-augmented generation (RAG)-based settings. This paper presents an industry case study of an open-source, multi-tenant platform that enables small businesses to deploy customised LLM-based support chatbots via a no-code workflow. The platform is built on distributed, lightweight k3s clusters spanning heterogeneous, low-cost machines and interconnected through an encrypted overlay network, enabling cost-efficient resource pooling while enforcing container-based isolation and per-tenant data access controls. In addition, the platform integrates practical, platform-level defences against prompt injection attacks in RAG-based chatbots, translating insights from recent prompt injection research into deployable security mechanisms without requiring model retraining or enterprise-scale infrastructure. We evaluate the proposed platform through a real-world e-commerce deployment, demonstrating that secure and efficient LLM-based chatbot services can be achieved under realistic cost, operational, and security constraints faced by small businesses.",
      "authors": [
        "Jiazhu Xie",
        "Bowen Li",
        "Heyu Fu",
        "Chong Gao",
        "Ziqi Xu",
        "Fengling Han"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.CR"
      ],
      "published": "2026-01-21 23:29:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15528v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15505v1",
      "title": "Stabilizer-Code Channel Transforms Beyond Repetition Codes for Improved Hashing Bounds",
      "abstract": "The quantum hashing bound guarantees that rates up to $1-H(p_I, p_X, p_Y, p_Z)$ are achievable for memoryless Pauli channels, but it is not generally tight. A known way to improve achievable rates for certain asymmetric Pauli channels is to apply a small inner stabilizer code to a few channel uses, decode, and treat the resulting logical noise as an induced Pauli channel; reapplying the hashing argument to this induced channel can beat the baseline hashing bound. We generalize this induced-channel viewpoint to arbitrary stabilizer codes used purely as channel transforms. Given any $ [\\![ n, k ]\\!] $ stabilizer generator set, we construct a full symplectic tableau, compute the induced joint distribution of logical Pauli errors and syndromes under the physical Pauli channel, and obtain an achievable rate via a hashing bound with decoder side information. We perform a structured search over small transforms and report instances that improve the baseline hashing bound for a family of Pauli channels with skewed and independent errors studied in prior work.",
      "authors": [
        "Tyler Kann",
        "Matthieu R. Bloch",
        "Shrinivas Kudekar",
        "Ruediger Urbanke"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "quant-ph"
      ],
      "published": "2026-01-21 22:24:46+00:00",
      "link": "https://arxiv.org/pdf/2601.15505v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15488v1",
      "title": "Multi-Persona Thinking for Bias Mitigation in Large Language Models",
      "abstract": "Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.",
      "authors": [
        "Yuxing Chen",
        "Guoqing Luo",
        "Zijun Wu",
        "Lili Mou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-21 21:40:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15488v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15487v1",
      "title": "MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation",
      "abstract": "The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.",
      "authors": [
        "Chandan Kumar Sahu",
        "Premith Kumar Chilukuri",
        "Matthew Hetrich"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "published": "2026-01-21 21:39:09+00:00",
      "link": "https://arxiv.org/pdf/2601.15487v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15486v1",
      "title": "A Universal Large Language Model -- Drone Command and Control Interface",
      "abstract": "The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.",
      "authors": [
        "Javier N. Ramos-Silva",
        "Peter J. Burke"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-21 21:37:54+00:00",
      "link": "https://arxiv.org/pdf/2601.15486v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15485v1",
      "title": "The Rise of Large Language Models and the Direction and Impact of US Federal Research Funding",
      "abstract": "Federal research funding shapes the direction, diversity, and impact of the US scientific enterprise. Large language models (LLMs) are rapidly diffusing into scientific practice, holding substantial promise while raising widespread concerns. Despite growing attention to AI use in scientific writing and evaluation, little is known about how the rise of LLMs is reshaping the public funding landscape. Here, we examine LLM involvement at key stages of the federal funding pipeline by combining two complementary data sources: confidential National Science Foundation (NSF) and National Institutes of Health (NIH) proposal submissions from two large US R1 universities, including funded, unfunded, and pending proposals, and the full population of publicly released NSF and NIH awards. We find that LLM use rises sharply beginning in 2023 and exhibits a bimodal distribution, indicating a clear split between minimal and substantive use. Across both private submissions and public awards, higher LLM involvement is consistently associated with lower semantic distinctiveness, positioning projects closer to recently funded work within the same agency. The consequences of this shift are agency-dependent. LLM use is positively associated with proposal success and higher subsequent publication output at NIH, whereas no comparable associations are observed at NSF. Notably, the productivity gains at NIH are concentrated in non-hit papers rather than the most highly cited work. Together, these findings provide large-scale evidence that the rise of LLMs is reshaping how scientific ideas are positioned, selected, and translated into publicly funded research, with implications for portfolio governance, research diversity, and the long-run impact of science.",
      "authors": [
        "Yifan Qian",
        "Zhe Wen",
        "Alexander C. Furnas",
        "Yue Bai",
        "Erzhuo Shao",
        "Dashun Wang"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "published": "2026-01-21 21:37:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15485v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15482v1",
      "title": "Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding",
      "abstract": "Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.",
      "authors": [
        "Huayu Li",
        "ZhengXiao He",
        "Siyuan Tian",
        "Jinghao Wen",
        "Ao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 21:34:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15482v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15481v1",
      "title": "Early predicting of hospital admission using machine learning algorithms: Priority queues approach",
      "abstract": "Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.",
      "authors": [
        "Jakub Antczak",
        "James Montgomery",
        "Małgorzata O'Reilly",
        "Zbigniew Palmowski",
        "Richard Turner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-21 21:31:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15481v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15470v1",
      "title": "Nested and outlier embeddings into trees",
      "abstract": "In this paper, we consider outlier embeddings into HSTs and ultrametrics. In particular, for $(X,d)$, let $k$ be the size of the smallest subset of $X$ such that all but that subset (i.e. the ``outlier set'') can be probabilistically embedded into the space of HSTs with expected distortion at most $c$. Our primary result is showing that there exists an efficient algorithm that takes in $(X,d)$ and a target distortion $c$ and samples from a probabilistic embedding with at most $O(\\frac k ε\\log^2k)$ outliers and distortion at most $(32+ε)c$, for any $ε>0$. This leads to better instance-specific approximations for certain instances of the buy-at-bulk and dial-a-ride problems, whose current best approximation algorithms go through HST embeddings.   In order to facilitate our results, we largely focus on the concept of compositions of nested embeddings introduced by [Chawla and Sheridan 2024]. A nested embedding is a composition of two embeddings of a metric space $(X,d)$ -- a low distortion embedding of a subset $S$ of nodes, and a higher distortion embedding of the entire metric. The composition is a single embedding that preserves the low distortion over $S$ and does not increase distortion over the remaining points by much. In this paper, we expand this concept from the setting of deterministic embeddings to the setting of probabilistic embeddings. We show how to find good nested compositions of embeddings into HSTs, and combine this with an approximation algorithm of [Munagala et al. 2023] to obtain our results.",
      "authors": [
        "Shuchi Chawla",
        "Kristin Sheridan"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-21 21:09:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15470v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15468v1",
      "title": "Learning from Synthetic Data: Limitations of ERM",
      "abstract": "The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.   We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.",
      "authors": [
        "Kareem Amin",
        "Alex Bie",
        "Weiwei Kong",
        "Umar Syed",
        "Sergei Vassilvitskii"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DS",
        "stat.ML"
      ],
      "published": "2026-01-21 21:07:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15468v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15465v1",
      "title": "Cloning the Self for Mental Well-Being: A Framework for Designing Safe and Therapeutic Self-Clone Chatbots",
      "abstract": "As digital tools increasingly mediate mental health care, self-clone chatbots can offer a uniquely novel approach to intra-personal exploration and self-derived support. Trained to replicate users' conversational patterns, self-clones allow users to talk to themselves through their digital replicas. Despite the promises, these systems may carry risks around identity confusion, negative reinforcement, and blurred user agency. Through interviews with 16 mental health professionals and 6 general users, we aim to uncover tensions and design opportunities in this emerging space to guide responsible self-clone design. Our analysis produces a design framework organized around three priorities: (1) defining goals and grounding the approach in existing therapeutic models, (2) design dimensions including the self-clone persona and user-clone relationship dynamics, and (3) considerations for minimizing potential emotional and ethical harms. This framework contributes an interdisciplinary foundation for designing self-clone chatbots as AI-mediated self-interaction tools that are emotionally and ethically attuned in mental health contexts.",
      "authors": [
        "Mehrnoosh Sadat Shirvani",
        "Jackie Crowley",
        "Cher Peng",
        "Jackie Liu",
        "Thomas Chao",
        "Suky Martinez",
        "Laura Brandt",
        "Ig-Jae Kim",
        "Dongwook Yoon"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-21 21:03:22+00:00",
      "link": "https://arxiv.org/pdf/2601.15465v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15458v1",
      "title": "MuSAlS: A Fast Multiple Sequence Alignment Approach Using Hierarchical Clustering",
      "abstract": "Motivation: The multiple sequence alignment (MSA) problem has been extensively studied, with numerous approaches developed over recent years. With the rapid growth of sequence data, there is an increasing need for fast and accurate MSA tools that scale effectively to large datasets. Building on our previous work on CLAM, we are able to use exact dynamic programming (Needleman-Wunsch) while scaling to large datasets. We introduce MuSAlS (Multiple Sequence Alignment at Scale), a fast and scalable de novo MSA aligner. MuSAlS uses hierarchical clustering to construct a guide tree based on the Levenshtein distance metric, enabling efficient and accurate alignment through a bottom-up approach. Results: MuSAlS achieves competitive accuracy compared to state-of-the-art methods while significantly improving runtime performance. This makes it a valuable tool for researchers analyzing large-scale genomic and metagenomic datasets, addressing the growing demand for scalable bioinformatics solutions. Availability and Implementation: MuSAlS is implemented in the Rust programming language, and available at https://github.com/URI-ABD/clam",
      "authors": [
        "Emily G. Light",
        "Morgan Prior",
        "Noah M. Daniels",
        "Najib Ishaq"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-21 20:54:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15458v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15455v1",
      "title": "Remarks on Algebraic Reconstruction of Types and Effects",
      "abstract": "In their 1991 paper \"Algebraic Reconstruction of Types and Effects,\" Pierre Jouvelot and David Gifford presented a type-and-effect reconstruction algorithm based on an algebraic structure of effects. Their work is considered a milestone in the development of type-and-effect systems, and has inspired numerous subsequent works in the area of static analysis. However, unlike the later research it spawned, the original algorithm considered a language with higher-rank polymorphism, a feature which is challenging to implement correctly. In this note, we identify subtle bugs related to variable binding in their approach to this feature. We revisit their type system and reconstruction algorithm, and describe the discovered issues.",
      "authors": [
        "Patrycja Balik",
        "Szymon Jędras",
        "Piotr Polesiuk"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-01-21 20:50:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15455v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15445v1",
      "title": "Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation",
      "abstract": "Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.",
      "authors": [
        "Runlong Ye",
        "Oliver Huang",
        "Patrick Yung Kang Lee",
        "Michael Liut",
        "Carolina Nobre",
        "Ha-Kyung Kong"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-01-21 20:24:39+00:00",
      "link": "https://arxiv.org/pdf/2601.15445v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15437v1",
      "title": "Exploring Implicit Perspectives on Autism in Large Language Models Through Multi-Agent Simulations",
      "abstract": "Large Language Models (LLMs) like ChatGPT offer potential support for autistic people, but this potential requires understanding the implicit perspectives these models might carry, including their biases and assumptions about autism. Moving beyond single-agent prompting, we utilized LLM-based multi-agent systems to investigate complex social scenarios involving autistic and non-autistic agents. In our study, agents engaged in group-task conversations and answered structured interview questions, which we analyzed to examine ChatGPT's biases and how it conceptualizes autism. We found that ChatGPT assumes autistic people are socially dependent, which may affect how it interacts with autistic users or conveys information about autism. To address these challenges, we propose adopting the double empathy problem, which reframes communication breakdowns as a mutual challenge. We describe how future LLMs could address the biases we observed and improve interactions involving autistic people by incorporating the double empathy problem into their design.",
      "authors": [
        "Sohyeon Park",
        "Jesus Armando Beltran",
        "Aehong Min",
        "Anamara Ritt-Olson",
        "Gillian R. Hayes"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-21 20:04:54+00:00",
      "link": "https://arxiv.org/pdf/2601.15437v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15434v1",
      "title": "ManuRAG: Multi-modal Retrieval Augmented Generation for Manufacturing Question Answering",
      "abstract": "The evolution of digital manufacturing requires intelligent Question Answering (QA) systems that can seamlessly integrate and analyze complex multi-modal data, such as text, images, formulas, and tables. Conventional Retrieval Augmented Generation (RAG) methods often fall short in handling this complexity, resulting in subpar performance. We introduce ManuRAG, an innovative multi-modal RAG framework designed for manufacturing QA, incorporating specialized techniques to improve answer accuracy, reliability, and interpretability. To benchmark performance, we evaluate ManuRAG on three datasets comprising a total of 1,515 QA pairs, corresponding to mathematical, multiple-choice, and review-based questions in manufacturing principles and practices. Experimental results show that ManuRAG consistently outperforms existing methods across all evaluated datasets. Furthermore, ManuRAG's adaptable design makes it applicable to other domains, including law, healthcare, and finance, positioning it as a versatile tool for domain-specific QA.",
      "authors": [
        "Yunqing Li",
        "Zihan Dong",
        "Farhad Ameri",
        "Jianbang Zhang"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-21 19:59:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15434v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15422v1",
      "title": "ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks",
      "abstract": "In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.",
      "authors": [
        "Berk Ciloglu",
        "Ozgun Ersoy",
        "Metin Ozturk",
        "Ali Gorcin"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.ET"
      ],
      "published": "2026-01-21 19:33:00+00:00",
      "link": "https://arxiv.org/pdf/2601.15422v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15417v1",
      "title": "Ambient Dataloops: Generative Models for Dataset Refinement",
      "abstract": "We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.",
      "authors": [
        "Adrián Rodríguez-Muñoz",
        "William Daspit",
        "Adam Klivans",
        "Antonio Torralba",
        "Constantinos Daskalakis",
        "Giannis Daras"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 19:29:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15417v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15401v1",
      "title": "Multi-Input Ciphertext Multiplication for Homomorphic Encryption",
      "abstract": "Homomorphic encryption (HE) enables arithmetic operations to be performed directly on encrypted data. It is essential for privacy-preserving applications such as machine learning, medical diagnosis, and financial data analysis. In popular HE schemes, ciphertext multiplication is only defined for two inputs. However, the multiplication of multiple inputs is needed in many HE applications. In our previous work, a three-input ciphertext multiplication method for the CKKS HE scheme was developed. This paper first reformulates the three-input ciphertext multiplication to enable the combination of computations in order to further reduce the complexity. The second contribution is extending the multiplication to multiple inputs without compromising the noise overhead. Additional evaluation keys are introduced to achieve relinearization of polynomial multiplication results. To minimize the complexity of the large number of rescaling units in the multiplier, a theoretical analysis is developed to relocate the rescaling, and a multi-level rescaling approach is proposed to implement combined rescaling with complexity similar to that of a single rescaling unit. Guidelines and examples are provided on the input partition to enable the combination of more rescaling. Additionally, efficient hardware architectures are designed to implement our proposed multipliers. The improved three-input ciphertext multiplier reduces the logic area and latency by 15% and 50%, respectively, compared to the best prior design. For multipliers with more inputs, ranging from 4 to 12, the architectural analysis reveals 32% savings in area and 45% shorter latency, on average, compared to prior work.",
      "authors": [
        "Sajjad Akherati",
        "Xinmiao Zhang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-21 19:13:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15401v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15399v1",
      "title": "Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC",
      "abstract": "High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this complex decision. Our core hypothesis is that surrogate models informed by attention-based embeddings of job telemetry can capture performance dynamics more effectively than standard regression techniques. We pair this with an intelligent sample acquisition strategy to ensure the approach is data-efficient. On two production HPC datasets, our embedding-informed method consistently identified higher-quality Pareto fronts of runtime-power trade-offs compared to baselines. Furthermore, our intelligent data sampling strategy drastically reduced training costs while improving the stability of the results. To our knowledge, this is the first work to successfully apply embedding-informed surrogates in a MOBO framework to the HPC scheduling problem, jointly optimizing for performance and power on production workloads.",
      "authors": [
        "Ashna Nawar Ahmed",
        "Banooqa Banday",
        "Terry Jones",
        "Tanzima Z. Islam"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21 19:11:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15399v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15393v1",
      "title": "The computational two-way quantum capacity",
      "abstract": "Quantum channel capacities are fundamental to quantum information theory. Their definition, however, does not limit the computational resources of sender and receiver. In this work, we initiate the study of computational quantum capacities. These quantify how much information can be reliably transmitted when imposing the natural requirement that en- and decoding have to be computationally efficient. We focus on the computational two-way quantum capacity and showcase that it is closely related to the computational distillable entanglement of the Choi state of the channel. This connection allows us to show a stark computational capacity separation. Under standard cryptographic assumptions, there exists a quantum channel of polynomial complexity whose computational two-way quantum capacity vanishes while its unbounded counterpart is nearly maximal. More so, we show that there exists a sharp transition in computational quantum capacity from nearly maximal to zero when the channel complexity leaves the polynomial realm. Our results demonstrate that the natural requirement of computational efficiency can radically alter the limits of quantum communication.",
      "authors": [
        "Johannes Jakob Meyer",
        "Jacopo Rizzo",
        "Asad Raza",
        "Lorenzo Leone",
        "Sofiene Jerbi",
        "Jens Eisert"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.CC",
        "cs.CR",
        "cs.IT"
      ],
      "published": "2026-01-21 19:04:07+00:00",
      "link": "https://arxiv.org/pdf/2601.15393v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15282v1",
      "title": "Rethinking Video Generation Model for the Embodied World",
      "abstract": "Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments. It assesses both task-level correctness and visual fidelity through reproducible sub-metrics, including structural consistency, physical plausibility, and action completeness. Evaluation of 25 representative models highlights significant deficiencies in generating physically realistic robot behaviors. Furthermore, the benchmark achieves a Spearman correlation coefficient of 0.96 with human evaluations, validating its effectiveness. While RBench provides the necessary lens to identify these deficiencies, achieving physical realism requires moving beyond evaluation to address the critical shortage of high-quality training data. Driven by these insights, we introduce a refined four-stage data pipeline, resulting in RoVid-X, the largest open-source robotic dataset for video generation with 4 million annotated video clips, covering thousands of tasks and enriched with comprehensive physical property annotations. Collectively, this synergistic ecosystem of evaluation and data establishes a robust foundation for rigorous assessment and scalable training of video models, accelerating the evolution of embodied AI toward general intelligence.",
      "authors": [
        "Yufan Deng",
        "Zilin Pan",
        "Hongyu Zhang",
        "Xiaojie Li",
        "Ruoqing Hu",
        "Yufei Ding",
        "Yiming Zou",
        "Yan Zeng",
        "Daquan Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-21 18:59:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15282v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15269v1",
      "title": "Lightweight LLMs for Network Attack Detection in IoT Networks",
      "abstract": "The rapid growth of Internet of Things (IoT) devices has increased the scale and diversity of cyberattacks, exposing limitations in traditional intrusion detection systems. Classical machine learning (ML) models such as Random Forest and Support Vector Machine perform well on known attacks but require retraining to detect unseen or zero-day threats. This study investigates lightweight decoder-only Large Language Models (LLMs) for IoT attack detection by integrating structured-to-text conversion, Quantized Low-Rank Adaptation (QLoRA) fine-tuning, and Retrieval-Augmented Generation (RAG). Network traffic features are transformed into compact natural-language prompts, enabling efficient adaptation under constrained hardware. Experiments on the CICIoT2023 dataset show that a QLoRA-tuned LLaMA-1B model achieves an F1-score of 0.7124, comparable to the Random Forest (RF) baseline (0.7159) for known attacks. With RAG, the system attains 42.63% accuracy on unseen attack types without additional training, demonstrating practical zero-shot capability. These results highlight the potential of retrieval-enhanced lightweight LLMs as adaptable and resource-efficient solutions for next-generation IoT intrusion detection.",
      "authors": [
        "Piyumi Bhagya Sudasinghe",
        "Kushan Sudheera Kalupahana Liyanage",
        "Harsha S. Gardiyawasam Pussewalage"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-21 18:52:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15269v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15260v1",
      "title": "DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration",
      "abstract": "Perception is a cornerstone of autonomous driving, enabling vehicles to understand their surroundings and make safe, reliable decisions. Developing robust perception algorithms requires large-scale, high-quality datasets that cover diverse driving conditions and support thorough evaluation. Existing datasets often lack a high-fidelity digital twin, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real evaluations. To address this gap, we present DrivIng, a large-scale multimodal dataset with a complete geo-referenced digital twin of a ~18 km route spanning urban, suburban, and highway segments. Our dataset provides continuous recordings from six RGB cameras, one LiDAR, and high-precision ADMA-based localization, captured across day, dusk, and night. All sequences are annotated at 10 Hz with 3D bounding boxes and track IDs across 12 classes, yielding ~1.2 million annotated instances. Alongside the benefits of a digital twin, DrivIng enables a 1-to-1 transfer of real traffic into simulation, preserving agent interactions while enabling realistic and flexible scenario testing. To support reproducible research and robust validation, we benchmark DrivIng with state-of-the-art perception models and publicly release the dataset, digital twin, HD map, and codebase.",
      "authors": [
        "Dominik Rößle",
        "Xujun Xie",
        "Adithya Mohan",
        "Venkatesh Thirugnana Sambandham",
        "Daniel Cremers",
        "Torsten Schön"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-21 18:41:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15260v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15236v1",
      "title": "Metadata Conditioned Large Language Models for Localization",
      "abstract": "Large language models are typically trained by treating text as a single global distribution, often resulting in geographically homogenized behavior. We study metadata conditioning as a lightweight approach for localization, pre-training 31 models (at 0.5B and 1B parameter scales) from scratch on large-scale English news data annotated with verified URLs, country tags, and continent tags, covering 4 continents and 17 countries. Across four controlled experiments, we show that metadata conditioning consistently improves in-region performance without sacrificing cross-region generalization, enables global models to recover localization comparable to region-specific models, and improves learning efficiency. Our ablation studies demonstrate that URL-level metadata alone captures much of the geographic signal, while balanced regional data coverage remains essential, as metadata cannot fully compensate for missing regions. Finally, we introduce a downstream benchmark of 800 localized news MCQs and show that after instruction tuning, metadata conditioned global models achieve accuracy comparable to LLaMA-3.2-1B-Instruct, despite being trained on substantially less data. Together, these results establish metadata conditioning as a practical and compute-efficient approach for localization of language models.",
      "authors": [
        "Anjishnu Mukherjee",
        "Ziwei Zhu",
        "Antonios Anastasopoulos"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-21 18:20:59+00:00",
      "link": "https://arxiv.org/pdf/2601.15236v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15235v1",
      "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification",
      "abstract": "Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.",
      "authors": [
        "Fabi Nahian Madhurja",
        "Rusab Sarmun",
        "Muhammad E. H. Chowdhury",
        "Adam Mushtak",
        "Israa Al-Hashimi",
        "Sohaib Bassam Zoghoul"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-21 18:15:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15235v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15232v1",
      "title": "When Agents Fail: A Comprehensive Study of Bugs in LLM Agents with Automated Labeling",
      "abstract": "Large Language Models (LLMs) have revolutionized intelligent application development. While standalone LLMs cannot perform any actions, LLM agents address the limitation by integrating tools. However, debugging LLM agents is difficult and costly as the field is still in it's early stage and the community is underdeveloped. To understand the bugs encountered during agent development, we present the first comprehensive study of bug types, root causes, and effects in LLM agent-based software. We collected and analyzed 1,187 bug-related posts and code snippets from Stack Overflow, GitHub, and Hugging Face forums, focused on LLM agents built with seven widely used LLM frameworks as well as custom implementations. For a deeper analysis, we have also studied the component where the bug occurred, along with the programming language and framework. This study also investigates the feasibility of automating bug identification. For that, we have built a ReAct agent named BugReAct, equipped with adequate external tools to determine whether it can detect and annotate the bugs in our dataset. According to our study, we found that BugReAct equipped with Gemini 2.5 Flash achieved a remarkable performance in annotating bug characteristics with an average cost of 0.01 USD per post/code snippet.",
      "authors": [
        "Niful Islam",
        "Ragib Shahriar Ayon",
        "Deepak George Thomas",
        "Shibbir Ahmed",
        "Mohammad Wardat"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-21 18:13:10+00:00",
      "link": "https://arxiv.org/pdf/2601.15232v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15212v1",
      "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization",
      "abstract": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.",
      "authors": [
        "Dhrubo Saha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-21 17:36:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15212v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15194v1",
      "title": "Entropy of Soft Random Geometric Graphs in General Geometries",
      "abstract": "We study the effect of the choice of embedding geometry on the entropy of random geometric graph ensembles with soft connection functions. First we show that when the connection range is small, the entropy is dependent only on the dimension of the geometry and not the shape, but for large connection ranges the boundaries of the domain matter. Next, we formulate the problem of estimating entropy as a problem of estimating the average degree of a graph with the binary entropy function as its connection function. We use this formulation to study the effect of boundaries on the entropy, and to estimate the entropy of soft random geometric graphs in complicated geometries where a closed form pair distance density is not available.",
      "authors": [
        "Oliver Baker",
        "Carl P. Dettmann"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "cond-mat.stat-mech",
        "cs.IT"
      ],
      "published": "2026-01-21 17:11:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15194v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15188v1",
      "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback",
      "abstract": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.",
      "authors": [
        "Stephan Wallraven",
        "Tim Köhne",
        "Hartmut Westenberger",
        "Andreas Moser"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "published": "2026-01-21 17:06:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15188v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15178v1",
      "title": "Complexity analysis and practical resolution of the data classification problem with private characteristics",
      "abstract": "In this work we analyze the problem of, given the probability distribution of a population, questioning an unknown individual that is representative of the distribution so that our uncertainty about certain characteristics is significantly reduced -but the uncertainty about others, deemed private or sensitive, is not. Thus, the goal of the problem is extracting information being relevant to a legitimate purpose while preserving the privacy of individuals, which is crucial to enable non-intrusive selection processes in several areas. For instance, it is essential in the design of non-discriminatory personnel selection, promotion, and layoff processes in companies and institutions; in the retrieval of customer information being relevant to the service provided by a company (and no more); in certifications not revealing sensitive industrial information being irrelevant for the certification itself; etc. Interactive questioning processes are constructed for this purpose, which requires generalizing the notion of decision trees to account the amount of desired and undesired information retrieved for each branch of the plan. Our findings about this problem are both theoretical and practical: on the one hand, we prove its NP-completeness by a reduction from the Set Cover problem; and on the other hand, given this intractability, we provide heuristic solutions to find reasonable solutions in affordable time. In particular, a greedy algorithm and two genetic algorithms are presented. Our experiments indicate that the best results are obtained using a genetic algorithm reinforced with a greedy strategy.",
      "authors": [
        "David Pantoja",
        "Ismael Rodriguez",
        "Fernando Rubio",
        "Clara Segura"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC"
      ],
      "published": "2026-01-21 16:55:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15178v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15177v1",
      "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
      "abstract": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.",
      "authors": [
        "Lorenzo Fernández Maimó",
        "Alberto Huertas Celdrán",
        "Manuel Gil Pérez",
        "Félix J. García Clemente",
        "Gregorio Martínez Pérez"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "published": "2026-01-21 16:54:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15177v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15172v1",
      "title": "Is Peer Review Really in Decline? Analyzing Review Quality across Venues and Time",
      "abstract": "Peer review is at the heart of modern science. As submission numbers rise and research communities grow, the decline in review quality is a popular narrative and a common concern. Yet, is it true? Review quality is difficult to measure, and the ongoing evolution of reviewing practices makes it hard to compare reviews across venues and time. To address this, we introduce a new framework for evidence-based comparative study of review quality and apply it to major AI and machine learning conferences: ICLR, NeurIPS and *ACL. We document the diversity of review formats and introduce a new approach to review standardization. We propose a multi-dimensional schema for quantifying review quality as utility to editors and authors, coupled with both LLM-based and lightweight measurements. We study the relationships between measurements of review quality, and its evolution over time. Contradicting the popular narrative, our cross-temporal analysis reveals no consistent decline in median review quality across venues and years. We propose alternative explanations, and outline recommendations to facilitate future empirical studies of review quality.",
      "authors": [
        "Ilia Kuznetsov",
        "Rohan Nayak",
        "Alla Rozovskaya",
        "Iryna Gurevych"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-21 16:48:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15172v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15170v1",
      "title": "Large-Scale Multidimensional Knowledge Profiling of Scientific Literature",
      "abstract": "The rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature",
      "authors": [
        "Zhucun Xue",
        "Jiangning Zhang",
        "Juntao Jiang",
        "Jinzhuo Liu",
        "Haoyang He",
        "Teng Hu",
        "Xiaobin Hu",
        "Guangming Yao",
        "Yi Yuan",
        "Yong Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-21 16:47:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15170v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15167v1",
      "title": "DeGAS: Gradient-Based Optimization of Probabilistic Programs without Sampling",
      "abstract": "We present DeGAS, a differentiable Gaussian approximate semantics for loopless probabilistic programs that enables sample-free, gradient-based optimization in models with both continuous and discrete components. DeGAS evaluates programs under a Gaussian-mixture semantics and replaces measure-zero predicates and discrete branches with a vanishing smoothing, yielding closed-form expressions for posterior and path probabilities. We prove differentiability of these quantities with respect to program parameters, enabling end-to-end optimization via standard automatic differentiation, without Monte Carlo estimators. On thirteen benchmark programs, DeGAS achieves accuracy and runtime competitive with variational inference and MCMC. Importantly, it reliably tackles optimization problems where sampling-based baselines fail to converge due to conditioning involving continuous variables.",
      "authors": [
        "Francesca Randone",
        "Romina Doz",
        "Mirco Tribastone",
        "Luca Bortolussi"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-01-21 16:45:10+00:00",
      "link": "https://arxiv.org/pdf/2601.15167v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15161v1",
      "title": "Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems",
      "abstract": "Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.",
      "authors": [
        "Yinzhu Chen",
        "Abdine Maiga",
        "Hossein A. Rahmani",
        "Emine Yilmaz"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-21 16:40:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15161v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15366v1",
      "title": "AI-Based Culvert-Sewer Inspection",
      "abstract": "Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.   First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.",
      "authors": [
        "Christina Thrainer"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-21 16:33:33+00:00",
      "link": "https://arxiv.org/pdf/2601.15366v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15154v1",
      "title": "SAGA: Detecting Security Vulnerabilities Using Static Aspect Analysis",
      "abstract": "Python is one of the most popular programming languages; as such, projects written in Python involve an increasing number of diverse security vulnerabilities. However, existing state-of-the-art analysis tools for Python only support a few vulnerability types. Hence, there is a need to detect a large variety of vulnerabilities in Python projects.   In this paper, we propose the SAGA approach to detect and locate vulnerabilities in Python source code in a versatile way. SAGA includes a source code parser able to extract control- and data-flow information and to represent it as a symbolic control-flow graph, as well as a domain-specific language defining static aspects of the source code and their evolution during graph traversals. We have leveraged this language to define a library of static aspects for integrity, confidentiality, and other security-related properties.   We have evaluated SAGA on a dataset of 108 vulnerabilities, obtaining 100% sensitivity and 99.15% specificity, with only one false positive, while outperforming four common security analysis tools. This analysis was performed in less than 31 seconds, i.e., between 2.5 and 512.1 times faster than the baseline tools.",
      "authors": [
        "Yoann Marquer",
        "Domenico Bianculli",
        "Lionel C. Briand"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CR"
      ],
      "published": "2026-01-21 16:26:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15154v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15153v1",
      "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework",
      "abstract": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.",
      "authors": [
        "Choro Ulan uulu",
        "Mikhail Kulyabin",
        "Iris Fuhrmann",
        "Jan Joosten",
        "Nuno Miguel Martins Pacheco",
        "Filippos Petridis",
        "Rebecca Johnson",
        "Jan Bosch",
        "Helena Holmström Olsson"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-21 16:23:22+00:00",
      "link": "https://arxiv.org/pdf/2601.15153v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15151v1",
      "title": "Pipeline Automation Framework for Reusable High-throughput Network Applications on FPGA",
      "abstract": "In a context of ever-growing worldwide communication traffic, cloud service providers aim at deploying scalable infrastructures to address heterogeneous needs. Part of the network infrastructure, FPGAs are tailored to guarantee low-latency and high-throughput packet processing. However, slowness of the hardware design process impairs FPGA ability to be part of an agile infrastructure under constant evolution, from incident response to long-term transformation. Deploying and maintaining network functionalities across a wide variety of FPGAs raises the need to fine-tune hardware designs for several FPGA targets. To address this issue, we introduce PAF, an open-source architectural parameterization framework based on a pipeline-oriented design methodology. PAF (Pipeline Automation Framework) implementation is based on Chisel, a Scala-embedded Hardware Construction Language (HCL), that we leverage to interface with circuit elaboration. Applied to industrial network packet classification systems, PAF demonstrates efficient parameterization abilities, enabling to reuse and optimize the same pipelined design on several FPGAs. In addition, PAF focuses the pipeline description on the architectural intent, incidentally reducing the number of lines of code to express complex functionalities. Finally, PAF confirms that automation does not imply any loss of tight control on the architecture by achieving on par performance and resource usage with equivalent exhaustively described implementations.",
      "authors": [
        "Jean Bruant",
        "Pierre-Henri Horrein",
        "Olivier Muller",
        "Frédéric Pétrot"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-01-21 16:22:52+00:00",
      "link": "https://arxiv.org/pdf/2601.15151v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15146v1",
      "title": "A Real-Time Error Prevention System for Gaze-Based Interaction in Virtual Reality Based on Anomaly Detection",
      "abstract": "Gaze-based interaction enables intuitive, hands-free control in immersive environments, but remains susceptible to unintended inputs. We present a real-time error prevention system (EPS) that uses a temporal convolutional network autoencoder (TCNAE) to detect anomalies in gaze dynamics during selection tasks. In a visual search task in VR, 41 participants used three gaze-based methods - dwell time, gaze and head direction alignment, and nod - with and without EPS. The system reduced erroneous selections by up to 95% for dwell time and gaze and head, and was positively received by most users. Performance varied for nodding and between individuals, suggesting the need for adaptive systems. Objective metrics and subjective evaluations show that anomaly-based error prevention can improve gaze interfaces without disrupting interaction. These findings demonstrate the potential of anomaly-based error prevention for gaze interfaces and suggest applications in VR, AR, and assistive technologies.",
      "authors": [
        "Björn R. Severitt",
        "Yannick Sauer",
        "Nora Castner",
        "Siegfried Wahl"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-21 16:18:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15146v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15141v1",
      "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning",
      "abstract": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub",
      "authors": [
        "Tianshi Xu",
        "Yuteng Chen",
        "Meng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21 16:14:30+00:00",
      "link": "https://arxiv.org/pdf/2601.15141v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15139v1",
      "title": "Why Authors and Maintainers Link (or Don't Link) Their PyPI Libraries to Code Repositories and Donation Platforms",
      "abstract": "Metadata of libraries on the Python Package Index (PyPI)-including links to source code repositories and donation platforms-plays a critical role in supporting the transparency, trust, and sustainability of open-source libraries. Yet, many packages lack such metadata, and little is known about the underlying reasons. This paper presents a large-scale empirical study combining two targeted surveys sent to 50,000 PyPI authors and maintainers. We analyze more than 1,400 responses using large language model (LLM)-based topic modeling to uncover key motivations and barriers related to linking repositories and donation platforms. While repository URLs are often linked to foster collaboration, increase transparency, and enable issue tracking, some maintainers omit them due to oversight, laziness, or the perceived irrelevance to their project. Donation platform links are reported to support open source work or receive financial contributions, but are hindered by skepticism, technical friction, and organizational constraints. Cross-cutting challenges-such as outdated links, lack of awareness, and unclear guidance-affect both types of metadata. We further assess the robustness of our topic modeling pipeline across 30 runs (84% lexical and 89% semantic similarity) and validate topic quality with 23 expert raters (Randolph's kappa = 0.55). The study contributes empirical insights into PyPI's metadata practices and provides recommendations for improving them, while also demonstrating the effectiveness of our topic modeling approach for analyzing short-text survey responses.",
      "authors": [
        "Alexandros Tsakpinis",
        "Nicolas Raube",
        "Alexander Pretschner"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-21 16:13:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15139v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15131v1",
      "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding",
      "abstract": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.",
      "authors": [
        "Ayan Maity",
        "Sudeshna Sarkar"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-21 16:05:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15131v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15127v1",
      "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",
      "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS",
      "authors": [
        "Bostan Khan",
        "Masoud Daneshtalab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.DC"
      ],
      "published": "2026-01-21 16:03:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15127v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15124v1",
      "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation",
      "abstract": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.",
      "authors": [
        "Haonan Yuan",
        "Qingyun Sun",
        "Jiacheng Tao",
        "Xingcheng Fu",
        "Jianxin Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 16:02:43+00:00",
      "link": "https://arxiv.org/pdf/2601.15124v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15123v1",
      "title": "BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation",
      "abstract": "Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS.",
      "authors": [
        "Andrey Moskalenko",
        "Danil Kuznetsov",
        "Irina Dudko",
        "Anastasiia Iasakova",
        "Nikita Boldyrev",
        "Denis Shepelev",
        "Andrei Spiridonov",
        "Andrey Kuznetsov",
        "Vlad Shakhuro"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-01-21 16:02:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15123v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15114v1",
      "title": "From Who They Are to How They Act: Behavioral Traits in Generative Agent-Based Models of Social Media",
      "abstract": "Generative Agent-Based Modeling (GABM) leverages Large Language Models to create autonomous agents that simulate human behavior in social media environments, demonstrating potential for modeling information propagation, influence processes, and network phenomena. While existing frameworks characterize agents through demographic attributes, personality traits, and interests, they lack mechanisms to encode behavioral dispositions toward platform actions, causing agents to exhibit homogeneous engagement patterns rather than the differentiated participation styles observed on real platforms. In this paper, we investigate the role of behavioral traits as an explicit characterization layer to regulate agents' propensities across posting, re-sharing, commenting, reacting, and inactivity. Through large-scale simulations involving 980 agents and validation against real-world social media data, we demonstrate that behavioral traits are essential to sustain heterogeneous, profile-consistent participation patterns and enable realistic content propagation dynamics through the interplay of amplification- and interaction-oriented profiles. Our findings establish that modeling how agents act-not only who they are-is necessary for advancing GABM as a tool for studying social media phenomena.",
      "authors": [
        "Valerio La Gatta",
        "Gian Marco Orlando",
        "Marco Perillo",
        "Ferdinando Tammaro",
        "Vincenzo Moscato"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-01-21 15:51:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15114v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15104v1",
      "title": "A Myhill-Nerode Characterization and Active Learning for One-Clock Timed Automata",
      "abstract": "We present a Myhill-Nerode style characterization for languages recognized by one-clock deterministic timed automata (1-DTA). Although there is only one clock, distinct automata may reset it differently along the same word. This adds a significant challenge in the search for a canonical automaton. Our characterization is based on a new perspective of 1-DTAs in terms of \"half-integral\" words that they accept, along with the reset information encoded by them. We apply our results to develop L* style algorithms that learn the canonical 1-DTA.",
      "authors": [
        "Kyveli Doveri",
        "Pierre Ganty",
        "B. Srivathsan"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL",
        "cs.LO"
      ],
      "published": "2026-01-21 15:46:49+00:00",
      "link": "https://arxiv.org/pdf/2601.15104v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15098v1",
      "title": "Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction",
      "abstract": "As Micro-CT technology continues to refine its characterization of material microstructures, industrial CT ultra-precision inspection is generating increasingly large datasets, necessitating solutions to the trade-off between accuracy and efficiency in the 3D characterization of defects during ultra-precise detection. This article provides a unique perspective on recent advances in accurate and efficient 3D visualization using Micro-CT, tracing its evolution from medical imaging to industrial non-destructive testing (NDT). Among the numerous CT reconstruction and volume rendering methods, this article selectively reviews and analyzes approaches that balance accuracy and efficiency, offering a comprehensive analysis to help researchers quickly grasp highly efficient and accurate 3D reconstruction methods for microscopic features. By comparing the principles of computed tomography with advancements in microstructural technology, this article examines the evolution of CT reconstruction algorithms from analytical methods to deep learning techniques, as well as improvements in volume rendering algorithms, acceleration, and data reduction. Additionally, it explores advanced lighting models for high-accuracy, photorealistic, and efficient volume rendering. Furthermore, this article envisions potential directions in CT reconstruction and volume rendering. It aims to guide future research in quickly selecting efficient and precise methods and developing new ideas and approaches for real-time online monitoring of internal material defects through virtual-physical interaction, for applying digital twin model to structural health monitoring (SHM).",
      "authors": [
        "Yipeng Yin",
        "Rao Yao",
        "Qingying Li",
        "Dazhong Wang",
        "Hong Zhou",
        "Zhijun Fang",
        "Jianing Chen",
        "Longjie Qian",
        "Mingyue Wu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-21 15:37:38+00:00",
      "link": "https://arxiv.org/pdf/2601.15098v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15094v1",
      "title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks",
      "abstract": "Large Language Models (LLMs) have proven highly effective in automating software engineering tasks, bridging natural language and code semantics to achieve notable results in code generation and summarization. However, their scale incurs substantial computational costs, making full fine-tuning impractical. Parameter-Efficient Fine-Tuning (PEFT) methods like QLoRA enable efficient specialization with lower resource demands. Recent studies show QLoRA-optimized Large Code Models (LCMs) perform strongly across diverse tasks, yet it remains unclear whether this effectiveness persists when a single model is QLoRA fine-tuned for multiple code-related tasks. The interaction between Multi-task fine-tuning and QLoRA optimization, and how transfer learning affects correctness and quality of generated artifacts, remains largely unexplored. We investigate Multi-task QLoRA fine-tuning across three representative tasks: code generation, translation, and summarization. We evaluate functional correctness through execution-based and similarity-based metrics, complemented by comprehensive code quality analysis--an aspect largely overlooked in prior work. Our findings show that Multi-task QLoRA effectively leverages transfer learning, achieving competitive or superior performance relative to both Single-task QLoRA and Multi-task full fine-tuning. Larger models demonstrate more consistent balance between correctness and quality, whereas smaller models preserve functionality but exhibit a higher incidence of quality-related issues.",
      "authors": [
        "Md Zahidul Haque",
        "Saima Afrin",
        "Antonio Mastropaolo"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-21 15:33:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15094v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15091v1",
      "title": "Circadian Modulation of Semantic Exploration in Social Media Language",
      "abstract": "Human cognition exhibits strong circadian modulation, yet its influence on high-dimensional semantic behavior remains poorly understood. Using large-scale Reddit data, we quantify time-of-day variation in language use by embedding text into a pretrained transformer model and measuring semantic entropy as an index of linguistic exploration-exploitation, for which we show a robust circadian rhythmicity that could be entrained by seasonal light cues. Distinguishing between local and global semantic entropy reveals a systematic temporal dissociation: local semantic exploration peaks in the morning, reflecting broader exploration of semantic space, whereas global semantic diversity peaks later in the day as submissions accumulate around already established topics, consistent with \"rich-get-richer\" dynamics. These patterns are not explained by sentiment or affective valence, indicating that semantic exploration captures a cognitive dimension distinct from mood. The observed temporal structure aligns with known diurnal patterns in neuromodulatory systems, suggesting that biological circadian rhythms extend to the semantic domain.",
      "authors": [
        "Vuong Hung Truong",
        "Mariana Gabrielle Cangco Reyes",
        "Masatoshi Koizumi",
        "Jihwan Myung"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.SI",
        "q-bio.NC"
      ],
      "published": "2026-01-21 15:31:44+00:00",
      "link": "https://arxiv.org/pdf/2601.15091v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15079v1",
      "title": "LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training",
      "abstract": "Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.",
      "authors": [
        "Chenyu Liu",
        "Haige Li",
        "Luca Rossi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SI"
      ],
      "published": "2026-01-21 15:23:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15079v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15077v1",
      "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure",
      "abstract": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.",
      "authors": [
        "Christopher Scofield"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-21 15:23:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15077v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16193v1",
      "title": "Density-based structural frameworks for prime numbers, prime gaps, and Euler products",
      "abstract": "We develop a unified density-based framework for primality, coprimality, and prime pairs, and introduce an intrinsic normalized model for prime gaps constrained by the Prime Number Theorem. Within this setting, a structural tension between Hardy-Littlewood, Cramer, and PNT predictions emerges, leading to quantitative estimates on the rarity of extreme gaps. Additive representations of even integers are reformulated as local density problems, yielding non-conjectural upper and lower bounds compatible with Hardy-Littlewood heuristics. Finally, the Riemann zeta function is analyzed via truncated Euler products, whose stability and oscillatory structure provide a coherent interpretation of the critical line and prime-based numerical criteria for the localization of non-trivial zeros.",
      "authors": [
        "Gregorio Vettori"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "math.CV"
      ],
      "published": "2026-01-22 18:46:20+00:00",
      "link": "https://arxiv.org/pdf/2601.16193v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16122v1",
      "title": "Canonical structure of the LLG equation for exponential updates in micromagnetism",
      "abstract": "In this contribution we propose an exponential update algorithm for magnetic moments appearing in the framework of micromagnetics and the Landau-Lifshitz-Gilbert (LLG) equation. This algorithm can be interpreted as the geometric integration on spheres, that a priori satisfy the unit length constraint of the normalized magnetization vector. Even though the geometric structures for this are obvious and some works already use an exponential algorithm, to the best of the authors' knowledge, there is no canonical structure of the LLG equation for the exponential update algorithm in micromagnetism. Tensor algebraic reformulations of the LLG equation allow the canonical representation of the evolution equation for the magnetization, which serves as the basis for different integrators. Based on the specific structure of the exponential of skew symmetric matrices an efficient update scheme is derived. The excellent performance of the proposed exponential update algorithm is demonstrated in representative examples.",
      "authors": [
        "Jörg Schröder",
        "Maximilian Vorwerk"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-22 17:22:53+00:00",
      "link": "https://arxiv.org/pdf/2601.16122v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16110v1",
      "title": "Stability and Decay for the 2D Anisotropic Navier-Stokes Equations with Fractional Horizontal Dissipation on $\\mathbb{R}^2$",
      "abstract": "The stability problem for the 2D Navier-Stokes equations with dissipation in only one direction on $\\mathbb R^2$ is not fully understood. This dissipation is in the intermediate regime between the fully dissipative Navier-Stokes and the inviscid Euler. Navier-Stokes solutions in $\\mathbb R^2$ decay algebraically in time while Euler solutions can grow rather rapidly in time. This paper solves the fundamental stability and large-time behavior problem on the anisotropic Navier-Stokes with fractional dissipation $Λ_1^{2s}$ for all $0\\leq s<1$. The case $s=1$ corresponds to the standard one directional dissipation $\\partial_1^2$. Different techniques are developed to treat different ranges of fractional exponents: $0\\leq s\\leq \\frac34$, $\\frac34<s<\\frac{11}{12}$, and $\\frac{11}{12} \\leq s <1$. The final range is the most difficult case, for which we introduce the spatial polynomial $A_2$ weights and exploit the boundedness of Riesz transforms on weighted $L^2$-spaces.",
      "authors": [
        "Zhibin Wang",
        "Jiahong Wu",
        "Ning Zhu"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-22 16:57:08+00:00",
      "link": "https://arxiv.org/pdf/2601.16110v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16090v1",
      "title": "Birational automorphism groups in families of hyper-Kähler manifolds",
      "abstract": "We study the behavior of birational automorphism groups in families of projective hyper-Kähler manifolds.",
      "authors": [
        "Francesco Antonio Denisi",
        "Claudio Onorati",
        "Francesca Rizzo",
        "Sasha Viktorova"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-22 16:41:36+00:00",
      "link": "https://arxiv.org/pdf/2601.16090v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16043v1",
      "title": "A Second-Order Dynamical System for Solving Generalized Inverse Mixed Variational Inequality problems",
      "abstract": "In this paper, we study a class of generalized inverse mixed variational inequality problems (GIMVIPs). We propose a novel projection-based second-order time-varying dynamical system for solving GIMVIPs. Under the assumptions that the underlying operators are strongly monotone and Lipschitz continuous, we establish the existence and uniqueness of solution trajectories and prove their global exponential convergence to the unique solution of the GIMVIP. Furthermore, a discrete-time realization of the continuous dynamical system is developed, resulting in an inertial projection algorithm. We show that the proposed algorithm achieves linear convergence under suitable choices of parameters. Finally, numerical experiments are presented to illustrate the effectiveness and convergence behavior of the proposed method in solving GIMVIPs.",
      "authors": [
        "Nam Van Tran"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-22 15:18:46+00:00",
      "link": "https://arxiv.org/pdf/2601.16043v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16003v1",
      "title": "Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints",
      "abstract": "Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10μs, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines.",
      "authors": [
        "Yunan Wang",
        "Chuxiong Hu",
        "Zhao Jin"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "eess.SY"
      ],
      "published": "2026-01-22 14:28:37+00:00",
      "link": "https://arxiv.org/pdf/2601.16003v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15996v1",
      "title": "Minimax-optimal Halpern iterations for Lipschitz maps",
      "abstract": "This paper investigates the minimax-optimality of Halpern fixed-point iterations for Lipschitz maps in general normed spaces. Starting from an a priori bound on the orbit of iterates, we derive non-asymptotic estimates for the fixed-point residuals. These bounds are tight, meaning that they are attained by a suitable Lipschitz map and an associated Halpern sequence. By minimizing these tight bounds we identify the minimax-optimal Halpern scheme. For contractions, the optimal iteration exhibits a transition from an initial Halpern phase to the classical Banach-Picard iteration and, as the Lipschitz constant approaches one, we recover the known convergence rate for nonexpansive maps. For expansive maps, the algorithm is purely Halpern with no Banach-Picard phase; moreover, on bounded domains, the residual estimates converge to the minimal displacement bound. Inspired by the minimax-optimal iteration, we design an adaptive scheme whose residuals are uniformly smaller than the minimax-optimal bounds, and can be significantly sharper in practice. Finally, we extend the analysis by introducing alternative bounds based on the distance to a fixed point, which allow us to handle mappings on unbounded domains; including the case of affine maps for which we also identify the minimax-optimal iteration.",
      "authors": [
        "Mario Bravo",
        "Roberto Cominetti",
        "Jongmin Lee"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.ST"
      ],
      "published": "2026-01-22 14:17:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15996v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15970v1",
      "title": "Iteration complexity of the Difference-of-Convex Algorithm for unconstrained optimization: a simple proof",
      "abstract": "We propose a simple proof of the worst-case iteration complexity for the Difference of Convex functions Algorithm (DCA) for unconstrained minimization, showing that the global rate of convergence of the norm of the objective function's gradients at the iterates converge to zero like o(1/k). A small example is also provided indicating that the rate cannot be improved.",
      "authors": [
        "Serge Gratton",
        "Philippe L. Toint"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-22 13:50:59+00:00",
      "link": "https://arxiv.org/pdf/2601.15970v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15742v1",
      "title": "A sequential linear complementarity problem method for generalized Nash equilibrium problems",
      "abstract": "We propose a sequential linear complementarity problem (SLCP) method for solving generalized Nash equilibrium problems (GNEPs). By introducing a novel merit function that utilizes the specific structure of GNEPs, we establish global convergence of the method. The conditions guaranteeing global convergence are analogous to those for the classical sequential quadratic programming method with exact Lagrange Hessians, making this a natural and reasonable generalization. Moreover, we provide a detailed analysis of the solvability of the mixed linear complementarity subproblems, which are formulated as affine GNEPs. Sufficient characterizations for the local superlinear convergence are also derived, highlighting the efficiency of the proposed method. Finally, numerical experiments demonstrate the practical performance and effectiveness of the SLCP method in comparison with existing approaches.",
      "authors": [
        "Ruoyu Diao",
        "Yu-Hong Dai",
        "Liwei Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-22 08:12:51+00:00",
      "link": "https://arxiv.org/pdf/2601.15742v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15684v1",
      "title": "Parallelizable Riemannian Alternating Direction Method of Multipliers for Non-convex Pose Graph Optimization",
      "abstract": "Pose graph optimization (PGO) is fundamental to robot perception and navigation systems, serving as the mathematical backbone for solving simultaneous localization and mapping (SLAM). Existing solvers suffer from polynomial growth in computational complexity with graph size, hindering real-time deployment in large-scale scenarios. In this paper, by duplicating variables and introducing equality constraints, we reformulate the problem and propose a Parallelizable Riemannian Alternating Direction Method of Multipliers (PRADMM) to solve it efficiently. Compared with the state-of-the-art methods that usually exhibit polynomial time complexity growth with graph size, PRADMM enables efficient parallel computation across vertices regardless of graph size. Crucially, all subproblems admit closed-form solutions, ensuring PRADMM maintains exceptionally stable performance. Furthermore, by carefully exploiting the structures of the coefficient matrices in the constraints, we establish the global convergence of PRADMM under mild conditions, enabling larger relaxation step sizes within the interval $(0,2)$. Extensive empirical validation on two synthetic datasets and multiple real-world 3D SLAM benchmarks confirms the superior computational performance of PRADMM.",
      "authors": [
        "Xin Chen",
        "Chunfeng Cui",
        "Deren Han",
        "Liqun Qi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-22 06:06:35+00:00",
      "link": "https://arxiv.org/pdf/2601.15684v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15611v1",
      "title": "Degree-choosability of proper conflict-free list coloring of sparse graphs",
      "abstract": "Given a graph $G$ and a mapping $f:V(G) \\to \\mathbb{N}$, an $f$-list assignment of $G$ is a function that maps each $v \\in V(G)$ to a set of at least $f(v)$ colors. For an $f$-list assignment $L$ of a graph $G$, a proper conflict-free $L$-coloring of $G$ is a proper coloring $φ$ of $G$ such that for every vertex $v \\in V(G)$, $φ(v) \\in L(v)$ and some appears precisely once in the neighborhood of $v$. We say that $G$ is proper conflict-free $f$-choosable if for every $f$-list assignment $L$ of $G$, there exists a proper conflict-free $L$-coloring of $G$. If $G$ is proper conflict-free $f$-choosable and there is a constant $k$ such that $f(v)= d_G(v)+k$ for every vertex $v$ of $G$, then we say $G$ is proper conflict-free $({\\rm degree}+k)$-choosable. In this paper, we consider graphs with a bounded maximum average degree. We show that every graph with the maximum average degree less than $\\frac{10}{3}$ is proper conflict-free $({\\rm degree}+3)$-choosable, and that every graph with the maximum average degree less than $\\frac{18}{7}$ is proper conflict-free $({\\rm degree}+2)$-choosable. As a result, every planar graph with girth at least $5$ is proper conflict-free $({\\rm degree}+3)$-choosable, and every planar graph with girth at least $9$ is proper conflict-free $({\\rm degree}+2)$-choosable.",
      "authors": [
        "Masaki Kashima",
        "Riste Škrekovski",
        "Rongxing Xu"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-22 03:23:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15611v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15411v1",
      "title": "Asymptotic behaviour of coupled random dynamical systems with multiscale aspects",
      "abstract": "We examine a class of stochastic differential inclusions involving multiscale effects designed to solve a class of generalized variational inequalities. This class of problems contains constrained convex non-smooth optimization problems, constrained saddle-point problems and various equilibrium problems in economics and engineering. In order to respect constraints we adopt a penalty approach, introducing an explicit time-dependency into the evolution system. The resulting dynamics are described in terms of a non-autonomous stochastic evolution equation governed by maximally monotone operators in the drift and perturbed by a Brownian motion. We study the asymptotic behavior, as well as finite time convergence rates in terms of gap functions. The condition we use to prove convergence involves a Legendre transform of the function describing the set C, a condition first used by Attouch and Czarnecki (J. Differ. Equations, Vol. 248, Issue 6, 2010) in the context of deterministic evolution equations. We also establish a large deviations principle showing that individual trajectories exhibit exponential concentration around the solution set. Finally we show how our continuous-time approach relates to penalty-regulated algorithms of forward-backward type after performing a suitable Euler-Maruyama discretisation.",
      "authors": [
        "D. Russell Luke",
        "Johannes-Carl Schnebel",
        "Mathias Staudigl",
        "Juan Peypouquet",
        "Siqi Qu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.DS"
      ],
      "published": "2026-01-21 19:20:34+00:00",
      "link": "https://arxiv.org/pdf/2601.15411v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15403v1",
      "title": "F-Purity of Binomial Edge Ideals",
      "abstract": "In 2012, K. Matsuda introduced the class of weakly closed graphs and investigated when binomial edge ideals are F-pure. He proved that weakly closed binomial edge ideals are F-pure whenever the base field has positive characteristic. He conjectured that: (i) when the base field has characteristic two, every F-pure binomial edge ideal comes from a weakly closed graph; and (ii) that every binomial edge ideal is F-pure provided that the characteristic of the residue field is sufficiently large.   In this paper, we resolve both of Matsuda's conjectures. We confirm Matsuda's first conjecture, showing that the binomial edge ideal of a graph defines an F-pure quotient in characteristic 2 if and only if the graph is weakly closed. We also show that Matsuda's second conjecture is false in a very strong way by showing that graphs containing asteroidal triples, such as the net, define non-F-pure binomial edge ideals in any positive characteristic. Our results yield a complete classification of F-pure binomial edge ideals of chordal graphs as well as large families of standard graded algebras that are F-injective but neither F-pure nor F-rational in all characteristics.",
      "authors": [
        "Adam LaClair",
        "Jason McCullough"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2026-01-21 19:14:52+00:00",
      "link": "https://arxiv.org/pdf/2601.15403v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15252v1",
      "title": "Automating Idealness Proofs for Binary Programs with Application to Rectangle Packing",
      "abstract": "An integer program is called ideal if its continuous relaxation coincides with its convex hull allowing the problem to be solved as a continuous program and offering substantial computational advantages. Proving idealness analytically can be extraordinarily tedious -- even for small formulations -- such proofs often span many pages of intricate case analysis which motivates the development of automated verification methods. We develop a general-purpose framework for certifying idealness in Mixed Binary Linear Programs (MBLPs), formulating the verification problem as a linear program when the data is fixed and as a nonconvex quadratic program when the data is parametric. We apply this framework to study several formulations of the rectangle packing problem that are conjectured to be pairwise-ideal, obtaining computational proofs where analytic proofs were previously unknown or impractical. As our second contribution, we introduce and model a novel generalization of the rectangle packing problem that enforces edge clearances between selected rectangles. We present both existing and novel MBLP formulations which arise from different encodings of the underlying disjunctive constraints. We perform some computational experiments on these formulations under a strip-packing objective to determine the importance of pairwise-idealness in practice.",
      "authors": [
        "Jamie Fravel",
        "Robert Hildebrand"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 18:35:20+00:00",
      "link": "https://arxiv.org/pdf/2601.15252v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15245v1",
      "title": "Coloring small locally sparse degenerate graphs and related problems",
      "abstract": "The classic upper bound on the chromatic number of $d$-degenerate graphs is $d+1$, shown to be tight by complete graphs. A natural question is whether this bound remains tight if one forbids large cliques. Classic constructions of Tutte and Zykov from the early 50s show that there exist $d$-degenerate $(d+1)$-chromatic graphs that are triangle-free, however these constructions grow rapidly with $d$. Motivated by this and addressing a problem posed by the second author at the Oberwolfach Graph Theory workshop, we prove that the minimum order $f(d)$ of a $d$-degenerate triangle-free graph of chromatic number $d+1$ satisfies $e^{Ω(d)}\\le f(d)\\le e^{O(d^2\\log d)}.$ The lower bound follows from a novel upper bound on the chromatic number of triangle-free graphs: Every triangle-free $d$-degenerate graph $G$ on $n \\le e^{O(d)}$ vertices satisfies $$χ(G)\\le O\\left(\\frac{d}{\\log\\left(d/\\log n\\right)}\\right).$$ We extend this to a more general result about degenerate graphs with sparse neighborhoods, which has applications to many graph coloring problems: For example, we prove that every counterexample to Hadwiger's conjecture with parameter $t$ must have a complete bipartite subgraph with one exponentially large side ($K_{a,b}$ where $a=(\\log t)^{1/2-o(1)}$ and $b=e^{t^{1-o(1)}}$) or a small and very dense subgraph (of order $\\le t$ with $t^{2-o(1)}$ edges) in some neighborhood.   For the upper bound on $f(d)$ we establish a surprising connection between $f(d)$ and the on-line-chromatic number $g(n)$ of $n$-vertex triangle-free graphs. We also give an asymptotic improvement of the previous best upper bound for $g(n)$ due to Lovász, Saks and Trotter from 1989.   Along the way we disprove a generalization of Harris' fractional coloring conjecture to graphs of bounded clique number and raise numerous problems which open up interesting directions to explore for future research.",
      "authors": [
        "Domagoj Bradač",
        "Jacob Fox",
        "Raphael Steiner",
        "Benny Sudakov",
        "Shengtong Zhang"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-21 18:26:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15245v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15226v1",
      "title": "Exact general solutions for cosmological scalar field evolution in a vacuum-energy dominated expansion",
      "abstract": "We derive exact general solutions (as opposed to attractor particular solutions) for the evolution of a scalar field $φ$ in a universe dominated by a background fluid with equation of state parameter $w_B = -1$, extending earlier work on exact solutions with $w_B > -1$. Straightfoward exact solutions exist when the evolution is described by a linear differential equation, corresponding to constant, linear, and quadratic potentials. In the nonlinear case, exact solutions are derived for $V = V_0\\ln φ$, $V = V_0 φ^{1/2}$ and $V = V_0/φ$, and the logarithmic potential also yields an exact first integral. These complicated parametric solutions are considerably less useful than those derived previously for a universe dominated by a barotropic fluid such as matter or radiation with $w_B > -1$. However, we generalize the slow-roll approximation and show that it applies to all sufficiently flat potentials in the case of a vacuum-dominated expansion, while it never applies when the universe is dominated by a background fluid with $w_B > -1$.",
      "authors": [
        "Patrick Hu",
        "Robert J. Scherrer"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.CO",
        "hep-th",
        "math-ph"
      ],
      "published": "2026-01-21 18:02:23+00:00",
      "link": "https://arxiv.org/pdf/2601.15226v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15210v2",
      "title": "Enhanced posterior sampling via diffusion models for efficient metasurfaces inverse design",
      "abstract": "The inverse design of metasurfaces faces inherent challenges due to the nonlinear and highly complex relationship between geometric configurations and their electromagnetic behavior. Traditional optimization approaches often suffer from excessive computational demands and a tendency to converge to suboptimal solutions. This study presents a diffusion-based generative framework that incorporates a dedicated consistency constraint and advanced posterior sampling methods to ensure adherence to desired electromagnetic specifications. Through rigorous validation on small-scale metasurface configurations, the proposed approach demonstrates marked enhancements in both accuracy and reliability of the generated designs. Furthermore, we introduce a scalable methodology that extends inverse design capabilities to large-scale metasurfaces, validated for configurations of up to $98 \\times 98$ nanopillars. Notably, this approach enables rapid design generation completed in minute by leveraging models trained on substantially smaller arrays ($23 \\times 23$). These innovations establish a robust and efficient framework for high-precision metasurface inverse design.",
      "authors": [
        "Mathys Le Grand",
        "Pascal Urard",
        "Denis Rideau",
        "Loumi Trémas",
        "Damien Maitre",
        "Louis-Henri Fernandez-Mouron",
        "Adam Fuchs",
        "Régis Orobtchouk"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "math-ph"
      ],
      "published": "2026-01-21 17:33:42+00:00",
      "link": "https://arxiv.org/pdf/2601.15210v2",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15191v1",
      "title": "Parareal algorithm for coupled elliptic-parabolic problems",
      "abstract": "We present a convergence analysis of the parallel-in-time integration method known as the Parareal algorithm for degenerate differential-algebraic systems arising from quasi-static Biot models, which govern coupled flow and deformation in porous media. The underlying system exhibits a saddle-point structure and degeneracy due to the quasi-static assumption. We extend the Parareal algorithm to this setting and propose three coarse propagators: monolithic, fixed-stress, and multirate fixed-stress schemes. For each, we derive sufficient conditions for convergence and establish explicit time step restrictions that guarantee contractivity of the iteration matrix. Numerical experiments show computational savings accrued by using a parareal solver in multiphysics simulations involving poroelasticity and other coupled systems.",
      "authors": [
        "Iñigo Jimenez-Ciga",
        "Francisco Gaspar",
        "Kundan Kumar",
        "Florin A. Radu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-21 17:07:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15191v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15168v1",
      "title": "Path-OED for infinite-dimensional Bayesian linear inverse problems governed by PDEs",
      "abstract": "We consider infinite-dimensional Bayesian linear inverse problems governed by time-dependent partial differential equations (PDEs) and develop a mathematical and computational framework for optimal design of mobile sensor paths in this setting. The proposed path optimal experimental design (path-OED) framework is established rigorously in a function space setting and elaborated for the case of Bayesian c-optimality, which quantifies the posterior variance in a linear functional of the inverse parameter. The latter is motivated by goal-oriented formulations, where we seek to minimize the uncertainty in a scalar prediction of interest. To facilitate computations, we complement the proposed infinite-dimensional framework with discretized formulations, in suitably weighted finite-dimensional inner product spaces, and derive efficient methods for finding optimal sensor paths. The resulting computational framework is flexible, scalable, and can be adapted to a broad range of linear inverse problems and design criteria. We also present extensive computational experiments, for a model inverse problem constrained by an advection-diffusion equation, to demonstrate the effectiveness of the proposed approach.",
      "authors": [
        "J. Nicholas Neuberger",
        "Alen Alexanderian",
        "Bart van Bloemen Waanders",
        "Ahmed Attia"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 16:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.15168v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15157v1",
      "title": "Typical hyperbolic surfaces have an optimal spectral gap",
      "abstract": "The first non-zero Laplace eigenvalue of a hyperbolic surface, or its spectral gap, measures how well-connected the surface is: surfaces with a large spectral gap are hard to cut in pieces, have a small diameter and fast mixing times. For large hyperbolic surfaces (of large area or large genus $g$, equivalently), we know that the spectral gap is asymptotically bounded above by $\\frac 14$. The aim of these talks is to present joint work with Nalini Anantharaman, where we prove that most hyperbolic surfaces have a near-optimal spectral gap. That is to say, we prove that, for any $ε> 0$, the Weil--Petersson probability for a hyperbolic surface of genus $g$ to have a spectral gap greater than $\\frac 14- ε$ goes to one as $g$ goes to infinity. This statement is analogous to Alon's 1986 conjecture for regular graphs, proven by Friedman in 2003. I will present our approach, which shares many similarities with Friedman's work, and introduce new tools and ideas that we have developed in order to tackle this problem.",
      "authors": [
        "Laura Monk"
      ],
      "primary_category": "math.SP",
      "categories": [
        "math.SP",
        "math.MG"
      ],
      "published": "2026-01-21 16:32:39+00:00",
      "link": "https://arxiv.org/pdf/2601.15157v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15138v1",
      "title": "Inequalities of Miyaoka-Yau type $\\&$ Uniformisation of varieties of intermediate Kodaira Dimension",
      "abstract": "In this paper we present, for any integers $0\\leq ν\\leq n$, a set of inequalities satisfied by the Chern classes of any minimal complex projective variety of dimension $n$ and numerical dimension $ν$. In the cases where $ν$ is either very small or very large compared with $n$, this recovers many previously known results. We demonstrate that our inequalities are sharp by providing an explicit characterisation of those varieties achieving the equality; our proof, in particular, resolves the Abundance conjecture in this situation. Additionally, we provide some new examples of varieties with extremal Chern classes that demonstrate the optimality of our results.",
      "authors": [
        "Niklas Müller"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-21 16:12:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15138v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15134v1",
      "title": "A New Measure of Coarseness for Solutions to Cahn--Hilliard Equations",
      "abstract": "We introduce a new measure of coarseness for characterizing phase separation processes such as those described by Cahn--Hilliard equations. An advantage of our measure is that it remains consistent throughout the evolution, including for solutions with no periodic structure. We use our measure to compare two previous models of coarsening dynamics with numerically generated dynamics, providing the first direct check that we are aware of for the efficacy of these methods.",
      "authors": [
        "Peter Howard",
        "Adam Larios",
        "Quyuan Lin"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-21 16:07:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15134v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15092v1",
      "title": "Federated Incremental Subgradient Method for Convex Bilevel Optimization Problems",
      "abstract": "In this letter, we consider a bilevel optimization problem in which the outer-level objective function is strongly convex, whereas the inner-level problem consists of a finite sum of convex functions. Bilevel optimization problems arise in situations where the inner-level problem does not have a unique solution. This has led to the idea of introducing an outer-level objective function to select a solution with the specific desired properties. We propose an iterative method that combines an incremental algorithm with a broadcast algorithm, both based on the principles of federated learning. Under appropriate assumptions, we establish the convergence results of the proposed algorithm. To demonstrate its performance, we present two numerical examples related to binary classification and a location problem.",
      "authors": [
        "Sudkobfa Boontawee",
        "Mootta Prangprakhon",
        "Nimit Nimana"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 15:32:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15092v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16195v1",
      "title": "Pushing the limits of unconstrained machine-learned interatomic potentials",
      "abstract": "Machine-learned interatomic potentials (MLIPs) are increasingly used to replace computationally demanding electronic-structure calculations to model matter at the atomic scale. The most commonly used model architectures are constrained to fulfill a number of physical laws exactly, from geometric symmetries to energy conservation. Evidence is mounting that relaxing some of these constraints can be beneficial to the efficiency and (somewhat surprisingly) accuracy of MLIPs, even though care should be taken to avoid qualitative failures associated with the breaking of physical symmetries. Given the recent trend of \\emph{scaling up} models to larger numbers of parameters and training samples, a very important question is how unconstrained MLIPs behave in this limit. Here we investigate this issue, showing that -- when trained on large datasets -- unconstrained models can be superior in accuracy and speed when compared to physically constrained models. We assess these models both in terms of benchmark accuracy and in terms of usability in practical scenarios, focusing on static simulation workflows such as geometry optimization and lattice dynamics. We conclude that accurate unconstrained models can be applied with confidence, especially since simple inference-time modifications can be used to recover observables that are consistent with the relevant physical symmetries.",
      "authors": [
        "Filippo Bigi",
        "Paolo Pegolo",
        "Arslan Mazitov",
        "Michele Ceriotti"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "stat.ML"
      ],
      "published": "2026-01-22 18:46:58+00:00",
      "link": "https://arxiv.org/pdf/2601.16195v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16022v1",
      "title": "A Fast Monte Carlo Newton-Raphson Algorithm to Estimate Generalized Linear Mixed Models with Dense Covariance",
      "abstract": "Estimation of Generalised linear mixed models (GLMM) including spatial Gaussian process models is often considered computationally impractical for even moderately sized datasets. In this article, we propose a fast Monte Carlo maximum likelihood (MCML) algorithm for the estimation of GLMMs. The algorithm is a stochastic Newton-Raphson method, which approximates the expected Hessian and gradient of the log-likelihood by drawing samples of the random effects. We propose a new stopping criterion for efficient termination and preventing long runs of sampling in the stationary post-convergence phase of the algorithm and discuss Monte Carlo sample size choice. We run a series of simulation comparisons of spatial statistical models alongside the popular integrated nested Laplacian approximation method and demonstrate potential for similar or improved estimator performance and reduced running times. We also consider scaling of the algorithms to large datasets and demonstrate a greater than 100-fold reduction in running times using modern GPU hardware to illustrate the feasibility of full maximum likelihood methods with big spatial datasets.",
      "authors": [
        "Samuel I. Watson",
        "Yixin Wang",
        "Emanuele Giorgi"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-22 14:46:35+00:00",
      "link": "https://arxiv.org/pdf/2601.16022v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15132v1",
      "title": "Efficient prior sensitivity analysis for Bayesian model comparison",
      "abstract": "Bayesian model comparison implements Occam's razor through its sensitivity to the prior. However, prior-dependence makes it important to assess the influence of plausible alternative priors. Such prior sensitivity analyses for the Bayesian evidence are expensive, either requiring repeated, costly model re-fits or specialised sampling schemes. By exploiting the learned harmonic mean estimator (LHME) for evidence calculation we decouple sampling and evidence calculation, allowing resampled posterior draws to be used directly to calculate the evidence without further likelihood evaluations. This provides an alternative approach to prior sensitivity analysis for Bayesian model comparison that dramatically alleviates the computational cost and is agnostic to the method used to generate posterior samples. We validate our method on toy problems and a cosmological case study, reproducing estimates obtained by full Markov chain Monte Carlo (MCMC) sampling and nested sampling re-fits. For the cosmological example considered our approach achieves up to $6000\\times$ lower computational cost.",
      "authors": [
        "Zixiao Hu",
        "Jason D. McEwen"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "astro-ph.CO",
        "astro-ph.IM"
      ],
      "published": "2026-01-21 16:05:23+00:00",
      "link": "https://arxiv.org/pdf/2601.15132v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15952v1",
      "title": "Reconstructing Patched or Partial Holograms to allow for Whole Slide Imaging with a Self-Referencing Holographic Microscope",
      "abstract": "The last decade has seen significant advances in computer-aided diagnostics for cytological screening, mainly through the improvement and integration of scanning techniques such as whole slide imaging (WSI) and the combination with deep learning. Simultaneously, new imaging techniques such as quantitative phase imaging (QPI) are being developed to capture richer cell information with less sample preparation. So far, the two worlds of WSI and QPI have not been combined. In this work, we present a reconstruction algorithm which makes whole slide imaging of cervical smears possible by using a self-referencing three-wave digital holographic microscope. Since a WSI is constructed by combining multiple patches, the algorithm is adaptive and can be used on partial holograms and patched holograms. We present the algorithm for a single shot hologram, the adaptations to make it flexible to various inputs and show that the algorithm performs well for the tested epithelial cells. This is a preprint of our paper, which has been accepted for publication in 2026 IEEE International Symposium on Biomedical Imaging (ISBI).",
      "authors": [
        "Philip Groult",
        "Julia D. Sistermanns",
        "Ellen Emken",
        "Oliver Hayden",
        "Wolfgang Utschick"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "q-bio.QM"
      ],
      "published": "2026-01-22 13:41:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15952v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15854v1",
      "title": "Towards mathematical spaces for biological processes",
      "abstract": "Physics relies on mathematical spaces carefully matched to the phenomena under study. Phase space in classical mechanics, Hilbert space in quantum theory, configuration spaces in field theory all provide representations in which physical laws, stability and invariants become expressible and testable. In contrast, biology lacks an agreed-upon notion of space capturing context dependence, partial observability, degeneracy and irreversible dynamics. To address this gap, we introduce a unified mathematical space tailored to biological processes where states are represented in locally convex spaces indexed by context, where context includes both environment and history. Within our setting, proximity is defined through families of seminorms rather than a single global metric, allowing biological relevance to vary across conditions. Admissible sets encode biological constraints, observation maps formalize partial observability and many-to-one relations between state and dynamics capture irreversibility without requiring convergence to fixed points. Stabilization is characterized by neighborhood inclusion and degeneracy arises naturally through quotient structures induced by observation. We develop explicit constructions, operators and bounds within this space, yielding quantitative predictions dictated by its structure. A worked example based on EGFR-mutant non-small-cell lung cancer shows how single-cell data can be mapped into our framework, how numerical thresholds can be calibrated from the literature and how testable predictions can be formulated concerning rare tolerant states, context-dependent proximity and early stabilization. Overall, by providing biology with a space playing a role analogous to those used in physics, we aim to support structurally grounded and quantitative analyses of biological systems across contexts.",
      "authors": [
        "Arturo Tozzi"
      ],
      "primary_category": "q-bio.OT",
      "categories": [
        "q-bio.OT"
      ],
      "published": "2026-01-22 11:02:03+00:00",
      "link": "https://arxiv.org/pdf/2601.15854v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15483v1",
      "title": "Data complexity signature predicts quantum projected learning benefit for antibiotic resistance",
      "abstract": "This study presents the first large-scale empirical evaluation of quantum machine learning for predicting antibiotic resistance in clinical urine cultures. Antibiotic resistance is amongst the top threats to humanity, and inappropriate antibiotic use is a main driver of resistance. We developed a Quantum Projective Learning (QPL) approach and executed 60 qubit experiments on IBM Eagle and Heron quantum processing units. While QPL did not consistently outperform classical baselines, potentially reflecting current quantum hardware limitations, it did achieve parity or superiority in specific scenarios, notably for the antibiotic nitrofurantoin and selected data splits, revealing that quantum advantage may be data-dependent. Analysis of data complexity measures uncovered a multivariate signature, which comprised Shannon entropy, Fisher Discriminant Ratio, standard deviation of kurtosis, number of low-variance features, and total correlations. The multivariate model accurately (AUC = 0.88, $p$-value = 0.03) distinguished cases wherein QPL executed on quantum hardware would outperform classical models. This signature suggests that quantum kernels excel in feature spaces with high entropy and structural complexity. These findings point to complexity-driven adaptive model selection as a promising strategy for optimizing hybrid quantum-classical workflows in healthcare. Overall, this investigation marks the first application of quantum machine learning in urology, and in antibiotic resistance prediction. Further, this work highlights conditional quantum utility and introduces a principled approach for leveraging data complexity signatures to guide quantum machine learning deployment in biomedical applications.",
      "authors": [
        "Kahn Rhrissorrakrai",
        "Filippo Utro",
        "Alex Milinovich",
        "Sandip Vasavada",
        "Daniel Rhoads",
        "Laxmi Parida",
        "Glenn T. Werneburg"
      ],
      "primary_category": "q-bio.OT",
      "categories": [
        "q-bio.OT"
      ],
      "published": "2026-01-21 21:35:28+00:00",
      "link": "https://arxiv.org/pdf/2601.15483v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16012v1",
      "title": "Low-Complexity Sparse Superimposed Coding for Ultra Reliable Low Latency Communications",
      "abstract": "Sparse superimposed coding (SSC) has emerged as a promising technique for short-packet transmission in ultra-reliable low-latency communication scenarios. However, conventional SSC schemes often suffer from high encoding and decoding complexity due to the use of dense codebook matrices. In this paper, we propose a low-complexity SSC scheme by designing a sparse codebook structure, where each codeword contains only a small number of non-zero elements. The decoding is performed using the traditional multipath matching pursuit algorithm, and the overall complexity is significantly reduced by exploiting the sparsity of the codebook. Simulation results show that the proposed scheme achieves a favorable trade-off between BLER performance and computational complexity, and exhibits strong robustness across different transmission block lengths.",
      "authors": [
        "Yanfeng Zhang",
        "Xi'an Fan",
        "Xu Zhu",
        "Jinkai Zheng",
        "Hui Liang",
        "Weiwei Yang",
        "Tom H. Luan"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 14:38:20+00:00",
      "link": "https://arxiv.org/pdf/2601.16012v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15863v1",
      "title": "Time-Varying Rician K-factor in Measured Vehicular Channels at cmWave and mmWave Bands",
      "abstract": "Future vehicular communication systems will integrate millimeter wave (mmWave) technology to enhance data transmission rates. To investigate the propagation effects and small-scale fading differences between mmWave and conventional centimeter wave (cmWave) bands, multi-band channel measurements have to be conducted. One key parameter to characterize small-scale fading is the Rician K-factor. In this paper, we analyze the time-varying K-factor of vehicle-to-infrastructure (V2I) channels across multiple frequency bands, measured in an urban street environment. Specifically, we investigate three frequency bands with center frequencies of 3.2 GHz, 34.3 GHz and 62.35 GHz using measurement data with 155.5 MHz bandwidth and a sounding repetition rate of 31.25 μs. Furthermore, we analyze the relationship between K-factor and root-mean-square (RMS) delay spread. We show that the Ricean K-factor is similar at different frequency bands and that is correlated with the RMS delay spread.",
      "authors": [
        "Faruk Pasic",
        "Markus Hofer",
        "Thomas Zemen",
        "Andreas F. Molisch",
        "Christoph F. Mecklenbräuker"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 11:10:28+00:00",
      "link": "https://arxiv.org/pdf/2601.15863v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15821v1",
      "title": "Separable Delay And Doppler Estimation In Passive Radar",
      "abstract": "In passive radar, a network of distributed sensors exploit signals from so-called Illuminators-of-Opportunity to detect and localize targets. We consider the case where the IO signal is available at each receiver node through a reference channel, whereas target returns corrupted by interference are collected in a separate surveillance channel. The problem formulation is similar to an active radar that uses a noise-like waveform, or an integrated sensing and communication application. The available data is first split into batches of manageable size. In the direct approach, the target's time-delay and Doppler parameters are estimated jointly by incoherently combining the batch-wise data. We propose a new method to estimate the time-delay separately, thus avoiding a costly 2-D search. Our approach is designed for slowly moving targets, and the accuracy of the time-delay estimate is similar to that of the full batch-wise 2-D method. Given the time-delay, the coherency between batches can be restored when estimating the Doppler parameter. Thereby, the separable approach is found to yield superior Doppler estimates over a wide parameter range. In addition to reducing computational complexity, the proposed separable estimation technique also significantly reduces the communication overhead in a distributed radar setting.",
      "authors": [
        "Mats Viberg",
        "Daniele Gerosa",
        "Tomas McKelvey",
        "Patrik Dammert",
        "Thomas Eriksson"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 10:13:34+00:00",
      "link": "https://arxiv.org/pdf/2601.15821v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15819v1",
      "title": "Dual-Mapping Sparse Vector Transmission for Short Packet URLLC",
      "abstract": "Sparse vector coding (SVC) is a promising short-packet transmission method for ultra reliable low latency communication (URLLC) in next generation communication systems. In this paper, a dual-mapping SVC (DM-SVC) based short packet transmission scheme is proposed to further enhance the transmission performance of SVC. The core idea behind the proposed scheme lies in mapping the transmitted information bits onto sparse vectors via block and single-element sparse mappings. The block sparse mapping pattern is able to concentrate the transmit power in a small number of non-zero blocks thus improving the decoding accuracy, while the single-element sparse mapping pattern ensures that the code length does not increase dramatically with the number of transmitted information bits. At the receiver, a two-stage decoding algorithm is proposed to sequentially identify non-zero block indexes and single-element non-zero indexes. Extensive simulation results verify that proposed DM-SVC scheme outperforms the existing SVC schemes in terms of block error rate and spectral efficiency.",
      "authors": [
        "Yanfeng Zhang",
        "Xu Zhu",
        "Jinkai Zheng",
        "Weiwei Yang",
        "Xianhua Yu",
        "Haiyong Zeng",
        "Yujie Liu",
        "Yong Liang Guan"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 10:07:38+00:00",
      "link": "https://arxiv.org/pdf/2601.15819v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15790v1",
      "title": "Adaptive Non-Uniform Sampling of Bandlimited Signals via Algorithm-Encoder Co-Design",
      "abstract": "We propose an adaptive non-uniform sampling framework for bandlimited signals based on an algorithm-encoder co-design perspective. By revisiting the convergence analysis of iterative reconstruction algorithms for non-uniform measurements, we derive a local, energy-based sufficient condition that governs reconstruction behavior as a function of the signal and derivative energies within each sampling interval. Unlike classical approaches that impose a global Nyquist-type bound on the inter-sample spacing, the proposed condition permits large gaps in slowly varying regions while enforcing denser sampling only where the signal exhibits rapid temporal variation. Building on this theoretical insight, we design a variable-bias, variable-threshold integrate-and-fire time encoding machine (VBT-IF-TEM) whose firing mechanism is explicitly shaped to enforce the derived local convergence condition. To ensure robustness, a shifted-signal formulation is introduced to suppress excessive firing in regions where the magnitude of the signal amplitude is close to zero or the local signal energy approaches zero. Using the proposed encoder, an analog signal is discretely represented by time encodings and signal averages, enabling perfect reconstruction via a standard iterative algorithm even when the local sampling rate falls below the Nyquist rate. Simulation results on synthetic signals and experiments on ultrasonic guided-wave and ECG signals demonstrate that the proposed framework achieves substantial reductions in sampling density compared to uniform sampling and conventional IF-TEMs, while maintaining accurate reconstruction. The results further highlight a controllable tradeoff between sampling density, reconstruction accuracy, and convergence behavior, which can be navigated through adaptive parameter selection.",
      "authors": [
        "Kaluguri Yashaswini",
        "Anshu Arora",
        "Satish Mulleti"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 09:25:54+00:00",
      "link": "https://arxiv.org/pdf/2601.15790v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15653v1",
      "title": "Distributed Multichannel Active Noise Control with Asynchronous Communication",
      "abstract": "Distributed multichannel active noise control (DMCANC) offers effective noise reduction across large spatial areas by distributing the computational load of centralized control to multiple low-cost nodes. Conventional DMCANC methods, however, typically assume synchronous communication and require frequent data exchange, resulting in high communication overhead. To enhance efficiency and adaptability, this work proposes an asynchronous communication strategy where each node executes a weight-constrained filtered-x LMS (WCFxLMS) algorithm and independently requests communication only when its local noise reduction performance degrades. Upon request, other nodes transmit the weight difference between their local control filter and the center point in WCFxLMS, which are then integrated to update both the control filter and the center point. This design enables nodes to operate asynchronously while preserving cooperative behavior. Simulation results demonstrate that the proposed asynchronous communication DMCANC (ACDMCANC) system maintains effective noise reduction with significantly reduced communication load, offering improved scalability for heterogeneous networks.",
      "authors": [
        "Junwei Ji",
        "Dongyuan Shi",
        "Boxiang Wang",
        "Ziyi Yang",
        "Haowen Li",
        "Woon-Seng Gan"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "eess.SP"
      ],
      "published": "2026-01-22 05:02:06+00:00",
      "link": "https://arxiv.org/pdf/2601.15653v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15471v1",
      "title": "Achievable Rate Optimization for Large Flexible Intelligent Metasurface Assisted Downlink MISO under Statistical CSI",
      "abstract": "The integration of electromagnetic metasurfaces into wireless communications enables intelligent control of the propagation environment. Recently, flexible intelligent metasurfaces (FIMs) have evolved beyond conventional reconfigurable intelligent surfaces (RISs), enabling three-dimensional surface deformation for adaptive wave manipulation. However, most existing FIM-aided system designs assume perfect instantaneous channel state information (CSI), which is impractical in large-scale networks due to the high training overhead and complicated channel estimation. To overcome this limitation, we propose a robust statistical-CSI-based optimization framework for downlink multiple-input single-output (MISO) systems with FIM-assisted transmitters. A block coordinate ascent (BCA)-based iterative algorithm is developed to jointly optimize power allocation and FIM morphing, maximizing the average achievable sum rate. Simulation results show that the proposed statistical-CSI-driven FIM design significantly outperforms conventional rigid antenna arrays (RAAs), validating its effectiveness and practicality.",
      "authors": [
        "Ling He",
        "Vaibhav Kumar",
        "Anastasios Papazafeiropoulos",
        "Miaowen Wen",
        "Le-Nam Tran",
        "Marwa Chafii"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-21 21:14:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15471v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15196v1",
      "title": "TTCBF: A Truncated Taylor Control Barrier Function for High-Order Safety Constraints",
      "abstract": "Control Barrier Functions (CBFs) enforce safety by rendering a prescribed safe set forward invariant. However, standard CBFs are limited to safety constraints with relative degree one, while High-Order CBF (HOCBF) methods address higher relative degree at the cost of introducing a chain of auxiliary functions and multiple class K functions whose tuning scales with the relative degree. In this paper, we introduce a Truncated Taylor Control Barrier Function (TTCBF), which generalizes standard discrete-time CBFs to consider high-order safety constraints and requires only one class K function, independent of the relative degree. We also propose an adaptive variant, adaptive TTCBF (aTTCBF), that optimizes an online gain on the class K function to improve adaptability, while requiring fewer control design parameters than existing adaptive HOCBF variants. Numerical experiments in a relative-degree-six spring-mass system and a cluttered corridor navigation validate the above theoretical findings.",
      "authors": [
        "Jianye Xu",
        "Bassam Alrifaee"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-21 17:15:14+00:00",
      "link": "https://arxiv.org/pdf/2601.15196v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16086v1",
      "title": "Random Walks Across Dimensions: Exploring Simplicial Complexes",
      "abstract": "We introduce a novel operator to describe a random walk process on a simplicial complex. Walkers are allowed to wonder across simplices of various dimensions, bridging nodes to edges, and edges to triangles, via a nested organization that hierarchically extends to higher structures of arbitrary large, but finite, dimension. The asymptotic distribution of the walkers provides a natural ranking to gauge the relative importance of higher order simplices. Optimal search strategies in presence of stochastic teleportation are addressed and the peculiar interplay of noise with higher order structures unraveled.",
      "authors": [
        "Diego Febbe",
        "Duccio Fanelli",
        "Timoteo Carletti"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "nlin.AO",
        "physics.soc-ph"
      ],
      "published": "2026-01-22 16:33:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16086v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15998v1",
      "title": "Application of zone refining to the development of NaI(Tl) detectors for SABRE North",
      "abstract": "The SABRE North experiment is developing ultra-high radiopurity NaI(Tl) detectors to investigate dark matter. To achieve this, SABRE North utilizes the technique called zone refining for NaI powder purification. This work details the mathematical model developed to describe the purification process. By comparing this model to the results of the commissioning and production runs conducted prior to crystal growth, the distribution coefficients were determined for various impurities, contained in the powder at the parts-per-billion (ppb) level. Furthermore, the synthesis of data from both zone refining and normal freezing is discussed. These findings can be used to predict the SABRE North detectors background level in the energy region-of-interest for dark matter search and to optimize the production of ultra-high purity crystals through multiple purification strategies.",
      "authors": [
        "C. Ananna",
        "F. B. Armani",
        "G. Cataldi",
        "D. D'Angelo",
        "G. D'Imperio",
        "M. L. De Giorgi",
        "G. Di Carlo",
        "M. Diemoz",
        "A. Ianni",
        "S. G. Khattak",
        "E. Martinenghi",
        "A. Miccoli",
        "M. Misiaszek",
        "D. Montanino",
        "V. Pettinacci",
        "L. Pietrofaccia",
        "S. Rahatlou",
        "K. Szczepaniec",
        "C. Tomei",
        "V. Toso",
        "C. Vignoli",
        "S. Zuhra",
        "L. Cid",
        "A. Mellen-Spencer",
        "S. Nisi",
        "J. Tower"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex"
      ],
      "published": "2026-01-22 14:18:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15998v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15989v1",
      "title": "On-chip Multimode Opto-electronic Neural Network",
      "abstract": "Opto-electronic computing combines the complementary strengths of photonics and electronics to deliver ultrahigh computational throughput with high energy efficiency. However, its practical deployment for real-world applications has been limited by architectures that rely on delicate wavelength management or phase-sensitive coherent detection. Here, we demonstrate the first multimode opto-electronic neural network (MOENN) on a silicon-on-insulator platform. By utilizing orthogonal waveguide eigenmodes as independent information carriers, our architecture achieves robust single-wavelength computation that is inherently immune to spectral crosstalk and phase noise. The fabricated MOENN chip monolithically integrates all functional components, including input encoders, programmable mode-division fan-in/-out units, and most importantly, the nonlinear multimode activation functions. We report the system's versatility through in-situ training via a genetic algorithm, successfully resolving the nonlinear decision boundaries of a two-class dataset and achieving 92.1% accuracy on the Iris classification benchmark. Furthermore, we reconfigure the MOENN into a one-dimensional convolutional neural network, attaining an accuracy of 90.7% on the electrocardiogram-based emotion recognition task. This work establishes a new opto-electronic computing paradigm of simple control and excellent robustness, providing a compelling path toward scalable, deployable photonic intelligence.",
      "authors": [
        "Jinlong Xiang",
        "Youlve Chen",
        "Chaojun Xu",
        "Yuchen Yin",
        "Yufeng Zhang",
        "Yikai Su",
        "Zhipei Sun",
        "Xuhan Guo"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-22 14:12:39+00:00",
      "link": "https://arxiv.org/pdf/2601.15989v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15944v1",
      "title": "Partitioning networks into clusters of synchronized nodes via the message-passing algorithm: an unbiased scalable approach",
      "abstract": "Partitioning large networks into stable clusters of synchronized nodes is a challenging task. Recent approaches based on spectral analysis can provide exact results on specific dynamics but remain unfeasible for very large networks. Moreover, within a stochastic framework, it is unclear which dynamics should be chosen to study synchronization. Here we propose an unbiased and scalable method based on the message-passing algorithm. By exploiting the collective behavior emerging across critical points of an effective Ising-like model, we identify dynamically coherent clusters of synchronized nodes and illustrate the approach on some large real-world networks. We find that, unlike continuous-time dynamics, abrupt desyncrhronization occurs even in simple graphs, without the need to invoke higher order interactions. However, when noise is included, the transition to synchronization becomes smoother and proceeds through the formation of plateaus, albeit at the cost of requiring larger coupling strengths.",
      "authors": [
        "Massimo Ostilli"
      ],
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "cond-mat.dis-nn",
        "physics.data-an"
      ],
      "published": "2026-01-22 13:26:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15944v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15938v1",
      "title": "Operating a large-diameter dual-phase liquid xenon TPC in the unshielded PANCAKE facility",
      "abstract": "Future liquid-xenon (LXe) based observatories for rare processes, such as XLZD, require testing of large components and sub-assemblies in cryogenic liquid or gaseous xenon environments. Here we present results from the stable operation of a shallow dual-phase LXe TPC with an inner diameter of 133.4\\,cm and a height of 3.1\\,cm in the unshielded PANCAKE platform, without underground suppression of cosmic-ray backgrounds. A total of 340\\,kg of xenon was used in the experiment, of which 127\\,kg constituted the active TPC mass. Measurements of the LXe purity-dependent electron lifetime and the electron drift velocity in LXe demonstrate that sensitive measurements to characterize the TPC performance are possible in a high-background environment, even with a very basic PMT-based light detection system. Improving this will straightforwardly reduce the TPC threshold, which was observed to be around 15\\,keV for electronic recoils in TPC operation.",
      "authors": [
        "Julia Müller",
        "Jaron Grigat",
        "Robin Glade-Beucke",
        "Sebastian Lindemann",
        "Tiffany Luce",
        "Gnanesh Chandra Madduri",
        "Jens Reininghaus",
        "Marc Schumann",
        "Adam Softley-Brown",
        "Andrew Stevens"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det"
      ],
      "published": "2026-01-22 13:18:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15938v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15868v1",
      "title": "Large-scale real-time signal processing in physics experiments: The ALICE TPC FPGA pipeline",
      "abstract": "For LHC Run 3, the ALICE Time Projection Chamber was upgraded to operate in continuous readout mode. Interaction rates of up to 50 kHz in Pb-Pb collisions require real-time processing of more than 3 TB/s of raw detector data. This requirement is met by a custom FPGA-based processing pipeline that performs the complete front-end data treatment fully in-stream, including common-mode correction, pedestal subtraction, ion-tail filtering, zero suppression, and dense data packing.   A central element of the design is a highly parallel common-mode correction algorithm operating directly on the streaming data. It robustly identifies signal-free readout channels on a time-bin basis and applies pad-dependent scaling to compensate for local variations in capacitive coupling in the GEM readout. In combination with pedestal subtraction and ion-tail filtering, this enables accurate baseline restoration under extreme high-occupancy conditions, preventing signal loss while efficiently suppressing noise prior to zero suppression.   The pipeline operates continuously at the full detector bandwidth and reduces the raw input rate to about 900 GB/s for Pb-Pb collisions at the target interaction rate. Overall, it represents a large-scale FPGA-based real-time signal-processing implementation for high-energy physics detector readout.",
      "authors": [
        "J. Alme",
        "T. Alt",
        "C. Andrei",
        "V. Anguelov",
        "H. Appelshäuser",
        "M. Arslandok",
        "R. Averbeck",
        "M. Ball",
        "G. G. Barnaföldi",
        "P. Becht",
        "R. Bellwied",
        "A. Berdnikova",
        "B. Blidaru",
        "L. Boldizsár",
        "L. Bratrud",
        "P. Braun-Munzinger",
        "M. Bregant",
        "C. L. Britton",
        "H. Büsching",
        "H. Caines",
        "P. Chatzidaki",
        "P. Christiansen",
        "T. M. Cormier",
        "L. Döpper",
        "R. Ehlers",
        "L. Fabbietti",
        "F. Flor",
        "J. J. Gaardhøje",
        "M. G. Munhoz",
        "C. Garabatos",
        "P. Gasik",
        "Á. Gera",
        "P. Glässel",
        "N. Grünwald",
        "T. Gündem",
        "T. Gunji",
        "H. Hamagaki",
        "J. W. Harris",
        "P. Hauer",
        "E. Hellbär",
        "H. Helstrup",
        "A. Herghelegiu",
        "H. D. Hernandez Herrera",
        "Y. Hou",
        "C. Hughes",
        "M. Ivanov",
        "J. Jäger",
        "Y. Ji",
        "J. Jung",
        "M. Jung",
        "B. Ketzer",
        "S. Kirsch",
        "M. Kleiner",
        "A. G. Knospe",
        "M. Korwieser",
        "M. Kowalski",
        "L. Lautner",
        "M. Lesch",
        "C. Lippmann",
        "G. Mantzaridis",
        "R. D. Majka",
        "A. Marin",
        "C. Markert",
        "S. Masciocchi",
        "A. Matyja",
        "M. Meres",
        "D. L. Mihaylov",
        "D. Miśkowiec",
        "R. H. Munzer",
        "H. Murakami",
        "K. Münning",
        "A. Nassirpour",
        "C. Nattrass",
        "B. S. Nielsen",
        "W. A. V. Noije",
        "A. C. Oliveira Da Silva",
        "A. Oskarsson",
        "K. Oyama",
        "L. Österman",
        "Y. Pachmayer",
        "G. Paić",
        "M. Petris",
        "M. Petrovici",
        "M. Planinic",
        "J. Rasson",
        "K. F. Read",
        "A. Rehman",
        "R. Renfordt",
        "A. Riedel",
        "K. Røed",
        "D. Röhrich",
        "E. Rubio",
        "A. Rusu",
        "S. Sadhu",
        "B. C. S. Sanches",
        "J. Schambach",
        "A. Schmah",
        "C. Schmidt",
        "A. Schmier",
        "K. Schweda",
        "D. Sekihata",
        "D. Silvermyr",
        "B. Sitar",
        "N. Smirnov",
        "H. K. Soltveit",
        "C. Sonnabend",
        "S. P. Sorensen",
        "J. Stachel",
        "L. Šerkšnytė",
        "G. Tambave",
        "K. Ullaland",
        "B. Ulukutlu",
        "D. Varga",
        "O. Vazquez Rueda",
        "B. Voss",
        "J. Wiechula",
        "B. Windelband",
        "J. Wilkinson",
        "J. Witte",
        "A. Yadav",
        "F. Zanone",
        "S. Zhu"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det"
      ],
      "published": "2026-01-22 11:16:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15868v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15776v1",
      "title": "Coherent Mode Decoupling: A Versatile Framework for High-Throughput Partially Coherent Light Transport",
      "abstract": "Accurate and efficient wave-optics simulation of partially coherent light transport systems is critical for the design of advanced optical systems, ranging from computational lithography to diffraction-limited storage rings (DLSR). However, traditional approaches based on Coherent Mode Decomposition suffer from high computational costs due to the propagating massive sets of two-dimensional modes. In this paper, we propose the Coherent Mode Decoupling (CMDC) algorithm, a high-throughput computational framework designed to accelerate these simulations by orders of magnitude without compromising physical fidelity. The method factorizes 2D modes into efficient one-dimensional (1D) components, while crucially incorporating a subspace compression strategy to capture non-separable coupling effects. We demonstrated the generality and robustness of this framework in applications ranging from computational lithography to coherent beamlines of DLSR.",
      "authors": [
        "Han Xu",
        "Ming Li",
        "Shuo Wang",
        "Zhe Ren",
        "Peng Liu",
        "Yi Zhang",
        "Yuhui Dong",
        "Liang Zhou"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-22 09:06:44+00:00",
      "link": "https://arxiv.org/pdf/2601.15776v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15769v1",
      "title": "Explainable deep-learning detection of microplastic fibers via polarization-resolved holographic microscopy",
      "abstract": "Reliable identification of microplastic fibers is crucial for environmental monitoring but remains analytically challenging. We report an explainable deep-learning framework for classifying microplastic and natural microfibers using polarization-resolved digital holographic microscopy. From multiplexed holograms, the complex Jones matrix of each fiber was reconstructed to extract polarization eigen-parameters describing optical anisotropy. Statistical descriptors of nine polarization characteristics formed a 72-dimensional feature vector for a total of 296 fibers spanning six material classes, including polyamide 6, polyethylene terephthalate, polyamide 6.6, polypropylene, cotton and wool. The designed fully connected deep neural network achieved an accuracy of 96.7 % on the validation data, surpassing that of common machine-learning classifiers. Explainable artificial intelligence analysis with Shapley additive explanations identified eigenvalue-ratio quantities as dominant predictors, revealing the physical basis for classification. An additional reduced-feature model with the preserved architecture exploiting only these most significant eigenvalue-based characteristics retained high accuracy (93.3 %), thereby confirming their dominant role while still outperforming common machine-learning classifiers. These results establish polarization-based features as distinctive optical fingerprints and demonstrate the first explainable deep-learning approach for automated microplastic fiber identification.",
      "authors": [
        "Jan Appel",
        "Marika Valentino",
        "Lisa Miccio",
        "Vittorio Bianco",
        "Raffaella Mossotti",
        "Giulia Dalla Fontana",
        "Miroslav Ježek",
        "Pietro Ferraro",
        "Jaromír Běhal"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "physics.data-an"
      ],
      "published": "2026-01-22 08:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.15769v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15662v1",
      "title": "Emergence of spatiotemporal patterns in a fuel-driven coupled cooperative supramolecular system",
      "abstract": "Chemically fueled supramolecular systems can exhibit complex, time-dependent behaviors reminiscent of living matter when maintained far from equilibrium by continuous energy or fuel consumption. Here, we introduce a minimal reaction-diffusion model that captures the essential dynamics of a cooperative supramolecular polymerization network driven by monomer activation and deactivation. We show that a balance between autocatalytic growth and inhibitory decay sustains a nonequilibrium steady state in the model that undergoes a Hopf bifurcation, giving rise to autonomous oscillations. When spatial transport is introduced through diffusion, the system displays rich spatiotemporal phenomena, such as traveling wavefronts and transient polygonal patterns. Our results demonstrate that the interplay between reaction kinetics and diffusion can spontaneously generate self-organized, life-like dynamics in synthetic supramolecular polymer systems. This theoretical framework not only bridges molecular self-assembly and active matter dynamics but also provides design principles for creating adaptive, oscillatory, and self-patterning materials powered by chemical fuels.",
      "authors": [
        "Akta Singh",
        "Nayana Mukherjee",
        "Jagannath Mondal",
        "Pushpita Ghosh"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "physics.chem-ph"
      ],
      "published": "2026-01-22 05:22:11+00:00",
      "link": "https://arxiv.org/pdf/2601.15662v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15604v1",
      "title": "Adaptive information-maximization encoding for ghost imaging--A general Bayesian framework under experimental physical constraints",
      "abstract": "Ghost imaging (GI) has demonstrated diverse imaging capabilities enabled by its encoding-decoding-based computational imaging mechanism. Accordingly, information-theoretic studies have emerged as a promising avenue for probing the fundamental performance bounds of of GI and related computational imaging paradigms. However, the design of information-theoretically optimal encoding strategies remains largely unexplored, primarily due to the intractability of the prior probability density function (PDF) of an unknown scene. Here, by leveraging the ability of recursively estimating the PDF of the object to be imaged via Bayesian filtering, we propose to establish an adaptive information-maximization encoding (AIME) design framework. Based on the adaptively estimated posterior PDF from previously acquired measurements, the expected information gain of subsequent detections is evaluated and maximized to design the corresponding encoding patterns in a closed-loop manner. Within this framework, the theoretical form of the information-optimal encoding under representative physical constraints is analytically derived. Corresponding experimental results show that, GI systems employing information-optimal encoding achieve markedly improved imaging performance compared with conventional fixed point-to-point imaging without relying on additional heuristic regularization schemes, particularly in low signal-to-noise ratio regimes. Moreover, the proposed strategy consistently enables significantly enhanced information acquisition capability compared with existing encoding strategies, leading to substantially improved imaging quality. These results establish a principled information-theoretic foundation for optimal encoding design in computational imaging paradigms,provided that the forward model can be accurately characterized.",
      "authors": [
        "Jianshuo Sun",
        "Chenyu Hu",
        "Zynwang Bo",
        "Zhentao Liu",
        "Mengyu Chen",
        "Longkun Du",
        "Weitao Liu",
        "Shensheng Han"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-22 03:05:50+00:00",
      "link": "https://arxiv.org/pdf/2601.15604v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15581v1",
      "title": "Head-wearable Holographic Head-mounted Display with 6 Degrees of Freedom",
      "abstract": "A head-mounted display (HMD) using holography technology (holo-HMD) is expected to be the next generation of HMDs capable of reducing three-dimensional sickness. In HMDs, it is important to generate images that respond to head movement in real time. However, in holo-HMDs, generation of hologram data in real time is difficult due to the large computational resources required. This paper proposes a fast calculation algorithm for generating hologram data for holo-HMDs, which requires low computational power. A holo-HMD supporting six degrees of freedom was also developed using this algorithm and it was confirmed that it obtained reconstructed images with six degrees of freedom in real time (30 fps or more).",
      "authors": [
        "Taichi Sakakihara",
        "Teppei Jodo",
        "Seok Kang",
        "Yuji Sakamoto"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-22 02:02:53+00:00",
      "link": "https://arxiv.org/pdf/2601.15581v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16180v1",
      "title": "Studying energy-resolved transport with wavepacket dynamics on quantum computers",
      "abstract": "Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.",
      "authors": [
        "Melody Lee",
        "Roland C. Farrell"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.dis-nn"
      ],
      "published": "2026-01-22 18:30:30+00:00",
      "link": "https://arxiv.org/pdf/2601.16180v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16144v1",
      "title": "Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory",
      "abstract": "In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule.",
      "authors": [
        "Tetsuro Abe",
        "Shu Tanaka"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-22 17:36:32+00:00",
      "link": "https://arxiv.org/pdf/2601.16144v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16111v1",
      "title": "Transition in Splitting Probabilities of Quantum Walks",
      "abstract": "We investigate the splitting probability of a monitored continuous-time quantum walk with two targets and show that, in stark contrast to a classical random walk, it exhibits a nonanalytic, phase-transition-like behavior controlled by the sampling time at the targets. For large systems and sampling times smaller than a critical value $τ_c = 2π/ΔE$, where $ΔE$ is the energy bandwidth, the splitting probability is universal and equal to $1/2$, independent of the initial condition and the sampling time. Above the critical sampling, a nonuniversal regime emerges in which the splitting probability deviates from $1/2$ and develops a fluctuating pattern of pronounced peaks and dips dependent on both the sampling time and the initial condition. These results follow from a nontrivial mapping of the splitting problem onto a pair of single-target detection problems enabled by the superposition principle.",
      "authors": [
        "Prashant Singh",
        "David A. Kessler",
        "Eli Barkai"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-22 16:57:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16111v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16055v1",
      "title": "Facile Optimization of Combinatorial Sputtering Processes with Arbitrary Numbers of Components for Targeted Compositions",
      "abstract": "Combinatorial sputtering is a physical vapor deposition method that enables the high-throughput synthesis of compositionally varied thin films. Using this technique, the effects of stoichiometry on specific properties of alloy thin films with analog composition gradients can be mapped using high-throughput characterization. To obtain specific stoichiometries, such as those desired for an equiatomic, intermetallic, or doped compounds, the sputter power of each target must be simultaneously tuned to optimize the deposition rate of each component. This optimization problem increases in complexity with the number of components, which commonly leads to iterative guess-and-check processing and can limit the intrinsic high-throughput advantages of this synthesis method. To circumvent this challenge, this work introduces a composition optimization procedure that enables the facile synthesis of sputtered combinatorial films with targeted compositions. This procedure leverages the expeditious mapping of composition using wavelength dispersive x-ray fluorescence and is capable of optimizing processing for an arbitrary number of components. As a demonstration, this method is leveraged to sputter a combinatorial Cr$_{v}$Fe$_{w}$Mo$_{x}$Nb$_{y}$Ta$_{z}$ film with an equiatomic composition near the wafer center.",
      "authors": [
        "Shelby Sutton Fields",
        "Christopher David White",
        "Keith Knipling",
        "Steven Bennett"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-22 15:39:38+00:00",
      "link": "https://arxiv.org/pdf/2601.16055v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16029v1",
      "title": "The flux of particles in a one-dimensional Fleming-Viot process",
      "abstract": "The Fleming-Viot process describes a system of $N$ particles diffusing on a graph with an absorbing site. Whenever one of the particles is absorbed, it is replaced by a new particle at the position of one of the $N-1$ remaining particles. Here we consider the case where the particles lie on the semi-infinite line with a biased diffusion towards the origin which is the absorbing site. In the large $N$ limit, the evolution of the density becomes deterministic and has a number of characteristics similar to the Fisher-KPP equation: a one-parameter family of steady state solutions, dependence of the long time asymptotics on the initial conditions, Bramson logarithmic shift, etc. One noticeable difference, however, is that in the Fleming-Viot case, the solution can be computed explicitly for arbitrary initial conditions and at an arbitrary time. By modifying the diffusion rule near the origin, one can produce a transition in the flux of absorbed particles, very similar to the pushed-pulled transition in travelling waves. Lastly, using a cut-off approximation (which is known to be correct in the theory of travelling waves), we derive a number of predictions for the leading large $N$ correction of the flux of absorbed particles.",
      "authors": [
        "Éric Brunet",
        "Bernard Derrida"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-22 14:57:09+00:00",
      "link": "https://arxiv.org/pdf/2601.16029v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16006v1",
      "title": "Coarsening dynamics of fingerprint labyrinthine patterns: Machine learning assisted characterization",
      "abstract": "Fingerprint labyrinthine patterns exhibit a level of structural complexity beyond simple stripe phases, combining local stripe order with a dense network of point-like defects. Unlike symmetry-breaking phases, where coarsening proceeds via diffusive defect annihilation, or conventional stripe phases, where curvature-driven motion of extended grain boundaries dominates, the coarsening of fingerprint labyrinths is governed primarily by localized junction and terminal defects. Using the Turing-Swift-Hohenberg equation, we study the nonequilibrium relaxation of fingerprint labyrinthine patterns following a quench. To go beyond conventional Fourier-based diagnostics, we employ a template-matching convolutional neural network (TM-CNN) to identify and track junctions and terminals directly in real space, enabling a quantitative characterization of defect statistics and spatial correlations. We show that, although these point-like defects drive coarsening, their motion is strongly constrained by the surrounding stripe geometry, leading to slow, nondiffusive dynamics that are qualitatively distinct from both conventional phase ordering and stripe coarsening. Together, these results establish defect-mediated dynamics as the central organizing principle of fingerprint labyrinthine coarsening and demonstrate the effectiveness of machine-learning-assisted approaches for complex pattern-forming systems.",
      "authors": [
        "Supriyo Ghosh",
        "Vinicius Yu Okubo",
        "Kotaro Shimizu",
        "B. S. Shivaram",
        "Hae Yong Kim",
        "Gia-Wei Chern"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "nlin.PS"
      ],
      "published": "2026-01-22 14:32:25+00:00",
      "link": "https://arxiv.org/pdf/2601.16006v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16000v1",
      "title": "Hysteretic Excitation in Non-collinear Antiferromagnetic Spin-Torque Oscillators: A Terminal Velocity Motion Perspective",
      "abstract": "We present a theoretical framework for non-collinear antiferromagnetic spin torque oscillators (NC-AFM STO) by unifying spin dynamics under the Poisson Bracket formalism. Shifting from traditional torque-based descriptions to an operational symmetry perspective, we develop two complementary viewpoints: a vector perspective identifying infinite degenerate Rigid Body Precession (RBP) states where exchange energy depends solely on the total magnetic momentum, and a particle perspective decomposing dynamics into Center-of-Mass (CM) translation and Relative Motion (RM) oscillation. Using time-dependent rotational and translational transformation techniques, we analytically resolve the rapid (~10 ps) transient evolution into a stable RBP state driven by SOT and damping. We demonstrate that the out-of-plane anisotropy (OPA) lifts the exchange degeneracy, triggering a long-term (~1 ns) oscillatory decay toward a steady state characterized by uniform spin z-components and a 120-degree inter-spin locking angle. This state is accurately governed by our Terminal Velocity Motion (TVM) model [arXiv:2305.14013], where exchange coupling transforms into kinetic energy with a light effective mass. The model precisely predicts SOT-driven transients, hysteretic excitation, and the dynamic phase diagram. Finally, we account for the sub-critical current regime mismatch by identifying a 'Rigid-Body Breaking' effect: a surge in effective friction caused by the self-resonance of RM variables induced by CM translation, mediated by the in-plane anisotropy (IPA).",
      "authors": [
        "Hao-Hsuan Chen",
        "Ching-Ming Lee"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall"
      ],
      "published": "2026-01-22 14:19:52+00:00",
      "link": "https://arxiv.org/pdf/2601.16000v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15439v1",
      "title": "Dissipative Quantum Dynamics in Static Network with Different Topologies",
      "abstract": "We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems.",
      "authors": [
        "Wei-Yang Liu",
        "Hsuan-Wei Lee"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-21 20:08:07+00:00",
      "link": "https://arxiv.org/pdf/2601.15439v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15149v1",
      "title": "Biphasic Meniscus Coating for Scalable and Material Efficient Quantum Dot Films",
      "abstract": "Colloidal quantum dots (cQDs) have emerged as a cornerstone of next-generation optoelectronics, offering unparalleled spectral tunability and solution-processability. However, the transition from laboratory-scale devices to sustainable industrial manufacturing is fundamentally hindered by spin-coating workflows, which are intrinsically wasteful and restricted to planar geometries. These limitations are particularly acute for high-performance cQDs containing regulated elements such as lead, cadmium, or mercury, where poor material utilization exacerbates both environmental burden and cost. Here we report a biphasic dip-coating strategy that redefines the material efficiency of nanocrystal film fabrication. By utilizing an immiscible underlayer to displace ~88% of the active reservoir volume, we demonstrate a deposition geometry that decouples material consumption from total precursor volume. Infrared PbS photodetectors fabricated via this approach maintain their performance against spin-coated benchmarks while reducing ink consumption by up to 20-fold. Our technoeconomic analysis reveals that this biphasic architecture achieves cost parity at film thicknesses an order of magnitude lower than conventional monophasic dip-coating. Our results establish a low-waste framework for solution-processed materials, providing a viable pathway for the resource-efficient manufacturing of optoelectronic devices.",
      "authors": [
        "Shlok Joseph Paul",
        "Letian Li",
        "Zheng Li",
        "Andrew Kim",
        "Mia Klopfestein",
        "Stephanie S. Lee",
        "Ayaskanta Sahu"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall"
      ],
      "published": "2026-01-21 16:21:02+00:00",
      "link": "https://arxiv.org/pdf/2601.15149v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15227v1",
      "title": "Reassessing CP Violation in the C2HDM with Machine Learning",
      "abstract": "We provide a study of the parameter space of the complex 2-Higgs Doublet Model (C2HDM), focusing on signs of large CP-violating couplings of the 125 GeV Higgs boson with the fermions. The study is performed utilizing Machine Learning (ML) techniques developed recently for parameter space exploration, including an Evolutionary Strategy Algorithm and Novelty Reward. We give particular attention to the electron electric dipole moment (eEDM). We confirm that the recently found kite diagrams are crucial for the outcome of the analysis. Moreover, their use also mitigates the dependence of the results on the scale and scheme choice of the masses in the loop diagrams. We furthermore point out that, already at the current level of experimental precision, the Barr-Zee diagrams with charm quark loops must be taken into account. The combined use of kite diagrams and ML techniques allows for the resurrection of large fermion CP-odd couplings for Type-II and Flipped C2HDM when the 125 GeV Higgs coincides with the second lightest neutral scalar. This arises due to cancellations, typically of the per-mil order, which, moreover, will still be possible for a foreseeable eEDM precision down to $10^{-33}$ e.cm. For these cases, the constraints on the CP-odd couplings arises from the precision LHC measurements.",
      "authors": [
        "Rafael Boto",
        "Karim Elyaouti",
        "Duarte Fontes",
        "Maria Gonçalves",
        "Margarete Mühlleitner",
        "Jorge C. Romão",
        "Rui Santos",
        "João P. Silva"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-01-21 18:02:51+00:00",
      "link": "https://arxiv.org/pdf/2601.15227v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15147v1",
      "title": "Chemical evolution of antimatter domains in early Universe",
      "abstract": "According to modern physics, our Universe is baryon-asymmetric. That phenomenon can not be described in the frameworks of the Standard Model of particle physics. Globally, the Universe consists of baryon matter. However, some scenarios can lead to the existence of local antimatter domains. In the research, the chemical evolution of such an isolated antimatter domain, surrounded by baryonic matter, is studied. The size of the domain is estimated according to the conditions of its survival in baryon surrounding, and the process of annihilation at its border is taken into account.",
      "authors": [
        "A. I. Dembitskaia",
        "Stephane Weiss",
        "M. Yu. Khlopov",
        "M. A. Krasnov"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph",
        "astro-ph.CO"
      ],
      "published": "2026-01-21 16:19:56+00:00",
      "link": "https://arxiv.org/pdf/2601.15147v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16099v1",
      "title": "Matrix Bootstrap Approximation without Positivity Constraint",
      "abstract": "We propose a bootstrap approximation method for the Hermitian one-matrix model that does not rely on positivity constraints. The theoretical foundation of this method is that the one-matrix model admits an eigenvalue distribution $ρ(λ)$, and that the moments $w_n$ generated from it satisfy the loop equations. Our framework is designed to numerically determine a self-consistent pair of $ρ(λ)$ and $w_n$ that simultaneously satisfies these two requirements. In the concrete implementation, we employ a least-squares method, for which no sign problem arises in principle, and therefore the method can be formally applied also to Minkowski-type models. Actual numerical calculations show that this bootstrap approximation reproduces, with very high accuracy, the exact solutions for Euclidean-type models and the perturbative results for Minkowski-type models.",
      "authors": [
        "Reishi Maeta"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th"
      ],
      "published": "2026-01-22 16:47:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16099v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15612v1",
      "title": "Gravitational equal-area law and critical phenomena of cuspy black hole shadow",
      "abstract": "The formation of a cusp on a black hole shadow is a striking signature of physics beyond the Kerr paradigm. We demonstrate that this morphological change fundamentally alters the shadow's topology with the topological charge flipping from 1 to -1. To analyze this topological transition, we introduce a gravitational equal-area law, analogous to Maxwell's construction in thermodynamics, and identify a critical point for cusp formation. Near this point, we uncover universal behavior characterized by a critical exponent 1/2, which places this gravitational lensing system within the mean-field universality class. These results establish a new framework for testing fundamental physics of black hole shadows, reframing the search for deviations from general relativity as a targeted hunt for a distinct topological and critical phenomenon.",
      "authors": [
        "Shao-Wen Wei",
        "Chao-Hui Wang",
        "Yu-Peng Zhang",
        "Yu-Xiao Liu",
        "Robert B. Mann"
      ],
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-01-22 03:26:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15612v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16190v1",
      "title": "Evolution of the recent high-accretion state of the recurrent nova T CrB: HST, Swift, NuSTAR, and XMM-Newton observations",
      "abstract": "As the recurrent nova T Coronae Borealis (T CrB) approaches its next predicted thermonuclear eruption, it is currently exhibiting a \"super-active state\" (SAS) characterized by enhanced multiwavelength emission similar to the behavior recorded prior to the 1946 outburst. We present a multiwavelength analysis of the SAS and the subsequent \"faint state\" using observations from HST, Swift, NuSTAR, and XMM-Newton. Our results indicate that the SAS was driven by an increase in the mass accretion rate, which caused the accretion disk's boundary layer to become optically thick. A weighted least squares regression analysis quantifies the evolution of the accretion components, displaying a highly significant (4.5$σ$) increase in the luminosity of the optically thin cooling flow (L$_{cf}$) and a marginal (2.58$σ$) decrease in the optically thick boundary layer luminosity (L$_{bb}$) as the system transitioned into the faint state. We find that this dimming is consistent with an intrinsic change in the accretion flow rather than dust obscuration, supported by the lack of infrared excess and the stability of the 2175 Å feature. Additionally, a time-series analysis using autoregressive modeling to account for correlated red noise revealed no significant periodicities, thereby disputing the previously reported $\\sim$6000 s signal. These findings suggest that the pre-outburst evolution of T CrB is characterized by significant changes in the accretion disk structure and boundary layer, providing a self-consistent physical framework for the system's behavior as it approaches eruption.",
      "authors": [
        "G. J. M. Luna",
        "N. P. M. Kuin",
        "K. Mukai",
        "J. L. Sokoloski",
        "K. Page",
        "J. P. Osborne"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.SR"
      ],
      "published": "2026-01-22 18:42:04+00:00",
      "link": "https://arxiv.org/pdf/2601.16190v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16159v1",
      "title": "Magnetar fraction in Core-Collapse Supernovae",
      "abstract": "Magnetars are extreme neutron stars powered by ultra-strong magnetic fields ($\\sim10^{14}$ Gauss) and are compelling engines for some of the most powerful extragalactic transients such as Super Luminous Supernovae, Gamma-Ray Bursts, and Fast Radio Bursts. Yet their formation rate relative to ordinary neutron stars remains uncertain, often precluding direct comparisons with the rates of these extragalactic transients. Furthermore, magnetars have been recently shown to be evolutionarily related to other neutron star classes, complicating the estimate of the exact magnetar fraction within the neutron star population. We study the magnetar birth fraction in core-collapse supernovae using pulsar population synthesis of all isolated neutron star classes in our Galaxy, incorporating self-consistently the Galactic dynamical evolution, spin-down and magneto-thermal evolution. This approach allows us to derive strong constraints from small close-to-complete observational samples. In particular, looking at the age-limited young ($<$2 kyr) neutron star population in the Milky Way we find 24 detected young neutron stars, with only 10 of them (41%) being classical rotational powered pulsars, while the others (59%) are either magnetars or central compact objects, the latter believed to be equally magnetically powered. We further compare the results with the nearby volume-limited class ($<$500 pc) of X-ray Dim Isolated Neutron stars, old nearby magnetars. We conclude that the observed population of isolated neutron stars in the Galaxy can be reproduced only by assuming a core-collapse supernova rate larger than two, and a larger magnetar fraction than previously inferred. By assuming a bimodal initial magnetic field ($B_0$) distribution at birth, we find that the magnetar class peaks between $B_0\\sim 1-2.5\\times10^{14}$ Gauss and represents on average $\\sim50$% of the entire neutron star population.",
      "authors": [
        "Celsa Pardo-Araujo",
        "Nanda Rea",
        "Michele Ronchi",
        "Vanessa Graber"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE"
      ],
      "published": "2026-01-22 18:00:26+00:00",
      "link": "https://arxiv.org/pdf/2601.16159v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16100v1",
      "title": "Formation and X-ray emission from hot bubbles in planetary nebulae - III. The impact of [Wolf-Rayet]-type winds",
      "abstract": "We use radiation-hydrodynamical simulations to investigate the formation and synthetic X-ray emission of hot bubbles within planetary nebulae (PNe) driven by the powerful winds of H-deficient, [Wolf-Rayet]([WR])-type stars. Our models, based on {\\sc mesa} stellar evolution tracks for 1--3 M$_{\\odot}$ progenitors, adopt a recent mass-loss rate prescription for [WR] stars and incorporate the enhanced radiative cooling of their C-rich material, comparing the results against standard H-rich PN models. The enhanced mass-loss in the [WR] models leads to an accelerated post-AGB evolution and a subsequent delay in hot bubble formation compared to their H-rich counterparts, as suggested by a previous work. By computing synthetic X-ray spectra that account for the mixed H-rich and H-deficient gas phases, we find that models incorporating [WR] winds exhibit significantly higher X-ray luminosities ($L_\\mathrm{X}$) than their H-rich counterparts, but the emissivity-weighted plasma temperature of the X-ray-emitting gas converge to values of $T_\\mathrm{X} = [1-3] \\times 10^{6}$~K, regardless of whether the system follows a [WR]-type or an H-rich post-AGB evolutionary path. Our results reinforce previous suggestions that mixing is a key mechanism in generating the observed soft X-ray emission even for PN hosting [WR] central stars.",
      "authors": [
        "Rogelio Orozco-Duarte",
        "Jesús A. Toalá",
        "S. Jane Arthur",
        "Janis B. Rodríguez-González",
        "Luke Conmy",
        "Rolf Kuiper"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.HE"
      ],
      "published": "2026-01-22 16:48:02+00:00",
      "link": "https://arxiv.org/pdf/2601.16100v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15965v1",
      "title": "Clump-like Structures in High-Redshift Galaxies: Mass Scaling and Radial Trends from JADES",
      "abstract": "Massive star-forming clumps are a prominent feature of high-redshift galaxies and are thought to trace gravitational fragmentation, feedback, and bulge growth in gas-rich disks. We present a statistical analysis of clump-like structures in $\\sim$3600 galaxies spanning $2 \\lesssim z \\lesssim 8$ from deep JWST/NIRCam imaging in the JADES GOODS--South field. Clumps are identified as residual features after subtracting smooth Sérsic profiles, enabling a uniform, rest-frame optical census of sub-galactic structure. We characterize their physical properties, size--mass relations, and spatial distributions to constrain models of sub-galactic structure formation and evolution. We find that clumps in our sample are typically low-mass ($10^{\\sim7-8}M_\\odot$), actively star-forming, and show diverse gas-phase metallicity, dust attenuation, and stellar population properties. Their sizes and average pairwise separations increase with cosmic time (toward lower redshift), consistent with inside-out disk growth. The clump mass function follows a power law with slope $α= -1.50_{-0.17}^{+0.19}$, consistent with fragmentation in turbulent disks. We find a deficit of relatively young clumps near galaxy centers and a radial transition in the size--mass relation: outer clumps exhibit steeper, near-virial slopes ($R_{\\rm e}\\propto M_*^{\\sim 0.3}$), while inner clumps follow flatter trends ($R_{\\rm e}\\propto M_*^{\\sim 0.2}$), consistent with structural evolution via migration or disruption. These results provide new constraints on the formation, survival, and dynamical evolution of clumps, highlighting their role in shaping galaxy morphology during the peak of cosmic star formation.",
      "authors": [
        "Yongda Zhu",
        "Marcia J. Rieke",
        "Zhiyuan Ji",
        "Andrew J. Bunker",
        "Courtney Carreira",
        "A. Lola Danhaive",
        "Qiao Duan",
        "Eiichi Egami",
        "Daniel J. Eisenstein",
        "Kevin Hainline",
        "Benjamin D. Johnson",
        "Zheng Ma",
        "Dávid Puskás",
        "George H. Rieke",
        "Pierluigi Rinaldi",
        "Brant Robertson",
        "Sandro Tacchella",
        "Hannah Übler",
        "Natalia C. Villanueva",
        "Christina C. Williams",
        "Christopher N. A. Willmer",
        "Zihao Wu",
        "Junyu Zhang"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-22 13:43:20+00:00",
      "link": "https://arxiv.org/pdf/2601.15965v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15958v1",
      "title": "JWST Advanced Deep Extragalactic Survey (JADES) Data Release 5: Wisp Subtraction with the Non-negative Matrix Factorization Algorithm",
      "abstract": "Wisps are among the most prominent scattered light artifacts in JWST/NIRCam imaging. They often appear in certain regions of the detectors and contaminate observations at surface-brightness levels relevant for faint-source photometry. We introduce a new subtraction method that uses the non-negative matrix factorization (NMF) algorithm to model and remove wisps. Using deep NIRCam observations from the JWST Advanced Deep Extragalactic Survey (JADES) and other programs, we construct multi-component, filter- and detector-specific wisp templates that capture the wisp structures and their exposure-to-exposure morphological variations. Wisps in individual exposures are represented as non-negative linear combinations of these templates, consistent with their additive nature and reducing degeneracies relative to single-template scaling. Compared to existing approaches, our method delivers lower residual root mean square in wisp-affected regions and reduces photometric bias and scatter to levels consistent with clean detector areas. The NMF wisp templates are readily applicable to other datasets and are publicly released to support future NIRCam extragalactic surveys.",
      "authors": [
        "Zihao Wu",
        "Benjamin D. Johnson",
        "Daniel J. Eisenstein",
        "Phillip Cargile",
        "Kevin Hainline",
        "Ryan Hausen",
        "Pierluigi Rinaldi",
        "Brant E. Robertson",
        "Sandro Tacchella",
        "Christina C. Williams",
        "Christopher N. A. Willmer"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA"
      ],
      "published": "2026-01-22 13:43:13+00:00",
      "link": "https://arxiv.org/pdf/2601.15958v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15691v1",
      "title": "Development of an early warning method incorporating pre-supernova neutrino light curves",
      "abstract": "Massive stars ($M>8\\mathrm{M_\\odot}$) emit neutrinos known as pre-supernova (pre-SN) neutrinos through thermal and nuclear interactions for cooling the stellar core during the final stage of stellar evolution. Real-time monitoring of their pre-SN neutrino interaction rate offers a crucial opportunity to issue an early warning to a core-collapse supernova. Some neutrino detectors, including KamLAND and Super-Kamiokande already operate pre-SN alarm systems based on a statistically significant excess of the observed event rate over the expected background. To improve alarm sensitivity, we propose an alarm method which incorporates the time evolution of the observed pre-SN neutrino event rate. The method uses a log likelihood ratio test that references multiple theoretical stellar-evolution models and treats the core collapse time as a nuisance parameter to be profiled over. The performance of the proposed method was evaluated using simulated data for the KamLAND, Super-Kamiokande with dissolved Gadolinium (SK-Gd) and their combined analysis. The results demonstrate a significant improvement in the warning time compared to the conventional rate-only method, while maintaining the same false alarm rate.",
      "authors": [
        "Keita Saito",
        "Minori Eizuka",
        "Zhuojun Hu",
        "Koichi Ichimura",
        "Motoyasu Ikeda",
        "Koji Ishidoshiro",
        "Nanami Kawada",
        "Lucas N. Machado",
        "Lluis Marti-Magro",
        "Kazuha Mikami",
        "Koga Tachibana",
        "Roger A. Wendell"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM"
      ],
      "published": "2026-01-22 06:26:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15691v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15619v1",
      "title": "A compact object with a K type star companion in the solar neighborhood: a wide post common envelope binary with a white dwarf candidate",
      "abstract": "Post-common envelope binaries (PCEBs) consisting of a white dwarf (WD) plus a main-sequence (MS) star can constrain current prescriptions of common envelope evolution (CEE) and calibrate theoretical models of binary formation and evolution. Most PCEBs studied to date have typical orbital periods of hours to a few days and can be well explained by assuming inefficient CEE to expel the envelope. However, there are currently several systems with relatively wide orbital periods ($>$18 days). To explain these wide PCEBs, additional sources of energy have been suggested to be taken into account. Here, we present the discovery and observational characterization of a compact object ($M\\,\\geq\\,0.58\\,\\rm M_{\\odot}$) with a K-type star companion in the solar neighborhood ($d\\sim 112$ pc) and an orbital period of $P_{\\rm orb}\\sim 14$ days. The compact object binary is likely to be a system consisting of a WD and a barium dwarf. Such a system with an orbital period within the gap between tight and wide binaries provides a test of whether additional energy sources are required to explain its formation. Using binary evolution models, we investigate the evolutionary history of this wide PCEB system and find that the observed properties of this source can be explained without invoking any extra energy source.",
      "authors": [
        "Jie Lin",
        "Hailiang Chen",
        "Bojun Wang",
        "Yudong Luo",
        "Wenshi Tang",
        "Bo Huang"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR"
      ],
      "published": "2026-01-22 03:50:14+00:00",
      "link": "https://arxiv.org/pdf/2601.15619v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15585v1",
      "title": "Multi-band Reconstruction of Sixteen Gravitational Lens Systems using PISCO data",
      "abstract": "Next-generation surveys such as the Euclid survey, the Legacy Survey of Space and Time (LSST), and the China Space Station Telescope (CSST) survey are expected to discover ~10^5 galaxy-galaxy scale strong gravitational lenses. This motivates the development of scalable and robust lens modeling approaches that can efficiently and reliably learn from wide-field survey datasets before high-resolution follow-up. We design a scalable, Bayesian, Lenstronomy-based pipeline and apply it to a sample of sixteen lens candidates observed with the Parallel Imager for Southern Cosmology Observations (PISCO) on the Magellan telescope. PISCO provides four-band imaging (z, i, r, g) with colours, depth and seeing conditions comparable to LSST. To fully exploit the constraining power of this dataset, our pipeline performs simultaneous multi-band modeling, using a common mass profile across all four bands while allowing independent light profiles in each. This approach leverages color information to provide joint constraints on the lens mass and yields reduced uncertainties compared to single-band analyses. Fifteen out of sixteen PISCO lens candidates are successfully recovered with interpretable lensing configurations, including DESJ0533-2536, the first reported hyperbolic-umbilic galaxy-galaxy scale strong lensing candidate. We further assess how much model complexity can be reliably constrained given the resolution and seeing of PISCO-like data. Overall, our results demonstrate that scalable, multi-band lens modeling of ground-based data can extract meaningful constraints on mass and source morphology, providing a practical pathway to maximize the scientific return from large samples in upcoming surveys.",
      "authors": [
        "Huimin Qu",
        "Daniel J. Ballard",
        "Geraint F. Lewis",
        "Karl Glazebrook",
        "Antony Stark",
        "Sarah M. Sweet",
        "Colin Jacobs",
        "Kim-Vy Tran",
        "Brian Stalder",
        "Tania M. Barone",
        "Tucker Jones",
        "Keerthi Vasan G. C.",
        "Thomas E. Collett",
        "Glenn G. Kacprzak",
        "Dorota Bayer"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-22 02:15:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15585v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15583v1",
      "title": "Mapping dark matter and the emergence of large-scale structure",
      "abstract": "We discuss a potential survey to map dark matter and the emergence of large-scale structure to redshift z ~ 1.5 (baseline) or z~3.5 (with near-IR extension) using a massively multiplexed spectrograph on a 10m-class telescope, such as the proposed Widefield Spectroscopic Telescope.",
      "authors": [
        "Jon Loveday",
        "Jochen Liske",
        "Ivan K. Baldry",
        "Simon P. Driver",
        "Aaron Robotham",
        "Sabine Bellstedt",
        "Luke Davies",
        "Trystan Lambert"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.IM"
      ],
      "published": "2026-01-22 02:07:04+00:00",
      "link": "https://arxiv.org/pdf/2601.15583v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15460v1",
      "title": "Constraining nonminimal f(T) gravity from Primordial Nucleosynthesis to Late-Universe observations",
      "abstract": "We present a multi-epoch test of f(T) gravity with nonminimal torsion-matter coupling, combining early- and late-Universe observations. At the MeV scale, Big-Bang Nucleosynthesis constrains the fractional variation of the weak freeze-out temperature, |δτ_f/τ_f|, thereby mapping light-element abundances into limits on deviations from the standard expansion history. At low redshift, we confront the model with type Ia supernovae, baryon acoustic oscillations, and cosmic-chronometer data, which respectively probe distances, the late-time standard ruler, and the Hubble rate. Independent analyses highlight the complementary roles of each dataset, while a joint SNe Ia + BAO + CC fit breaks degeneracies and yields the tightest combined bounds. As an illustration, we examine two representative torsion-modified gravity scenarios: BBN strongly limits large departures from standard cosmology, whereas late-time probes remain compatible with a near-ΛCDM background. This unified approach demonstrates the power of linking early-Universe nuclear physics with precision cosmological observables in assessing torsional extensions of gravity.",
      "authors": [
        "Yahia Al-Omar",
        "Majida Nahili",
        "Nidal Chamoun"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-01-21 20:55:54+00:00",
      "link": "https://arxiv.org/pdf/2601.15460v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15387v1",
      "title": "Solar twins in Gaia DR3 GSP-Spec I. Building a large catalog of Solar twins with ages",
      "abstract": "[Abbreviated] Context. Solar twins, stars whose stellar parameters (Teff, log g, and [M/H]) are very close to the Solar ones, offer a unique opportunity to investigate Galactic archaeology with very high accuracy and precision. However, most previous catalogs of Solar twins contain only a small number of objects (typically a few tens), and their selection functions are poorly characterized. Aims. We aim at building a large catalog of Solar twins from Gaia DR3 GSP-Spec, providing model-driven, rather than data-driven, stellar parameters including ages, together with a well-characterized selection function. Methods. Using stellar parameters from the Gaia DR3 GSP-Spec catalog, we selected Solar-twin candidates whose parameters lie within +- 200 K in Teff, +- 0.2 in log g, and +- 0.1 dex in [M/H] of the Solar values. Candidates unlikely to be genuine Solar twins were removed using Gaia flags and photometric constraints. We determined accurate ages for individual twins with a Bayesian isochrone-projection method, considering three combinations of parameters: Teff, [M/H], and either log g, M_G, or M_Ks. We also constructed a mock catalog to characterize the selection function. Results. Our final GSP-Spec Solar-twin catalog contains 6,594 stars. The mock catalog consisting of 75,588 artificial twins well reproduces the main characteristics of the observed catalog, especially for ages determined with M_G or M_Ks. To demonstrate the usefulness of our catalog, we compared chemical abundances [X/Fe] with age. We statistically confirmed the age--[X/Fe] relations for several species (e.g., Al, Si, Ca, and Y), demonstrating that trends previously identified in small but very high-precision samples persist in a much larger, independent sample. Conclusions. Our study bridges small high-precision Solar-twin samples and large data-driven ones, enabling demographic studies of Solar twins.",
      "authors": [
        "Daisuke Taniguchi",
        "Patrick de Laverny",
        "Alejandra Recio-Blanco",
        "Takuji Tsujimoto",
        "Pedro A. Palicio"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA"
      ],
      "published": "2026-01-21 19:02:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15387v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15382v1",
      "title": "A Stratification in Magnetic Field Structures: The Radio Outflow in NGC 4151",
      "abstract": "The nature of radio outflows in radio-quiet AGN remains poorly understood. In this study, we present kpc-scale polarization observations of the Seyfert galaxy NGC\\,4151 using the Karl G. Jansky Very Large Array (VLA) in B-array at 3 and 10 GHz. We find that the inferred magnetic (B-) field structures show a stratification: a `spine-sheath'-like structure, with fields perpendicular to the jet direction in the `spine' and parallel in the `sheath', is observed in the higher resolution (0.5 arcsec) image at 10 GHz. In addition, a `wind'-like component with B-fields perpendicular to the radio outflow is observed in the 3 GHz image (resolution 2 arcsec); this feature is prominent along the `receding' (eastern) jet direction. Rotation measure (RM) ranges from $-230$ to 250 rad m$^{-2}$ over the polarized regions, indicating a low-electron-density ($10^{-2}-10^{-3}$ cm$^{-3}$) tenuous medium surrounding the source causing Faraday rotation. A {tentative} RM gradient of $+75$ to $-25$ rad m$^{-2}$ is observed transverse to the northern `wind' component, while a similar gradient with opposite sign is seen across the southern `wind' component, suggestive of a helical magnetic field threading the outflow. Based on an analysis of the available radio and X-ray data, we conclude that the stratified radio outflow in NGC 4151 is magnetically-driven. The bi-conical radio `wind' is found to be massive ($1050-3200 M_\\odot$) with a high mass outflow rate ($0.01-0.03$ M$_\\odot$ yr$^{-1}$) but low in kinetic power ($<0.01$% of L$_{\\rm{bol}}$), making it less impactful for galactic-scale feedback. Our study suggests that radio-quiet AGN may also host magnetically dominant jets and winds, even while their jets are smaller and weaker compared to radio-loud AGN.",
      "authors": [
        "Salmoli Ghosh",
        "P. Kharb",
        "E. Costantini",
        "J. Gallimore",
        "D. Williams-Baldwin",
        "M. Mehdipour"
      ],
      "primary_category": "astro-ph.GA",
      "categories": [
        "astro-ph.GA"
      ],
      "published": "2026-01-21 19:01:13+00:00",
      "link": "https://arxiv.org/pdf/2601.15382v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15378v1",
      "title": "The Back-in-time Void Finder: dynamical identification of cosmic voids through optimal transport reconstruction",
      "abstract": "Cosmic voids have increasingly emerged as a powerful cosmological probe. However, their large spatial extent and intrinsically underdense environments make their identification highly sensitive to shot noise, redshift-space distortions (RSD), and observational systematics, particularly for topological and density-based void definitions. We introduce the Back-In-Time Void Finder (BitVF), a novel dynamical and physically motivated algorithm that identifies cosmic voids as regions of negative divergence of the Lagrangian displacement field reconstructed from the present-day tracer distribution. The reconstruction relies on an optimized discrete optimal transport algorithm that recovers the backward-in-time dynamics of tracers, naturally accounting for tracer bias without relying on cosmological assumptions. We validate BitVF against the widely used topological void finder REVOLVER using high-resolution N-body simulations, showing that it produces void catalogs with smoother and more physically motivated density profiles, as well as abundances that are more stable under tracer subsampling and shot noise. We further apply it to realistic DESI-like mock light-cone galaxy catalogs, demonstrating that it intrinsically mitigates redshift-space systematic effects, preserving real-space void size functions more faithfully than topological methods. Modeling RSD, the reconstruction can be combined with a fiducial cosmology and an assumed tracer bias within a bias-corrected Kaiser framework, yielding reconstructed-space void catalogs consistent with real-space statistics across redshift. Its performance is characterized as a function of the main internal parameters, showing an optimal balance between accuracy, computational efficiency, and applicability to stage IV galaxy surveys. BitVF will be publicly released within the CosmoBolognaLib.",
      "authors": [
        "Simone Sartori",
        "Sofia Contarini",
        "Elena Sarpa",
        "Giulia Degni",
        "Federico Marulli",
        "Stephanie Escoffier",
        "Lauro Moscardini"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-01-21 19:00:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15378v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15371v1",
      "title": "Digging into the Interior of Hot Cores with ALMA (DIHCA). VII. Disk candidates around high-mass stars and evidence of anisotropic infall",
      "abstract": "We study the kinematics of condensations in 30 fields forming high-mass stars with ALMA at a high-resolution of ~0.08'' on average (~230 au). The presence of disks is important for feeding high-mass stars without feedback halting growth as their masses increase. In the search for velocity gradients resembling rotation that can reveal the presence of disks, we analyze the emission of gas tracers in 49 objects using CH$_3$OH, CH$_3$CN, and tentative detections of HNCO and cis-HCOOH. Most of the velocity distributions show velocity gradients indicative of rotation. We reveal a total of 32 disk candidates, the largest sample to date that has been uniformly analyzed at a few hundred au scales in the high-mass regime. Their position-velocity maps are generally asymmetric with one side brighter than the opposite. We successfully fit a power law to the position-velocity maps of the disk candidates and find indices between -0.5 (Keplerian rotation) and -1 (rotation under specific angular momentum conservation) with a median of -0.7. Under Keplerian rotation assumption, we estimate central masses, uncorrected for inclination, ranging between 7 to 45 M$_\\odot$. Excluding outliers, the disk candidates are relatively more compact (<200 au) and less massive (<5 M$_\\odot$) than previous results at coarser angular resolution. We calculate an average Toomre-$Q$ parameter and find that most are gravitationally unstable (median of 0.5). We conclude that these observations offer the first opportunity to separate the disk and envelope components of hot cores on a statistically significant sample, and confirm that anisotropic collapse plays an role in feeding high-mass (proto)stars.",
      "authors": [
        "Fernando A. Olguin",
        "Patricio Sanhueza",
        "Yoko Oya",
        "Adam Ginsburg",
        "Maria T. Beltrán",
        "Kaho Morii",
        "Roberto Galván-Madrid",
        "Huei-Ru Vivien Chen",
        "Qiuyi Luo",
        "Kei E. I. Tanaka",
        "Suinan Zhang",
        "Yu Cheng",
        "Fumitaka Nakamura",
        "Shanghuo Li",
        "Kotomi Taniguchi",
        "Guido Garay",
        "Qizhou Zhang",
        "Masao Saito",
        "Takeshi Sakai",
        "Xing Lu",
        "Jixiang Weng",
        "Andrés E. Guzmán"
      ],
      "primary_category": "astro-ph.SR",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA"
      ],
      "published": "2026-01-21 19:00:00+00:00",
      "link": "https://arxiv.org/pdf/2601.15371v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16206v1",
      "title": "LLM-in-Sandbox Elicits General Agentic Intelligence",
      "abstract": "We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.",
      "authors": [
        "Daixuan Cheng",
        "Shaohan Huang",
        "Yuxian Gu",
        "Huatong Song",
        "Guoxin Chen",
        "Li Dong",
        "Wayne Xin Zhao",
        "Ji-Rong Wen",
        "Furu Wei"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-22 18:57:09+00:00",
      "link": "https://arxiv.org/pdf/2601.16206v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16174v1",
      "title": "Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints",
      "abstract": "Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.",
      "authors": [
        "Yiyao Yang"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-22 18:19:52+00:00",
      "link": "https://arxiv.org/pdf/2601.16174v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16171v1",
      "title": "Non-Linearly Separable Distributed Computing: A Sparse Tensor Factorization Approach",
      "abstract": "The work considers the $N$-server distributed computing setting with $K$ users requesting functions that are arbitrary multi-variable polynomial evaluations of $L$ real (potentially non-linear) basis subfunctions. Our aim is to seek efficient task-allocation and data-communication techniques that reduce computation and communication costs. Towards this, we take a tensor-theoretic approach, in which we represent the requested non-linearly decomposable functions using a properly designed tensor $\\bar{\\mathcal{F}}$, whose sparse decomposition into a tensor $\\bar{\\mathcal{E}}$ and matrix $\\mathbf{D}$ directly defines the task assignment, connectivity, and communication patterns. We here design an achievable scheme, employing novel fixed-support SVD-based tensor factorization methods and careful multi-dimensional tiling of subtensors, yielding computation and communication protocols whose costs are derived here, and which are shown to perform substantially better than the state of art.",
      "authors": [
        "Ali Khalesi",
        "Ahmad Tanha",
        "Derya Malak",
        "Petros Elia"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 18:16:19+00:00",
      "link": "https://arxiv.org/pdf/2601.16171v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16142v1",
      "title": "Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic Games",
      "abstract": "The problem of determining the (least) fixpoint of (higher-dimensional) functions over the non-negative reals frequently occurs when dealing with systems endowed with a quantitative semantics. We focus on the situation in which the functions of interest are not known precisely but can only be approximated. As a first contribution we generalize an iteration scheme called dampened Mann iteration, recently introduced in the literature. The improved scheme relaxes previous constraints on parameter sequences, allowing learning rates to converge to zero or not converge at all. While seemingly minor, this flexibility is essential to enable the implementation of chaotic iterations, where only a subset of components is updated in each step, allowing to tackle higher-dimensional problems. Additionally, by allowing learning rates to converge to zero, we can relax conditions on the convergence speed of function approximations, making the method more adaptable to various scenarios. We also show that dampened Mann iteration applies immediately to compute the expected payoff in various probabilistic models, including simple stochastic games, not covered by previous work.",
      "authors": [
        "Paolo Baldan",
        "Sebastian Gurke",
        "Barbara König",
        "Florian Wittbold"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.LG"
      ],
      "published": "2026-01-22 17:36:19+00:00",
      "link": "https://arxiv.org/pdf/2601.16142v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.16097v1",
      "title": "Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating",
      "abstract": "Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.",
      "authors": [
        "Makbule Gulcin Ozsoy"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-22 16:46:57+00:00",
      "link": "https://arxiv.org/pdf/2601.16097v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16028v1",
      "title": "Data-Driven Conditional Flexibility Index",
      "abstract": "With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.",
      "authors": [
        "Moritz Wedemeyer",
        "Eike Cramer",
        "Alexander Mitsos",
        "Manuel Dahmen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 14:56:10+00:00",
      "link": "https://arxiv.org/pdf/2601.16028v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15953v1",
      "title": "Decoupling Return-to-Go for Efficient Decision Transformer",
      "abstract": "The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.",
      "authors": [
        "Yongyi Wang",
        "Hanyu Liu",
        "Lingfeng Li",
        "Bozhou Chen",
        "Ang Li",
        "Qirui Zheng",
        "Xionghui Yang",
        "Wenxin Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 13:42:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15953v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15928v1",
      "title": "A Remark on Downlink Massive Random Access",
      "abstract": "In downlink massive random access (DMRA), a base station transmits messages to a typically small subset of active users, selected randomly from a massive number of total users. Explicitly encoding the identities of active users would incur a significant overhead scaling logarithmically with the number of total users. Recently, via a random coding argument, Song, Attiah and Yu have shown that the overhead can be reduced to within some upper bound irrespective of the number of total users. In this remark, recognizing that the code design for DMRA is an instance of covering arrays in combinatorics, we show that there exists deterministic construction of variable-length codes that incur an overhead no greater than $1 + log_2 e$ bits.",
      "authors": [
        "Yuchen Liao",
        "Wenyi Zhang"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 13:05:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15928v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15904v1",
      "title": "Dynamic Server Allocation Under Stochastic Switchover on Time-Varying Links",
      "abstract": "Dynamic resource allocation to parallel queues is a cornerstone of network scheduling, yet classical solutions often fail when accounting for the overhead of switching delays to queues with superior link conditions. In particular, system performance is further degraded when switching delays are stochastic and inhomogeneous. In this domain, the myopic, Max-Weight policy struggles, as it is agnostic to switching delays. This paper introduces ACI, a non-myopic, frame-based scheduling framework that directly amortizes these switching delays. We first use a Lyapunov drift analysis to prove that backlog-driven ACI is throughput-optimal with respect to a scaled capacity region; then validate ACI's effectiveness on multi-UAV networks with an FSO backhaul. Finally, we demonstrate how adapting its core urgency metric provides the flexibility to navigate the throughput-latency trade-off.",
      "authors": [
        "Hossein Mohammadalizadeh",
        "Holger Karl"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-22 12:31:17+00:00",
      "link": "https://arxiv.org/pdf/2601.15904v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15892v1",
      "title": "Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model",
      "abstract": "Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \\~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.",
      "authors": [
        "Chenghao Fan",
        "Wen Heng",
        "Bo Li",
        "Sichen Liu",
        "Yuxuan Song",
        "Jing Su",
        "Xiaoye Qu",
        "Kai Shen",
        "Wei Wei"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-22 12:13:17+00:00",
      "link": "https://arxiv.org/pdf/2601.15892v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15876v1",
      "title": "EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience",
      "abstract": "The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.",
      "authors": [
        "Taofeng Xue",
        "Chong Peng",
        "Mianqiu Huang",
        "Linsen Guo",
        "Tiancheng Han",
        "Haozhe Wang",
        "Jianing Wang",
        "Xiaocheng Zhang",
        "Xin Yang",
        "Dengchang Zhao",
        "Jinrui Ding",
        "Xiandi Ma",
        "Yuchen Xie",
        "Peng Pei",
        "Xunliang Cai",
        "Xipeng Qiu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 11:36:43+00:00",
      "link": "https://arxiv.org/pdf/2601.15876v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15853v1",
      "title": "Practical applications of Set Shaping Theory to Non-Uniform Sequences",
      "abstract": "Set Shaping Theory (SST) moves beyond the classical fixed-space model by constructing bijective mappings the original sequence set into structured regions of a larger sequence space. These shaped subsets are characterized by a reduced average information content, measured by the product of the empirical entropy and the length, yielding (N +k)H0(f(s)) < NH0(s), which represents the universal coding limit when the source distribution is unknown. The principal experimental difficulty in applying Set Shaping Theory to non-uniform sequences arises from the need to order the sequences of both the original and transformed sets according to their information content. An exact ordering of these sets entails exponential complexity, rendering a direct implementation impractical. In this article, we show that this obstacle can be overcome by performing an approximate but informative ordering that preserves the structural requirements of SST while achieving the shaping gain predicted by the theory. This result extends previous experimental findings obtained for uniformly distributed sequences and demonstrates that the shaping advantage of SST persists for non-uniform sequences. Finally, to ensure full reproducibility, the software implementing the proposed method has been made publicly available on GitHub, enabling independent verification of the results reported in this work",
      "authors": [
        "A. Schmidt",
        "A. Vdberg",
        "A. Petit"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 11:01:15+00:00",
      "link": "https://arxiv.org/pdf/2601.15853v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15807v1",
      "title": "Algebraic Statistics in OSCAR",
      "abstract": "We introduce the AlgebraicStatistics section of the OSCAR computer algebra system. We give an overview of its extensible design and highlight its features including serialization of data types for sharing results and creating databases, and state-of-the-art implicitization algorithms.",
      "authors": [
        "Tobias Boege",
        "Antony Della Vecchia",
        "Marina Garrote-López",
        "Benjamin Hollering"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO",
        "cs.NE",
        "math.AC",
        "math.ST"
      ],
      "published": "2026-01-22 09:46:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15807v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15778v1",
      "title": "Agentic Confidence Calibration",
      "abstract": "AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.",
      "authors": [
        "Jiaxin Zhang",
        "Caiming Xiong",
        "Chien-Sheng Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-22 09:08:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15778v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15761v1",
      "title": "Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning",
      "abstract": "Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \\textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.",
      "authors": [
        "Xiefeng Wu",
        "Mingyu Hu",
        "Shu Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 08:51:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15761v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15758v1",
      "title": "NL4ST: A Natural Language Query Tool for Spatio-Temporal Databases",
      "abstract": "The advancement of mobile computing devices and positioning technologies has led to an explosive growth of spatio-temporal data managed in databases. Representative queries over such data include range queries, nearest neighbor queries, and join queries. However, formulating those queries usually requires domain-specific expertise and familiarity with executable query languages, which would be a challenging task for non-expert users. It leads to a great demand for well-supported natural language queries (NLQs) in spatio-temporal databases. To bridge the gap between non-experts and query plans in databases, we present NL4ST, an interactive tool that allows users to query spatio-temporal databases in natural language. NL4ST features a three-layer architecture: (i) knowledge base and corpus for knowledge preparation, (ii) natural language understanding for entity linking, and (iii) generating physical plans. Our demonstration will showcase how NL4ST provides effective spatio-temporal physical plans, verified by using four real and synthetic datasets. We make NL4ST online and provide the demo video at https://youtu.be/-J1R7R5WoqQ.",
      "authors": [
        "Xieyang Wang",
        "Mengyi Liu",
        "Weijia Yi",
        "Jianqiu Xu",
        "Raymond Chi-Wing Wong"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-22 08:48:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15758v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15729v1",
      "title": "DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving",
      "abstract": "Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.",
      "authors": [
        "Rui Yang",
        "Lei Zheng",
        "Ruoyu Yao",
        "Jun Ma"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-01-22 07:56:36+00:00",
      "link": "https://arxiv.org/pdf/2601.15729v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15728v1",
      "title": "Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity",
      "abstract": "While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.",
      "authors": [
        "Hangle Hu",
        "Chenyu Hou",
        "Bin Cao",
        "Ruizhe Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-01-22 07:54:45+00:00",
      "link": "https://arxiv.org/pdf/2601.15728v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15726v1",
      "title": "Profit Maximization for Viral Marketing in Online Social Networks using Two Phase Diffusion Approach",
      "abstract": "Now-a-days, Online Social Networks (OSNs) are extensively used by different commercial houses for viral marketing. The key problem that arises in this context is to choose a limited number of highly influential users as the initial adopters of a brand such that the influence regarding the brand in the network gets maximized. Deviating from this standard setting, in this paper, we study the problem where every user of the network is associated with a selection cost and a benefit value. This benefit value can be earned from the user if (s)he is influenced by the brand. A fixed amount of budget is allocated for selecting the seed users. The goal of initial adopters is to choose a set of seed users within the budget such that the profit is maximized. We propose a two phase diffusion model for this problem where the goal is to split the diffusion process into two phases, and hence, split the budget into two halves. First, we spend the first half budget to select seed users for the first phase and observe the diffusion for a few rounds and then deploy the seed users for the second phase and successively complete the diffusion process. We prove several properties of the two phase influence function. Three solution approaches have been proposed for our problem with detailed analysis and illustrative examples. We conduct a number of experiments with three real-world social network datasets. From the experiments, we observe that the two phase diffusion approach leads to more amount of profit compared to the single-phase diffusion. In particular, for most instances, this improvement is greater than 18% and reaching as high as 40% by the proposed methodologies.",
      "authors": [
        "Poonam Sharma",
        "Suman Banerjee"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI"
      ],
      "published": "2026-01-22 07:51:17+00:00",
      "link": "https://arxiv.org/pdf/2601.15726v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15723v1",
      "title": "Generalized Information Inequalities via Submodularity, and Two Combinatorial Problems",
      "abstract": "It is well known that there is a strong connection between entropy inequalities and submodularity, since the entropy of a collection of random variables is a submodular function. Unifying frameworks for information inequalities arising from submodularity were developed by Madiman and Tetali (2010) and Sason (2022). Madiman and Tetali (2010) established strong and weak fractional inequalities that subsume classical results such as Han's inequality and Shearer's lemma. Sason (2022) introduced a convex-functional framework for generalizing Han's inequality, and derived unified inequalities for submodular and supermodular functions. In this work, we build on these frameworks and make three contributions. First, we establish convex-functional generalizations of the strong and weak Madiman and Tetali inequalities for submodular functions. Second, using a special case of the strong Madiman-Tetali inequality, we derive a new Loomis-Whitney-type projection inequality for finite point sets in $\\mathbb{R}^d$, which improves upon the classical Loomis-Whitney bound by incorporating slice-level structural information. Finally, we study an extremal graph theory problem that recovers and extends the previously known results of Sason (2022) and Boucheron et al., employing Shearer's lemma in contrast to the use of Han's inequality in those works.",
      "authors": [
        "Gunank Jakhar",
        "Gowtham R. Kurri",
        "Suryajith Chillara",
        "Vinod M. Prabhakaran"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "math.CO"
      ],
      "published": "2026-01-22 07:47:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15723v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15722v1",
      "title": "Communication-efficient Federated Graph Classification via Generative Diffusion Modeling",
      "abstract": "Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.",
      "authors": [
        "Xiuling Wang",
        "Xin Huang",
        "Haibo Hu",
        "Jianliang Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 07:46:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15722v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15714v1",
      "title": "Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs",
      "abstract": "We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.",
      "authors": [
        "Ryoma Sato"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-22 07:36:01+00:00",
      "link": "https://arxiv.org/pdf/2601.15714v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15703v1",
      "title": "Agentic Uncertainty Quantification",
      "abstract": "Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.",
      "authors": [
        "Jiaxin Zhang",
        "Prafulla Kumar Choubey",
        "Kung-Hsiang Huang",
        "Caiming Xiong",
        "Chien-Sheng Wu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-22 07:16:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15703v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15697v1",
      "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
      "abstract": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
      "authors": [
        "Binu V P",
        "Deepthy K Bhaskar",
        "Minimol B"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-22 06:51:45+00:00",
      "link": "https://arxiv.org/pdf/2601.15697v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15688v1",
      "title": "Performance-guided Reinforced Active Learning for Object Detection",
      "abstract": "Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.",
      "authors": [
        "Zhixuan Liang",
        "Xingyu Zeng",
        "Rui Zhao",
        "Ping Luo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-22 06:17:08+00:00",
      "link": "https://arxiv.org/pdf/2601.15688v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15673v1",
      "title": "Enhancing guidance for missing data in diffusion-based sequential recommendation",
      "abstract": "Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.",
      "authors": [
        "Qilong Yan",
        "Yifei Xing",
        "Dugang Liu",
        "Jingpu Duan",
        "Jian Yin"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-22 05:55:21+00:00",
      "link": "https://arxiv.org/pdf/2601.15673v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15671v1",
      "title": "StreetDesignAI: A Multi-Persona Evaluation System for Inclusive Infrastructure Design",
      "abstract": "Designing inclusive cycling infrastructure requires balancing competing needs of diverse user groups, yet designers often struggle to anticipate how different cyclists experience the same street. We investigate how persona-based multi-agent evaluation can support inclusive design by making experiential conflicts explicit. We present StreetDesignAI, an interactive system that enables designers to (1) ground evaluation in street context through imagery and map data, (2) receive parallel feedback from cyclist personas spanning confident to cautious users, and (3) iteratively modify designs while surfacing conflicts across perspectives. A within-subjects study with 26 transportation professionals demonstrates that structured multi-perspective feedback significantly improves designers' understanding of diverse user perspectives, ability to identify persona needs, and confidence in translating them into design decisions, with higher satisfaction and stronger intention for professional adoption. Qualitative findings reveal how conflict surfacing transforms design exploration from single-perspective optimization toward deliberate trade-off reasoning. We discuss implications for AI tools that scaffold inclusive design through disagreement as an interaction primitive.",
      "authors": [
        "Ziyi Wang",
        "Yilong Dai",
        "Duanya Lyu",
        "Mateo Nader",
        "Sihan Chen",
        "Wanghao Ye",
        "Zjian Ding",
        "Xiang Yan"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-01-22 05:53:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15671v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15663v1",
      "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
      "abstract": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
      "authors": [
        "Kristen Moore",
        "Diksha Goel",
        "Cody James Christopher",
        "Zhen Wang",
        "Minjune Kim",
        "Ahmed Ibrahim",
        "Ahmad Mohsin",
        "Seyit Camtepe"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-22 05:23:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15663v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15639v1",
      "title": "A Class of Subadditive Information Measures and their Applications",
      "abstract": "We introduce a two-parameter family of discrepancy measures, termed \\emph{$(G,f)$-divergences}, obtained by applying a non-decreasing function $G$ to an $f$-divergence $D_f$. Building on Csiszár's formulation of mutual $f$-information, we define a corresponding $(G,f)$-information measure $ I_{G,f}(X;Y)$. A central theme of the paper is subadditivity over product distributions and product channels. We develop reduction principles showing that, for broad classes of $G$, it suffices to verify divergence subadditivity on binary alphabets. Specializing to the functions $G(x)\\in\\{x,\\log(1+x),-\\log(1-x)\\}$, we derive tractable sufficient conditions on $f$ that guarantee subadditivity, covering many standard $f$-divergences. Finally, we present applications to finite-blocklength converses for channel coding, bounds in binary hypothesis testing, and an extension of the Shannon--Gallager--Berlekamp sphere-packing exponent framework to subadditive $(G,f)$-divergences.",
      "authors": [
        "Hamidreza Abin",
        "Mahdi Zinati",
        "Amin Gohari",
        "Mohammad Hossein Yassaee",
        "Mohammad Mahdi Mojahedian"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-22 04:38:05+00:00",
      "link": "https://arxiv.org/pdf/2601.15639v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15630v1",
      "title": "Agentic AI Governance and Lifecycle Management in Healthcare",
      "abstract": "Healthcare organizations are beginning to embed agentic AI into routine workflows, including clinical documentation support and early-warning monitoring. As these capabilities diffuse across departments and vendors, health systems face agent sprawl, causing duplicated agents, unclear accountability, inconsistent controls, and tool permissions that persist beyond the original use case. Existing AI governance frameworks emphasize lifecycle risk management but provide limited guidance for the day-to-day operations of agent fleets. We propose a Unified Agent Lifecycle Management (UALM) blueprint derived from a rapid, practice-oriented synthesis of governance standards, agent security literature, and healthcare compliance requirements. UALM maps recurring gaps onto five control-plane layers: (1) an identity and persona registry, (2) orchestration and cross-domain mediation, (3) PHI-bounded context and memory, (4) runtime policy enforcement with kill-switch triggers, and (5) lifecycle management and decommissioning linked to credential revocation and audit logging. A companion maturity model supports staged adoption. UALM offers healthcare CIOs, CISOs, and clinical leaders an implementable pattern for audit-ready oversight that preserves local innovation and enables safer scaling across clinical and administrative domains.",
      "authors": [
        "Chandra Prakash",
        "Mary Lind",
        "Avneesh Sisodia"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 04:01:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15630v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15626v1",
      "title": "Bridging Qualitative Rubrics and AI: A Binary Question Framework for Criterion-Referenced Grading in Engineering",
      "abstract": "PURPOSE OR GOAL: This study investigates how GenAI can be integrated with a criterion-referenced grading framework to improve the efficiency and quality of grading for mathematical assessments in engineering. It specifically explores the challenges demonstrators face with manual, model solution-based grading and how a GenAI-supported system can be designed to reliably identify student errors, provide high-quality feedback, and support human graders. The research also examines human graders' perceptions of the effectiveness of this GenAI-assisted approach. ACTUAL OR ANTICIPATED OUTCOMES: The study found that GenAI achieved an overall grading accuracy of 92.5%, comparable to two experienced human graders. The two researchers, who also served as subject demonstrators, perceived the GenAI as a helpful second reviewer that improved accuracy by catching small errors and provided more complete feedback than they could manually. A central outcome was the significant enhancement of formative feedback. However, they noted the GenAI tool is not yet reliable enough for autonomous use, especially with unconventional solutions. CONCLUSIONS/RECOMMENDATIONS/SUMMARY: This study demonstrates that GenAI, when paired with a structured, criterion-referenced framework using binary questions, can grade engineering mathematical assessments with an accuracy comparable to human experts. Its primary contribution is a novel methodological approach that embeds the generation of high-quality, scalable formative feedback directly into the assessment workflow. Future work should investigate student perceptions of GenAI grading and feedback.",
      "authors": [
        "Lili Chen",
        "Winn Wing-Yiu Chow",
        "Stella Peng",
        "Bencheng Fan",
        "Sachitha Bandara"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "published": "2026-01-22 03:57:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15626v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15609v1",
      "title": "When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.",
      "authors": [
        "Mingyuan Fan",
        "Weiguang Han",
        "Daixin Wang",
        "Cen Chen",
        "Zhiqiang Zhang",
        "Jun Zhou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-22 03:15:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15609v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15599v1",
      "title": "Autonomous Business System via Neuro-symbolic AI",
      "abstract": "Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.",
      "authors": [
        "Cecil Pang",
        "Hiroki Sayama"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 02:49:06+00:00",
      "link": "https://arxiv.org/pdf/2601.15599v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15589v1",
      "title": "Deep Learning for Perishable Inventory Systems with Human Knowledge",
      "abstract": "Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.",
      "authors": [
        "Xuan Liao",
        "Zhenkang Peng",
        "Ying Rong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22 02:26:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15589v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15580v1",
      "title": "Screening for Choice Sets",
      "abstract": "We study a screening problem in which an agent privately observes a set of feasible technologies and can strategically disclose only a subset to the principal. The principal then takes an action whose payoff consequences for both players are publicly known. Under the assumption that the possible technology sets are ordered by set inclusion, we show that the optimal mechanism promises the agent a utility that is weakly increasing as the reported set expands, and the choice of the principal maximizes her own utility subject to this promised utility constraint. Moreover, the optimal promised utility either coincides with the agent's utility under the complete information benchmark or remains locally constant, with the number of constant segments bounded by the number of downward-sloping segments of the complete information benchmark.",
      "authors": [
        "Tan Gan",
        "Yingkai Li"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH",
        "cs.GT"
      ],
      "published": "2026-01-22 02:00:34+00:00",
      "link": "https://arxiv.org/pdf/2601.15580v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15571v1",
      "title": "Verified polynomial-time reductions in Lean 4: formalizing the complexity of decision-relevant information",
      "abstract": "We present a Lean 4 framework for polynomial-time reductions and complexity-theory proofs, and use it to formalize the complexity of identifying decision-relevant information. Problem: given a decision problem, which coordinates suffice to compute an optimal action? (SUFFICIENCY-CHECK; explicit encodings). Verified complexity results (Lean): coNP-complete; $(1-\\varepsilon)\\ln n$ inapproximable (from SET-COVER); $2^{Ω(n)}$ lower bounds under ETH for succinct encodings; W[2]-hard for a natural parameterization; and a dichotomy between explicit and succinct models. Formalization contributions: bundled Karp reductions with polynomial-time witnesses; composition lemmas/tactics; and templates for NP/coNP and $Σ_2^P$ membership and hardness. Scale: about 5,600 lines of Lean across 36 files, with 230+ theorems and explicit polynomial bounds.",
      "authors": [
        "Tristan Simas"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC"
      ],
      "published": "2026-01-22 01:29:10+00:00",
      "link": "https://arxiv.org/pdf/2601.15571v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15551v1",
      "title": "ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance",
      "abstract": "Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource recommendation, but rarely integrating these components into a cohesive adaptive cycle. In this paper, we propose ALIGNAgent (Adaptive Learner Intelligence for Gap Identification and Next-step guidance), a multi-agent educational framework designed to deliver personalized learning through integrated knowledge estimation, skill-gap identification, and targeted resource recommendation.ALIGNAgent begins by processing student quiz performance, gradebook data, and learner preferences to generate topic-level proficiency estimates using a Skill Gap Agent that employs concept-level diagnostic reasoning to identify specific misconceptions and knowledge deficiencies. After identifying skill gaps, the Recommender Agent retrieves preference-aware learning materials aligned with diagnosed deficiencies, implementing a continuous feedback loop where interventions occur before advancing to subsequent topics. Extensive empirical evaluation on authentic datasets from two undergraduate computer science courses demonstrates ALIGNAgent's effectiveness, with GPT-4o-based agents achieving precision of 0.87-0.90 and F1 scores of 0.84-0.87 in knowledge proficiency estimation validated against actual exam performance.",
      "authors": [
        "Bismack Tokoli",
        "Luis Jaimes",
        "Ayesha S. Dina"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-22 00:45:15+00:00",
      "link": "https://arxiv.org/pdf/2601.15551v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15547v1",
      "title": "Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling",
      "abstract": "Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \\ours achieves state-of-the-art performance with 18--69$\\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.",
      "authors": [
        "Jingren Hou",
        "Hong Wang",
        "Pengyu Xu",
        "Chang Gao",
        "Huafeng Liu",
        "Liping Jing"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 00:33:38+00:00",
      "link": "https://arxiv.org/pdf/2601.15547v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15544v1",
      "title": "RDumb++: Drift-Aware Continual Test-Time Adaptation",
      "abstract": "Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.",
      "authors": [
        "Himanshu Mishra"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 00:20:23+00:00",
      "link": "https://arxiv.org/pdf/2601.15544v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15518v1",
      "title": "DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking",
      "abstract": "We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.",
      "authors": [
        "Wenxin Zhou",
        "Ritesh Mehta",
        "Anthony Miyaguchi"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-21 23:09:17+00:00",
      "link": "https://arxiv.org/pdf/2601.15518v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15500v1",
      "title": "Low-Dimensional Adaptation of Rectified Flow: A New Perspective through the Lens of Diffusion and Stochastic Localization",
      "abstract": "In recent years, Rectified flow (RF) has gained considerable popularity largely due to its generation efficiency and state-of-the-art performance. In this paper, we investigate the degree to which RF automatically adapts to the intrinsic low dimensionality of the support of the target distribution to accelerate sampling. We show that, using a carefully designed choice of the time-discretization scheme and with sufficiently accurate drift estimates, the RF sampler enjoys an iteration complexity of order $O(k/\\varepsilon)$ (up to log factors), where $\\varepsilon$ is the precision in total variation distance and $k$ is the intrinsic dimension of   the target distribution. In addition, we show that the denoising diffusion probabilistic model (DDPM) procedure is equivalent to a stochastic version of RF by establishing a novel connection between these processes and stochastic localization. Building on this connection, we further design a stochastic RF sampler that also adapts to the low-dimensionality of the target distribution under milder requirements on the accuracy of the drift estimates, and also with a specific time schedule. We illustrate with simulations on the synthetic data and text-to-image data experiments the improved performance of the proposed samplers implementing the newly designed time-discretization schedules.",
      "authors": [
        "Saptarshi Roy",
        "Alessandro Rinaldo",
        "Purnamrita Sarkar"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-01-21 22:09:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15500v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15495v1",
      "title": "Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge",
      "abstract": "A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.",
      "authors": [
        "Yiyang Feng",
        "Zeming Chen",
        "Haotian Wu",
        "Jiawei Zhou",
        "Antoine Bosselut"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-21 21:56:35+00:00",
      "link": "https://arxiv.org/pdf/2601.15495v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15493v1",
      "title": "Testing Deep Learning Libraries via Neurosymbolic Constraint Learning",
      "abstract": "Deep Learning (DL) libraries (e.g., PyTorch) are popular in AI development. These libraries are complex and contain bugs. Researchers have proposed various bug-finding techniques for such libraries. Yet, there is much room for improvement. A key challenge in testing DL libraries is the lack of API specifications. Prior testing approaches often inaccurately model the input specifications of DL APIs, resulting in missed valid inputs that could reveal bugs or false alarms due to invalid inputs.   To address this challenge, we develop Centaur -- the first neurosymbolic technique to test DL library APIs using dynamically learned input constraints. Centaur leverages the key idea that formal API constraints can be learned from a small number of automatically generated seed inputs, and that the learned constraints can be solved using SMT solvers to generate valid and diverse test inputs.   We develop a novel grammar that represents first-order logic formulae over API parameters and expresses tensor-related properties (e.g., shape, data types) as well as relational properties between parameters. We use the grammar to guide a Large Language Model (LLM) to enumerate syntactically correct candidate rules, validated using seed inputs. Further, we develop a custom refinement strategy to prune the set of learned rules to eliminate spurious or redundant rules. We use the learned constraints to systematically generate valid and diverse inputs by integrating SMT-based solving with randomized sampling.   We evaluate Centaur for testing PyTorch and TensorFlow. Our results show that Centaur's constraints have a recall of 94.0% and a precision of 94.0% on average. In terms of coverage, Centaur covers 203, 150, and 9,608 more branches than TitanFuzz, ACETest and Pathfinder, respectively. Using Centaur, we also detect 26 new bugs in PyTorch and TensorFlow, 18 of which are confirmed.",
      "authors": [
        "M M Abid Naziri",
        "Shinhae Kim",
        "Feiran Qin",
        "Marcelo d'Amorim",
        "Saikat Dutta"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-21 21:54:41+00:00",
      "link": "https://arxiv.org/pdf/2601.15493v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15478v1",
      "title": "Equal-Pay Contracts",
      "abstract": "We study multi-agent contract design, where a principal incentivizes a team of agents to take costly actions that jointly determine the project success via a combinatorial reward function. While prior work largely focuses on unconstrained contracts that allow heterogeneous payments across agents, many real-world environments limit payment dispersion. Motivated by this, we study equal-pay contracts, where all agents receive identical payments. Our results also extend to nearly-equal-pay contracts where any two payments are identical up to a constant factor.   We provide both algorithmic and hardness results across a broad hierarchy of reward functions, under both binary and combinatorial action models. While we focus on equal-pay contracts, our analysis also yields new insights into unconstrained contract design, and resolves two important open problems. On the positive side, we design polynomial-time O(1)-approximation algorithms for (i) submodular rewards under combinatorial actions, and (ii) XOS rewards under binary actions. These guarantees are tight: We rule out the existence of (i) a PTAS for combinatorial actions, even for gross substitutes rewards (unless P = NP), and (ii) any O(1)-approximation for XOS rewards with combinatorial actions. Crucially, our hardness results hold even for unconstrained contracts, thereby settling the corresponding open problems in this setting.   Finally, we quantify the loss induced by fairness via the price of equality, defined as the worst-case ratio between the optimal principal's utility achievable by unconstrained contracts and that achievable by equal-pay contracts. We obtain a bound of $Θ(\\log n/ \\log \\log n)$, where $n$ is the number of agents. This gap is tight in a strong sense: the upper bound applies even for XOS rewards with combinatorial actions, while the lower bound arises already for additive rewards with binary actions.",
      "authors": [
        "Michal Feldman",
        "Yoav Gal-Tzur",
        "Tomasz Ponitka",
        "Maya Schlesinger"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-01-21 21:29:13+00:00",
      "link": "https://arxiv.org/pdf/2601.15478v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15473v1",
      "title": "Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra",
      "abstract": "Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.",
      "authors": [
        "Fahd Seddik",
        "Abdulrahman Elbedewy",
        "Gaser Sami",
        "Mohamed Abdelmoniem",
        "Yahia Zakaria"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 21:23:00+00:00",
      "link": "https://arxiv.org/pdf/2601.15473v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15457v1",
      "title": "Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering",
      "abstract": "The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.",
      "authors": [
        "Anuj Maharjan",
        "Umesh Yadav"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-21 20:52:48+00:00",
      "link": "https://arxiv.org/pdf/2601.15457v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15442v1",
      "title": "A tensor network formalism for neuro-symbolic AI",
      "abstract": "The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basis encoding scheme for functions and model neural decompositions as tensor decompositions. The proposed formalism can be applied to represent logical formulas and probability distributions as structured tensor decompositions. This unified treatment identifies tensor network contractions as a fundamental inference class and formulates efficiently scaling reasoning algorithms, originating from probability theory and propositional logic, as contraction message passing schemes. The framework enables the definition and training of hybrid logical and probabilistic models, which we call Hybrid Logic Network. The theoretical concepts are accompanied by the python library tnreason, which enables the implementation and practical use of the proposed architectures.",
      "authors": [
        "Alex Goessmann",
        "Janina Schütte",
        "Maximilian Fröhlich",
        "Martin Eigel"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "math.NA",
        "stat.ML"
      ],
      "published": "2026-01-21 20:20:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15442v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15432v1",
      "title": "MEDFORD in a Box: Improvements and Future Directions for a Metadata Description Language",
      "abstract": "Scientific research metadata is vital to ensure the validity, reusability, and cost-effectiveness of research efforts. The MEDFORD metadata language was previously introduced to simplify the process of writing and maintaining metadata for non-programmers. However, barriers to entry and usability remain, including limited automatic validation, difficulty of data transport, and user unfamiliarity with text file editing. To address these issues, we introduce MEDFORD-in-a-Box (MIAB), a documentation ecosystem to facilitate researcher adoption and earlier metadata capture. MIAB contains many improvements, including an updated MEDFORD parser with expanded validation routines and BagIt export capability. MIAB also includes an improved VS Code extension that supports these changes through a visual IDE. By simplifying metadata generation, this new tool supports the creation of correct, consistent, and reusable metadata, ultimately improving research reproducibility.",
      "authors": [
        "Polina Shpilker",
        "Benjamin Stubbs",
        "Michael Sayers",
        "Yumin Lee",
        "Lenore Cowen",
        "Donna Slonim",
        "Shaun Wallace",
        "Alva Couch",
        "Noah M. Daniels"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.IR"
      ],
      "published": "2026-01-21 19:56:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15432v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15423v1",
      "title": "Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes",
      "abstract": "We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p < 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.",
      "authors": [
        "Lorian Bannis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21 19:37:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15423v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15394v1",
      "title": "Memorization Dynamics in Knowledge Distillation for Language Models",
      "abstract": "Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.",
      "authors": [
        "Jaydeep Borkar",
        "Karan Chadha",
        "Niloofar Mireshghallah",
        "Yuchen Zhang",
        "Irina-Elena Veliche",
        "Archi Mitra",
        "David A. Smith",
        "Zheng Xu",
        "Diego Garcia-Olano"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-21 19:04:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15394v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15390v1",
      "title": "FedUMM: A General Framework for Federated Learning with Unified Multimodal Models",
      "abstract": "Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.",
      "authors": [
        "Zhaolong Su",
        "Leheng Zhao",
        "Xiaoying Wu",
        "Ziyue Xu",
        "Jindong Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21 19:02:52+00:00",
      "link": "https://arxiv.org/pdf/2601.15390v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15370v1",
      "title": "Improving MoE Compute Efficiency by Composing Weight and Data Sparsity",
      "abstract": "Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.",
      "authors": [
        "Maciej Kilian",
        "Oleg Mkrtchyan",
        "Luke Zettlemoyer",
        "Akshat Shrivastava",
        "Armen Aghajanyan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 18:53:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15370v1",
      "tags": [
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15258v1",
      "title": "Distributed Agent-Constrained Truthful Facility Location",
      "abstract": "We study a distributed facility location problem in which a set of agents, each with a private position on the real line, is partitioned into a collection of fixed, disjoint groups. The goal is to open $k$ facilities at locations chosen from the set of positions reported by the agents. This decision is made by mechanisms that operate in two phases. In Phase 1, each group selects the position of one of its agents to serve as the group's representative location. In Phase 2, $k$ representatives are chosen as facility locations. Once the facility locations are determined, each agent incurs an individual cost, defined either as the sum of its distances to all facilities (sum-variant) or as the distance to its farthest facility (max-variant). We focus on the class of strategyproof mechanisms, which preclude the agents from benefiting through strategic misreporting, and establish tight bounds on the approximation ratio with respect to the social cost (the total individual agent cost) in both variants.",
      "authors": [
        "Argyrios Deligkas",
        "Panagiotis Kanellopoulos",
        "Alexandros A. Voudouris"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-01-21 18:40:17+00:00",
      "link": "https://arxiv.org/pdf/2601.15258v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15249v2",
      "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism",
      "abstract": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.",
      "authors": [
        "Garrett G. Wen",
        "Buxin Su",
        "Natalie Collina",
        "Zhun Deng",
        "Weijie Su"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "stat.ME"
      ],
      "published": "2026-01-21 18:30:42+00:00",
      "link": "https://arxiv.org/pdf/2601.15249v2",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15247v1",
      "title": "Taxonomy-Aligned Risk Extraction from 10-K Filings with Autonomous Improvement Using LLMs",
      "abstract": "We present a methodology for extracting structured risk factors from corporate 10-K filings while maintaining adherence to a predefined hierarchical taxonomy. Our three-stage pipeline combines LLM extraction with supporting quotes, embedding-based semantic mapping to taxonomy categories, and LLM-as-a-judge validation that filters spurious assignments. To evaluate our approach, we extract 10,688 risk factors from S&P 500 companies and examine risk profile similarity across industry clusters. Beyond extraction, we introduce autonomous taxonomy maintenance where an AI agent analyzes evaluation feedback to identify problematic categories, diagnose failure patterns, and propose refinements, achieving 104.7% improvement in embedding separation in a case study. External validation confirms the taxonomy captures economically meaningful structure: same-industry companies exhibit 63% higher risk profile similarity than cross-industry pairs (Cohen's d=1.06, AUC 0.82, p<0.001). The methodology generalizes to any domain requiring taxonomy-aligned extraction from unstructured text, with autonomous improvement enabling continuous quality maintenance and enhancement as systems process more documents.",
      "authors": [
        "Rian Dolphin",
        "Joe Dursun",
        "Jarrett Blankenship",
        "Katie Adams",
        "Quinton Pike"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-21 18:28:31+00:00",
      "link": "https://arxiv.org/pdf/2601.15247v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15241v1",
      "title": "Feasibility Preservation under Monotone Retrieval Truncation",
      "abstract": "Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation.   We formalize retrieval as a sequence of candidate evidence sets and characterize conditions under which feasibility in the limit implies feasibility at finite retrieval depth. We show that monotone truncation suffices to guarantee finite witnessability for individual queries. For classes of queries, we identify finite generation of witness certificates as the additional condition required to obtain a uniform retrieval bound, and we show that this condition is necessary. We further exhibit sharp counterexamples demonstrating failure under non-monotone truncation, non-finitely-generated query classes, and purely slotwise coverage.   Together, these results isolate feasibility preservation as a correctness criterion for retrieval independent of relevance scoring or optimization, and clarify structural limitations inherent to truncation-based retrieval.",
      "authors": [
        "Sean Plummer"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "published": "2026-01-21 18:25:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15241v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15195v1",
      "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub",
      "abstract": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows.",
      "authors": [
        "Ramtin Ehsani",
        "Sakshi Pathak",
        "Shriya Rawal",
        "Abdullah Al Mujahid",
        "Mia Mohammad Imran",
        "Preetha Chatterjee"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-21 17:12:46+00:00",
      "link": "https://arxiv.org/pdf/2601.15195v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15182v1",
      "title": "Supporting Humans in Evaluating AI Summaries of Legal Depositions",
      "abstract": "While large language models (LLMs) are increasingly used to summarize long documents, this trend poses significant challenges in the legal domain, where the factual accuracy of deposition summaries is crucial. Nugget-based methods have been shown to be extremely helpful for the automated evaluation of summarization approaches. In this work, we translate these methods to the user side and explore how nuggets could directly assist end users. Although prior systems have demonstrated the promise of nugget-based evaluation, its potential to support end users remains underexplored. Focusing on the legal domain, we present a prototype that leverages a factual nugget-based approach to support legal professionals in two concrete scenarios: (1) determining which of two summaries is better, and (2) manually improving an automatically generated summary.",
      "authors": [
        "Naghmeh Farzi",
        "Laura Dietz",
        "Dave D. Lewis"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-21 17:00:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15182v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15165v1",
      "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models",
      "abstract": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation challenges the premise of existing RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning is better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap",
      "authors": [
        "Zanlin Ni",
        "Shenzhi Wang",
        "Yang Yue",
        "Tianyu Yu",
        "Weilin Zhao",
        "Yeguo Hua",
        "Tianyi Chen",
        "Jun Song",
        "Cheng Yu",
        "Bo Zheng",
        "Gao Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-21 16:41:58+00:00",
      "link": "https://arxiv.org/pdf/2601.15165v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15160v1",
      "title": "Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning",
      "abstract": "Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a \"compositional bridge\", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.",
      "authors": [
        "Yuval Kansal",
        "Niraj K. Jha"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-21 16:38:59+00:00",
      "link": "https://arxiv.org/pdf/2601.15160v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15158v1",
      "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",
      "abstract": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.",
      "authors": [
        "Yuval Ran-Milo",
        "Yotam Alexander",
        "Shahar Mendel",
        "Nadav Cohen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 16:36:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15158v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15148v1",
      "title": "Interval Scheduling Games",
      "abstract": "We consider a game-theoretic variant of an interval scheduling problem. Every job is associated with a length, a weight, and a color. Each player controls all the jobs of a specific color, and needs to decide on a processing interval for each of its jobs. Jobs of the same color can be processed simultaneously by the machine. A job is covered if the machine is configured to its color during its whole processing interval. The goal of the machine is to maximize the sum of weights of all covered jobs, and the goal of each player is to place its jobs such that the sum of weights of covered jobs from its color is maximized. The study of this game is motivated by several applications like antenna scheduling for wireless networks.   We first show that given a strategy profile of the players, the machine scheduling problem can be solved in polynomial time. We then study the game from the players' point of view. We analyze the existence of Nash equilibria, its computation, and inefficiency. We distinguish between instances of the classical interval scheduling problem, in which every player controls a single job, and instances in which color sets may include multiple jobs.",
      "authors": [
        "Vipin Ravindran Vijayalakshmi",
        "Marc Schroder",
        "Tami Tamir"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT"
      ],
      "published": "2026-01-21 16:20:44+00:00",
      "link": "https://arxiv.org/pdf/2601.15148v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15136v1",
      "title": "Conversational AI for Social Good (CAI4SG): An Overview of Emerging Trends, Applications, and Challenges",
      "abstract": "The integration of Conversational Agents (CAs) into daily life offers opportunities to tackle global challenges, leading to the emergence of Conversational AI for Social Good (CAI4SG). This paper examines the advancements of CAI4SG using a role-based framework that categorizes systems according to their AI autonomy and emotional engagement. This framework emphasizes the importance of considering the role of CAs in social good contexts, such as serving as empathetic supporters in mental health or functioning as assistants for accessibility. Additionally, exploring the deployment of CAs in various roles raises unique challenges, including algorithmic bias, data privacy, and potential socio-technical harms. These issues can differ based on the CA's role and level of engagement. This paper provides an overview of the current landscape, offering a role-based understanding that can guide future research and design aimed at the equitable, ethical, and effective development of CAI4SG.",
      "authors": [
        "Yi-Chieh Lee",
        "Junti Zhang",
        "Tianqi Song",
        "Yugin Tan"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-21 16:10:32+00:00",
      "link": "https://arxiv.org/pdf/2601.15136v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15130v1",
      "title": "The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks",
      "abstract": "The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the \"Plausibility Trap\": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the \"efficiency tax\"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.",
      "authors": [
        "Ivan Carrera",
        "Daniel Maldonado-Ruiz"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-21 16:05:01+00:00",
      "link": "https://arxiv.org/pdf/2601.15130v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15120v2",
      "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories",
      "abstract": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.",
      "authors": [
        "Qian Xiong",
        "Yuekai Huang",
        "Bo Yang",
        "Yujia Zheng",
        "Tianhao Li",
        "Ziyou Jiang",
        "Zhiyuan Chang",
        "Zhaoyang Li",
        "Huanxiang Feng",
        "Mingyang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-21 15:58:54+00:00",
      "link": "https://arxiv.org/pdf/2601.15120v2",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15100v1",
      "title": "Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek",
      "abstract": "Web AI agents such as ChatGPT Agent and GenSpark are increasingly used for routine web-based tasks, yet they still rely on text-based input prompts, lack proactive detection of user intent, and offer no support for interactive data analysis and decision making. We present WebSeek, a mixed-initiative browser extension that enables users to discover and extract information from webpages to then flexibly build, transform, and refine tangible data artifacts-such as tables, lists, and visualizations-all within an interactive canvas. Within this environment, users can perform analysis-including data transformations such as joining tables or creating visualizations-while an in-built AI both proactively offers context-aware guidance and automation, and reactively responds to explicit user requests. An exploratory user study (N=15) with WebSeek as a probe reveals participants' diverse analysis strategies, underscoring their desire for transparency and control during human-AI collaboration.",
      "authors": [
        "Yanwei Huang",
        "Arpit Narechania"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-21 15:38:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15100v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16063v1",
      "title": "Continuum limit of hypergraph $p$-Laplacian equations on point clouds",
      "abstract": "This paper studies a class of $p$-Laplacian equations on point clouds that arise from hypergraph learning in a semi-supervised setting. Under the assumption that the point clouds consist of independent random samples drawn from a bounded domain $Ω\\subset\\mathbb{R}^d$, we investigate the asymptotic behavior of the solutions as the number of data points tends to infinity, with the number of labeled points remains fixed. We show, for any $p>d$ in the viscosity solution framework, that the continuum limit is a weighted $p$-Laplacian equation subject to mixed Dirichlet and Neumann boundary conditions. The result provides a new discretization of the $p$-Laplacian on point clouds.",
      "authors": [
        "Kehan Shi"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-22 15:59:41+00:00",
      "link": "https://arxiv.org/pdf/2601.16063v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15950v1",
      "title": "Extreme Score Distributions in Countable-Outcome Round-Robin Tournaments of Equally Strong Players",
      "abstract": "We consider a general class of round-robin tournament models of equally strong players. In these models, each of the $n$ players competes against every other player exactly once. For each match between two players, the outcome is a value from a countable subset of the unit interval, and the scores of the two players in a match sum to one. The final score of each player is defined as the sum of the scores obtained in matches against all other players. We study the distribution of extreme scores, including the maximum, second maximum, and lower-order extremes. Since the exact distribution is computationally intractable even for small values of $n$, we derive asymptotic results as the number of players $n$ tends to infinity, including limiting distributions, and rates of convergence.",
      "authors": [
        "Yaakov Malinovsky"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.ST"
      ],
      "published": "2026-01-22 13:38:53+00:00",
      "link": "https://arxiv.org/pdf/2601.15950v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15658v1",
      "title": "Construction and Box-counting Dimension of the Edelstein Hidden Variable Fractal Interpolation Function",
      "abstract": "This paper presents the construction of a hidden variable fractal interpolation function using Edelstein contractions in an iterated function system based on a finite collection of data points. The approach incorporates an iterated function system where variable functions act as vertical scaling factors leading to a generalised vector-valued fractal interpolation function. Furthermore, the paper rigorously examines the smoothness of the constructed function and establishes an upper bound for the box-counting dimension of its graph.",
      "authors": [
        "Aiswarya T",
        "Srijanani Anurag Prasad"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-01-22 05:15:15+00:00",
      "link": "https://arxiv.org/pdf/2601.15658v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15636v1",
      "title": "Collaboration versus Specialization in Service Systems with Impatient Customers",
      "abstract": "We study tandem queueing systems in which servers work more efficiently in teams than on their own and customers are impatient in that they may leave the system while waiting for service. Our goal is to determine the server assignment policy that maximizes the long-run average throughput. We show that when each server is equally skilled at all tasks, the optimal policy has all the servers working together at all times. We also provide a complete characterization of the optimal policy for Markovian systems with two stations and two servers when each server's efficiency may be task dependent. We show that the throughput is maximized under the policy which assigns one server to each station (based on their relative skill at that station) unless station 2 has no work (in which case both servers work at station 1) or the number of customers in the buffer reaches a threshold whose value we characterize (in which case both servers work at station 2). We study how the optimal policy varies with the level of server synergy (including no synergy) and also compare the optimal policy for systems with different customer abandonment rates (including no abandonments). Finally, we investigate the case where the synergy among collaborating servers can be task-dependent and provide numerical results.",
      "authors": [
        "Bihan Chatterjee",
        "Sigrún Andradóttir",
        "Hayriye Ayhan"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-22 04:20:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15636v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15627v1",
      "title": "Limit behavior of linearly edge-reinforced random walks on the half-line",
      "abstract": "Motivated by the article [M. Takei, Electron. J. Probab. 26 (2021), article no. 104], we study the limit behavior of linearly edge-reinforced random walks on the half-line $\\mathbb{Z}_+$ with reinforcement parameter $δ>0$, and each edge $\\{x,x+1\\}$ has the initial weight $x^α\\ln^βx$ for $x > 1$ and $1$ for $x = 0, 1$. The aim of this paper is to study the almost sure limit behavior of the walk in the recurrent regime, and extend the results of Takei mentioned above.",
      "authors": [
        "Zechun Hu",
        "Renming Song",
        "Li Wang"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-22 03:58:14+00:00",
      "link": "https://arxiv.org/pdf/2601.15627v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15601v1",
      "title": "Overpartitions with repeated smallest non-overlined part",
      "abstract": "Inspired by Andrews' and Bachraoui's work on partitions with repeated smallest part, we extend the concept to overpartitions.",
      "authors": [
        "Amita Malik",
        "Rishabh Sarma"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.NT"
      ],
      "published": "2026-01-22 02:56:36+00:00",
      "link": "https://arxiv.org/pdf/2601.15601v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15531v1",
      "title": "Variable Stepsize Distributed Forward-Backward Splitting Methods as Relocated Fixed-Point Iterations",
      "abstract": "We present a family of distributed forward-backward methods with variable stepsizes to find a solution of structured monotone inclusion problems. The framework is constructed by means of relocated fixed-point iterations, extending the approach introduced in arXiv:2507.07428 to conically averaged operators, thus including iteration operators for methods of forward-backward type devised by graphs. The family of methods we construct preserve the per-iteration computational cost and the convergence properties of their constant stepsize counterparts. Specifically, we show that the resulting methods generate a sequence that converges to a fixed-point of the underlying iteration operator, whose shadow sequences converge to a solution of the problem. Numerical experiments illustrate the behaviour of our framework in structured sparse optimisation problems.",
      "authors": [
        "Felipe Atenas",
        "Minh N. Dao",
        "Matthew K. Tam"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 23:33:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15531v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15398v1",
      "title": "Understanding FISTA's weak convergence: A step-by-step introduction to the 2025 milestone",
      "abstract": "Beck and Teboulle's FISTA for finding the minimizer of the sum of two convex functions is one of the most important algorithms of the past decades. While function value convergence of the iterates was known, the actual convergence of the iterates remained elusive until October 2025 when Jang and Ryu, as well as Boţ, Fadili, and Nguyen proved weak convergence.   In this paper, we provide a gentle self-contained introduction to the proof of their remarkable result.",
      "authors": [
        "Heinz H. Bauschke",
        "Walaa M. Moursi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 19:09:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15398v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15218v1",
      "title": "Some reverse inequality in optimal mass transportation",
      "abstract": "Controlling the $\\mathcal W_\\infty$ Wasserstein distance by the $\\mathcal W_p$ Wasserstein distance is interesting both for theorical and numerical applications. A first paper on this problem was written several years ago [3]. Some year later [14] framed it in the same inequality for more general costs which increase with the distance. In this paper, we prove this type of inequality for optimal transport problems with pointwise cost which is a decreasing function of the distance. We show, in particular, that there is a general framework that encompasses all the cases above.",
      "authors": [
        "Luigi De Pascale",
        "Igor Pinheiro"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.AP"
      ],
      "published": "2026-01-21 17:49:36+00:00",
      "link": "https://arxiv.org/pdf/2601.15218v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15208v1",
      "title": "Penalty-Based Smoothing of Convex Nonsmooth Supremum Functions with Accelerated Inertial Dynamics",
      "abstract": "We propose a penalty-based smoothing framework for convex nonsmooth functions with a supremum structure. The regularization yields a differentiable surrogate with controlled approximation error, a single-valued dual maximizer, and explicit gradient formulas. We then study an accelerated inertial dynamic with vanishing damping driven by a time-dependent regularized function whose parameter decreases to zero. Under mild integrability and boundedness conditions on the regularization schedule, we establish an accelerated $\\mathcal{O}(t^{-2})$ decay estimate for the regularized residual and, in the regime $α>3$, a sharper $o(t^{-2})$ decay together with weak convergence of trajectories to a minimizer of the original nonsmooth problem via an Opial-type argument. Applications to multiobjective optimization (through Chebyshev/max scalarization) and to distributionally robust optimization (via entropic regularization over ambiguity sets) illustrate the scope of the framework.",
      "authors": [
        "Samir Adly",
        "Juan José Maulén",
        "Emilio Vilches"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 17:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.15208v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.16089v1",
      "title": "A forward-only scheme for online learning of proposal distributions in particle filters",
      "abstract": "We introduce a new online approach for constructing proposal distributions in particle filters using a forward scheme. Our method progressively incorporates future observations to refine proposals. This is in contrast to backward-scheme algorithms that require access to the entire dataset, such as the iterated auxiliary particle filters (Guarniero et al., 2017, arXiv:1511.06286) and controlled sequential Monte Carlo (Heng et al., 2020, arXiv:1708.08396) which leverage all future observations through backward recursion. In comparison, our forward scheme achieves a gradual improvement of proposals that converges toward the proposal targeted by these backward methods. We show that backward approaches can be numerically unstable even in simple settings. Our forward method, however, offers significantly greater robustness with only a minor trade-off in performance, measured by the variance of the marginal likelihood estimator. Numerical experiments on both simulated and real data illustrate the enhanced stability of our forward approach.",
      "authors": [
        "Sylvain Procope-Mamert",
        "Nicolas Chopin",
        "Maud Delattre",
        "Guillaume Kon Kam King"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO"
      ],
      "published": "2026-01-22 16:40:27+00:00",
      "link": "https://arxiv.org/pdf/2601.16089v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15942v1",
      "title": "A Hierarchical Bayesian Framework for Model-based Prognostics",
      "abstract": "In prognostics and health management (PHM) of engineered systems, maintenance decisions are ideally informed by predictions of a system's remaining useful life (RUL) based on operational data. Model-based prognostics algorithms rely on a parametric model of the system degradation process. The model parameters are learned from real-time operational data collected on the system. However, there can be valuable information in data from similar systems or components, which is not typically utilized in PHM. In this contribution, we propose a hierarchical Bayesian modeling (HBM) framework for PHM that integrates both operational data and run-to-failure data from similar systems or components. The HBM framework utilizes hyperparameter distributions learned from data of similar systems or components as priors. It enables efficient updates of predictions as more information becomes available, allowing for increasingly accurate assessments of the degradation process and its associated variability. The effectiveness of the proposed framework is demonstrated through two experimental applications involving real-world data from crack growth and lithium battery degradation. Results show significant improvements in RUL prediction accuracy and demonstrate how the framework facilitates uncertainty management through predictive distributions.",
      "authors": [
        "Xinyu Jia",
        "Iason Papaioannou",
        "Daniel Straub"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-22 13:24:33+00:00",
      "link": "https://arxiv.org/pdf/2601.15942v1",
      "tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.15999v1",
      "title": "Graph Topology Identification Based on Covariance Matching",
      "abstract": "Graph topology identification (GTI) is a central challenge in networked systems, where the underlying structure is often hidden, yet nodal data are available. Conventional solutions to address these challenges rely on probabilistic models or complex optimization formulations, commonly suffering from non-convexity or requiring restrictive assumptions on acyclicity or positivity. In this paper, we propose a novel covariance matching (CovMatch) framework that directly aligns the empirical covariance of the observed data with the theoretical covariance implied by an underlying graph. We show that as long as the data-generating process permits an explicit covariance expression, CovMatch offers a unified route to topology inference.   We showcase our methodology on linear structural equation models (SEMs), showing that CovMatch naturally handles both undirected and general sparse directed graphs - whether acyclic or positively weighted - without explicit knowledge of these structural constraints. Through appropriate reparameterizations, CovMatch simplifies the graph learning problem to either a conic mixed integer program for undirected graphs or an orthogonal matrix optimization for directed graphs. Numerical results confirm that, even for relatively large graphs, our approach efficiently recovers the true topology and outperforms standard baselines in accuracy. These findings highlight CovMatch as a powerful alternative to log-determinant or Bayesian methods for GTI, paving the way for broader research on learning complex network topologies with minimal assumptions.",
      "authors": [
        "Yongsheng Han",
        "Raj Thilak Rajan",
        "Geert Leus"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-22 14:19:01+00:00",
      "link": "https://arxiv.org/pdf/2601.15999v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15126v1",
      "title": "Sparse Sensor Arrays for Active Sensing: Models, Configurations and Applications",
      "abstract": "This chapter focuses on active sensing using sparse arrays. In active sensing applications, such as radar, sonar, wireless communications, and medical ultrasound, a collection of sensors probes the environment by emitting self-generated energy. A key benefit of such active multi-sensor arrays is their ability to focus and steer energy in desired directions by beamforming on transmit. Sparse sensor arrays offer several advantages over conventional uniform arrays, including improved resolution using fewer physical sensors and the capability to identify more scatterers than sensors. This is facilitated by the effective transmit-receive virtual array known as the sum co-array, which can have many more virtual sensors than the number of physical transmit or receive sensors. Herein, we focus on the design of low-redundancy sparse array configurations and on employing transmit-receive (Tx-Rx) beamforming using sparse arrays. We discuss the optimal, but computationally intractable Minimum-redundancy array, and a scalable symmetric array framework, which extends many well-known passive sparse array geometries to the active case. We also examine mitigating side lobes arising from spatial undersampling by a synthetic beamforming method known as image addition. We briefly present approaches for finding the physical beamforming weights synthesizing a desired Tx-Rx beampattern, and consider related spatio-temporal trade-offs. We conclude by discussing selected applications of sparse arrays in active sensing.",
      "authors": [
        "Robin Rajamäki",
        "Visa Koivunen"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-21 16:02:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15126v1",
      "tags": [
        "keyword:LNS"
      ]
    },
    {
      "id": "2601.15440v1",
      "title": "Numba-Accelerated 2D Diffusion-Limited Aggregation: Implementation and Fractal Characterization",
      "abstract": "We present dla-ideal-solver, a high-performance framework for simulating two-dimensional Diffusion-Limited Aggregation (DLA) using Numba-accelerated Python. By leveraging just-in-time (JIT) compilation, we achieve computational throughput comparable to legacy static implementations while retaining high-level flexibility. We investigate the Laplacian growth instability across varying injection geometries and walker concentrations. Our analysis confirms the robustness of the standard fractal dimension $D_f \\approx 1.71$ for dilute regimes, consistent with the Witten-Sander universality class. However, we report a distinct crossover to Eden-like compact growth ($D_f \\approx 1.87$) in high-density environments, attributed to the saturation of the screening length. Beyond standard mass-radius scaling, we employ generalized Rényi dimensions and lacunarity metrics to quantify the monofractal character and spatial heterogeneity of the aggregates. This work establishes a reproducible, open-source testbed for exploring phase transitions in non-equilibrium statistical mechanics.",
      "authors": [
        "Sandy H. S. Herho",
        "Faiz R. Fajary",
        "Iwan P. Anwar",
        "Faruq Khadami",
        "Nurjanna J. Trilaksono",
        "Rusmawan Suwarman",
        "Dasapta E. Irawan"
      ],
      "primary_category": "nlin.PS",
      "categories": [
        "nlin.PS",
        "physics.comp-ph"
      ],
      "published": "2026-01-21 20:10:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15440v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ]
    }
  ],
  "queries": [
    {
      "type": "keyword",
      "tag": "EOH",
      "paper_tag": "keyword:EOH",
      "query_text": "‪Evolution of Heuristics",
      "sim_scores": {
        "2601.16056v1": {
          "score": 0.029138513513513514,
          "rank": 1
        },
        "2601.15717v1": {
          "score": 0.0287391216352965,
          "rank": 2
        },
        "2601.15690v1": {
          "score": 0.02817460317460317,
          "rank": 3
        },
        "2601.15678v1": {
          "score": 0.02712049508554787,
          "rank": 4
        },
        "2601.15738v1": {
          "score": 0.026742581090407176,
          "rank": 5
        },
        "2601.15434v1": {
          "score": 0.026494565217391304,
          "rank": 6
        },
        "2601.16175v1": {
          "score": 0.026333789329685362,
          "rank": 7
        },
        "2601.15092v1": {
          "score": 0.0260840108401084,
          "rank": 8
        },
        "2601.15178v1": {
          "score": 0.02547482665058788,
          "rank": 9
        },
        "2601.15849v1": {
          "score": 0.02325870646766169,
          "rank": 10
        },
        "2601.15153v1": {
          "score": 0.02325863113264688,
          "rank": 11
        },
        "2601.15727v1": {
          "score": 0.021910919540229883,
          "rank": 12
        },
        "2601.15808v1": {
          "score": 0.021749136939010358,
          "rank": 13
        },
        "2601.15992v1": {
          "score": 0.021515326778484674,
          "rank": 14
        },
        "2601.15127v1": {
          "score": 0.021462639109697933,
          "rank": 15
        },
        "2601.16083v1": {
          "score": 0.020476190476190478,
          "rank": 16
        },
        "2601.16194v1": {
          "score": 0.019836328055506138,
          "rank": 17
        },
        "2601.15751v1": {
          "score": 0.0193001443001443,
          "rank": 18
        },
        "2601.15487v1": {
          "score": 0.019148400100781053,
          "rank": 19
        },
        "2601.15172v1": {
          "score": 0.01914039135264462,
          "rank": 20
        },
        "2601.15417v1": {
          "score": 0.018910256410256412,
          "rank": 21
        },
        "2601.15141v1": {
          "score": 0.018829561527581327,
          "rank": 22
        },
        "2601.15593v1": {
          "score": 0.018527278461053294,
          "rank": 23
        },
        "2601.16025v1": {
          "score": 0.01847457627118644,
          "rank": 24
        },
        "2601.15411v1": {
          "score": 0.01752123786407767,
          "rank": 25
        },
        "2601.16091v1": {
          "score": 0.017392619479733817,
          "rank": 26
        },
        "2601.15455v1": {
          "score": 0.017391304347826087,
          "rank": 27
        },
        "2601.16163v1": {
          "score": 0.01734970726831358,
          "rank": 28
        },
        "2601.15482v1": {
          "score": 0.01639344262295082,
          "rank": 29
        },
        "2601.16038v1": {
          "score": 0.01625,
          "rank": 30
        },
        "2601.15170v1": {
          "score": 0.016129032258064516,
          "rank": 31
        },
        "2601.15249v2": {
          "score": 0.015873015873015872,
          "rank": 32
        },
        "2601.16020v1": {
          "score": 0.015384615384615385,
          "rank": 33
        },
        "2601.15790v1": {
          "score": 0.015151515151515152,
          "rank": 34
        },
        "2601.16156v1": {
          "score": 0.015151515151515152,
          "rank": 35
        },
        "2601.16072v1": {
          "score": 0.015130752540824483,
          "rank": 36
        },
        "2601.15715v1": {
          "score": 0.014709028669234061,
          "rank": 37
        },
        "2601.15952v1": {
          "score": 0.014492753623188406,
          "rank": 38
        },
        "2601.15876v1": {
          "score": 0.014492753623188406,
          "rank": 39
        },
        "2601.16193v1": {
          "score": 0.014285714285714285,
          "rank": 40
        },
        "2601.16122v1": {
          "score": 0.014084507042253521,
          "rank": 41
        },
        "2601.15561v1": {
          "score": 0.014084507042253521,
          "rank": 42
        },
        "2601.16043v1": {
          "score": 0.01373652133145804,
          "rank": 43
        },
        "2601.15212v1": {
          "score": 0.0136986301369863,
          "rank": 44
        },
        "2601.15399v1": {
          "score": 0.0136986301369863,
          "rank": 45
        },
        "2601.16007v1": {
          "score": 0.013513513513513514,
          "rank": 46
        },
        "2601.15094v1": {
          "score": 0.013333333333333334,
          "rank": 47
        },
        "2601.15687v1": {
          "score": 0.013157894736842105,
          "rank": 48
        },
        "2601.16142v1": {
          "score": 0.013157894736842105,
          "rank": 49
        },
        "2601.15077v1": {
          "score": 0.012987012987012988,
          "rank": 50
        },
        "2601.15123v1": {
          "score": 0.01282051282051282,
          "rank": 51
        },
        "2601.15551v1": {
          "score": 0.01282051282051282,
          "rank": 52
        },
        "2601.15552v1": {
          "score": 0.012658227848101266,
          "rank": 53
        },
        "2601.15531v1": {
          "score": 0.0125,
          "rank": 54
        },
        "2601.15707v1": {
          "score": 0.012048192771084338,
          "rank": 55
        },
        "2601.15804v1": {
          "score": 0.011904761904761904,
          "rank": 56
        },
        "2601.16180v1": {
          "score": 0.011764705882352941,
          "rank": 57
        },
        "2601.15167v1": {
          "score": 0.011764705882352941,
          "rank": 58
        },
        "2601.15860v1": {
          "score": 0.011627906976744186,
          "rank": 59
        },
        "2601.15657v1": {
          "score": 0.011494252873563218,
          "rank": 60
        },
        "2601.15445v1": {
          "score": 0.011363636363636364,
          "rank": 61
        },
        "2601.16036v1": {
          "score": 0.011235955056179775,
          "rank": 62
        },
        "2601.15432v1": {
          "score": 0.011235955056179775,
          "rank": 63
        },
        "2601.15604v1": {
          "score": 0.011111111111111112,
          "rank": 64
        },
        "2601.15100v1": {
          "score": 0.011111111111111112,
          "rank": 65
        },
        "2601.15581v1": {
          "score": 0.01098901098901099,
          "rank": 66
        },
        "2601.15471v1": {
          "score": 0.010752688172043012,
          "rank": 67
        },
        "2601.16206v1": {
          "score": 0.010752688172043012,
          "rank": 68
        },
        "2601.15640v1": {
          "score": 0.010638297872340425,
          "rank": 69
        },
        "2601.15241v1": {
          "score": 0.010526315789473684,
          "rank": 70
        },
        "2601.15731v1": {
          "score": 0.010416666666666666,
          "rank": 71
        },
        "2601.16190v1": {
          "score": 0.010309278350515464,
          "rank": 72
        },
        "2601.15626v1": {
          "score": 0.010309278350515464,
          "rank": 73
        },
        "2601.16090v1": {
          "score": 0.01020408163265306,
          "rank": 74
        },
        "2601.15124v1": {
          "score": 0.01020408163265306,
          "rank": 75
        },
        "2601.15620v1": {
          "score": 0.010101010101010102,
          "rank": 76
        },
        "2601.16086v1": {
          "score": 0.010101010101010102,
          "rank": 77
        },
        "2601.15624v1": {
          "score": 0.009900990099009901,
          "rank": 78
        },
        "2601.15814v1": {
          "score": 0.00980392156862745,
          "rank": 79
        },
        "2601.16089v1": {
          "score": 0.00980392156862745,
          "rank": 80
        },
        "2601.15662v1": {
          "score": 0.009708737864077669,
          "rank": 81
        },
        "2601.16098v1": {
          "score": 0.009615384615384616,
          "rank": 82
        },
        "2601.15120v2": {
          "score": 0.009615384615384616,
          "rank": 83
        },
        "2601.15889v1": {
          "score": 0.009523809523809525,
          "rank": 84
        },
        "2601.15544v1": {
          "score": 0.009523809523809525,
          "rank": 85
        },
        "2601.15996v1": {
          "score": 0.009433962264150943,
          "rank": 86
        },
        "2601.15709v1": {
          "score": 0.009433962264150943,
          "rank": 87
        },
        "2601.15465v1": {
          "score": 0.009345794392523364,
          "rank": 88
        },
        "2601.15989v1": {
          "score": 0.009259259259259259,
          "rank": 89
        },
        "2601.15182v1": {
          "score": 0.009259259259259259,
          "rank": 90
        },
        "2601.15943v1": {
          "score": 0.009174311926605505,
          "rank": 91
        },
        "2601.15457v1": {
          "score": 0.009174311926605505,
          "rank": 92
        },
        "2601.16022v1": {
          "score": 0.00909090909090909,
          "rank": 93
        },
        "2601.15191v1": {
          "score": 0.009009009009009009,
          "rank": 94
        },
        "2601.15950v1": {
          "score": 0.009009009009009009,
          "rank": 95
        },
        "2601.15761v1": {
          "score": 0.008928571428571428,
          "rank": 96
        },
        "2601.16112v1": {
          "score": 0.008849557522123894,
          "rank": 97
        },
        "2601.15571v1": {
          "score": 0.008849557522123894,
          "rank": 98
        },
        "2601.15130v1": {
          "score": 0.008771929824561403,
          "rank": 99
        },
        "2601.15970v1": {
          "score": 0.008620689655172414,
          "rank": 100
        },
        "2601.15226v1": {
          "score": 0.008547008547008548,
          "rank": 101
        },
        "2601.15158v1": {
          "score": 0.008547008547008548,
          "rank": 102
        },
        "2601.15188v1": {
          "score": 0.00847457627118644,
          "rank": 103
        },
        "2601.16003v1": {
          "score": 0.008403361344537815,
          "rank": 104
        },
        "2601.15160v1": {
          "score": 0.008403361344537815,
          "rank": 105
        },
        "2601.15518v1": {
          "score": 0.008333333333333333,
          "rank": 106
        },
        "2601.15864v1": {
          "score": 0.008264462809917356,
          "rank": 107
        },
        "2601.15599v1": {
          "score": 0.008264462809917356,
          "rank": 108
        },
        "2601.15154v1": {
          "score": 0.00819672131147541,
          "rank": 109
        },
        "2601.15892v1": {
          "score": 0.00819672131147541,
          "rank": 110
        },
        "2601.16074v1": {
          "score": 0.008130081300813009,
          "rank": 111
        },
        "2601.15691v1": {
          "score": 0.008064516129032258,
          "rank": 112
        },
        "2601.15915v1": {
          "score": 0.008064516129032258,
          "rank": 113
        },
        "2601.15147v1": {
          "score": 0.008,
          "rank": 114
        },
        "2601.15984v1": {
          "score": 0.008,
          "rank": 115
        },
        "2601.15165v1": {
          "score": 0.007874015748031496,
          "rank": 116
        },
        "2601.15728v1": {
          "score": 0.0078125,
          "rank": 117
        },
        "2601.16159v1": {
          "score": 0.007751937984496124,
          "rank": 118
        },
        "2601.15148v1": {
          "score": 0.007751937984496124,
          "rank": 119
        },
        "2601.15563v1": {
          "score": 0.007692307692307693,
          "rank": 120
        },
        "2601.15942v1": {
          "score": 0.007692307692307693,
          "rank": 121
        },
        "2601.15151v1": {
          "score": 0.007633587786259542,
          "rank": 122
        },
        "2601.15136v1": {
          "score": 0.007633587786259542,
          "rank": 123
        },
        "2601.15282v1": {
          "score": 0.007575757575757576,
          "rank": 124
        },
        "2601.15729v1": {
          "score": 0.007575757575757576,
          "rank": 125
        },
        "2601.15776v1": {
          "score": 0.007518796992481203,
          "rank": 126
        },
        "2601.15247v1": {
          "score": 0.007518796992481203,
          "rank": 127
        },
        "2601.15619v1": {
          "score": 0.007462686567164179,
          "rank": 128
        },
        "2601.15398v1": {
          "score": 0.007462686567164179,
          "rank": 129
        },
        "2601.15440v1": {
          "score": 0.007407407407407408,
          "rank": 130
        },
        "2601.15532v1": {
          "score": 0.007352941176470588,
          "rank": 131
        },
        "2601.15758v1": {
          "score": 0.007352941176470588,
          "rank": 132
        },
        "2601.15757v1": {
          "score": 0.0072992700729927005,
          "rank": 133
        },
        "2601.15258v1": {
          "score": 0.0072992700729927005,
          "rank": 134
        },
        "2601.15965v1": {
          "score": 0.007246376811594203,
          "rank": 135
        },
        "2601.15208v1": {
          "score": 0.007246376811594203,
          "rank": 136
        },
        "2601.15195v1": {
          "score": 0.007194244604316547,
          "rank": 137
        },
        "2601.15742v1": {
          "score": 0.007142857142857143,
          "rank": 138
        },
        "2601.15485v1": {
          "score": 0.0070921985815602835,
          "rank": 139
        },
        "2601.15830v1": {
          "score": 0.007042253521126761,
          "rank": 140
        },
        "2601.16028v1": {
          "score": 0.007042253521126761,
          "rank": 141
        },
        "2601.15653v1": {
          "score": 0.006993006993006993,
          "rank": 142
        },
        "2601.15578v1": {
          "score": 0.006993006993006993,
          "rank": 143
        },
        "2601.15161v1": {
          "score": 0.006944444444444444,
          "rank": 144
        },
        "2601.15609v1": {
          "score": 0.006944444444444444,
          "rank": 145
        },
        "2601.15458v1": {
          "score": 0.006896551724137931,
          "rank": 146
        },
        "2601.15686v1": {
          "score": 0.006896551724137931,
          "rank": 147
        },
        "2601.15944v1": {
          "score": 0.00684931506849315,
          "rank": 148
        },
        "2601.16097v1": {
          "score": 0.006802721088435374,
          "rank": 149
        },
        "2601.15641v1": {
          "score": 0.006756756756756757,
          "rank": 150
        },
        "2601.15196v1": {
          "score": 0.006711409395973154,
          "rank": 151
        },
        "2601.15819v1": {
          "score": 0.006666666666666667,
          "rank": 152
        },
        "2601.15500v1": {
          "score": 0.006666666666666667,
          "rank": 153
        },
        "2601.15134v1": {
          "score": 0.006622516556291391,
          "rank": 154
        },
        "2601.16033v1": {
          "score": 0.006578947368421052,
          "rank": 155
        },
        "2601.15615v1": {
          "score": 0.006535947712418301,
          "rank": 156
        },
        "2601.15714v1": {
          "score": 0.006535947712418301,
          "rank": 157
        },
        "2601.15958v1": {
          "score": 0.006493506493506494,
          "rank": 158
        },
        "2601.15658v1": {
          "score": 0.006493506493506494,
          "rank": 159
        },
        "2601.15252v1": {
          "score": 0.0064516129032258064,
          "rank": 160
        },
        "2601.15394v1": {
          "score": 0.0064516129032258064,
          "rank": 161
        },
        "2601.16000v1": {
          "score": 0.00641025641025641,
          "rank": 162
        },
        "2601.15810v1": {
          "score": 0.006369426751592357,
          "rank": 163
        },
        "2601.15807v1": {
          "score": 0.006369426751592357,
          "rank": 164
        },
        "2601.15098v1": {
          "score": 0.006329113924050633,
          "rank": 165
        },
        "2601.16100v1": {
          "score": 0.006289308176100629,
          "rank": 166
        },
        "2601.15778v1": {
          "score": 0.006289308176100629,
          "rank": 167
        },
        "2601.15468v1": {
          "score": 0.00625,
          "rank": 168
        }
      }
    },
    {
      "type": "keyword",
      "tag": "EAA",
      "paper_tag": "keyword:EAA",
      "query_text": "Efficient Automatic Algorithm",
      "sim_scores": {
        "2601.15992v1": {
          "score": 0.028381642512077296,
          "rank": 1
        },
        "2601.15092v1": {
          "score": 0.027893738140417457,
          "rank": 2
        },
        "2601.15399v1": {
          "score": 0.027623285131627734,
          "rank": 3
        },
        "2601.16056v1": {
          "score": 0.026862026862026864,
          "rank": 4
        },
        "2601.15561v1": {
          "score": 0.026333907056798625,
          "rank": 5
        },
        "2601.15167v1": {
          "score": 0.026132699813337858,
          "rank": 6
        },
        "2601.15727v1": {
          "score": 0.025893752088205813,
          "rank": 7
        },
        "2601.15094v1": {
          "score": 0.02490996398559424,
          "rank": 8
        },
        "2601.15552v1": {
          "score": 0.02490996398559424,
          "rank": 9
        },
        "2601.16072v1": {
          "score": 0.024028361344537813,
          "rank": 10
        },
        "2601.16022v1": {
          "score": 0.023138297872340424,
          "rank": 11
        },
        "2601.16074v1": {
          "score": 0.022444170126809562,
          "rank": 12
        },
        "2601.16091v1": {
          "score": 0.02190827190827191,
          "rank": 13
        },
        "2601.16025v1": {
          "score": 0.021691473404869044,
          "rank": 14
        },
        "2601.15657v1": {
          "score": 0.021111111111111112,
          "rank": 15
        },
        "2601.15212v1": {
          "score": 0.02108843537414966,
          "rank": 16
        },
        "2601.16175v1": {
          "score": 0.020833333333333332,
          "rank": 17
        },
        "2601.15178v1": {
          "score": 0.019221967963386728,
          "rank": 18
        },
        "2601.15984v1": {
          "score": 0.01893939393939394,
          "rank": 19
        },
        "2601.16194v1": {
          "score": 0.018869565217391304,
          "rank": 20
        },
        "2601.15141v1": {
          "score": 0.01706603510727222,
          "rank": 21
        },
        "2601.15970v1": {
          "score": 0.01639344262295082,
          "rank": 22
        },
        "2601.15170v1": {
          "score": 0.01639344262295082,
          "rank": 23
        },
        "2601.16036v1": {
          "score": 0.015873015873015872,
          "rank": 24
        },
        "2601.15640v1": {
          "score": 0.015810523684539432,
          "rank": 25
        },
        "2601.15751v1": {
          "score": 0.015625,
          "rank": 26
        },
        "2601.16112v1": {
          "score": 0.015396323615501698,
          "rank": 27
        },
        "2601.15810v1": {
          "score": 0.015384615384615385,
          "rank": 28
        },
        "2601.15249v2": {
          "score": 0.015384615384615385,
          "rank": 29
        },
        "2601.15641v1": {
          "score": 0.015151515151515152,
          "rank": 30
        },
        "2601.16003v1": {
          "score": 0.014925373134328358,
          "rank": 31
        },
        "2601.16139v1": {
          "score": 0.014904698581560284,
          "rank": 32
        },
        "2601.15153v1": {
          "score": 0.014492753623188406,
          "rank": 33
        },
        "2601.15804v1": {
          "score": 0.01439363005308289,
          "rank": 34
        },
        "2601.15571v1": {
          "score": 0.014084507042253521,
          "rank": 35
        },
        "2601.15532v1": {
          "score": 0.013888888888888888,
          "rank": 36
        },
        "2601.15079v1": {
          "score": 0.013883587786259543,
          "rank": 37
        },
        "2601.15943v1": {
          "score": 0.0136986301369863,
          "rank": 38
        },
        "2601.15776v1": {
          "score": 0.013513513513513514,
          "rank": 39
        },
        "2601.15690v1": {
          "score": 0.013513513513513514,
          "rank": 40
        },
        "2601.16122v1": {
          "score": 0.013333333333333334,
          "rank": 41
        },
        "2601.15717v1": {
          "score": 0.013333333333333334,
          "rank": 42
        },
        "2601.15684v1": {
          "score": 0.013157894736842105,
          "rank": 43
        },
        "2601.15589v1": {
          "score": 0.013157894736842105,
          "rank": 44
        },
        "2601.15124v1": {
          "score": 0.013074129459517197,
          "rank": 45
        },
        "2601.16158v1": {
          "score": 0.012987012987012988,
          "rank": 46
        },
        "2601.16083v1": {
          "score": 0.012987012987012988,
          "rank": 47
        },
        "2601.15191v1": {
          "score": 0.01282051282051282,
          "rank": 48
        },
        "2601.15599v1": {
          "score": 0.01282051282051282,
          "rank": 49
        },
        "2601.15578v1": {
          "score": 0.0127859477124183,
          "rank": 50
        },
        "2601.15269v1": {
          "score": 0.012658227848101266,
          "rank": 51
        },
        "2601.16142v1": {
          "score": 0.012658227848101266,
          "rank": 52
        },
        "2601.15182v1": {
          "score": 0.0125,
          "rank": 53
        },
        "2601.15620v1": {
          "score": 0.012345679012345678,
          "rank": 54
        },
        "2601.15876v1": {
          "score": 0.012195121951219513,
          "rank": 55
        },
        "2601.16144v1": {
          "score": 0.011904761904761904,
          "rank": 56
        },
        "2601.16012v1": {
          "score": 0.011764705882352941,
          "rank": 57
        },
        "2601.15861v1": {
          "score": 0.011627906976744186,
          "rank": 58
        },
        "2601.15950v1": {
          "score": 0.011627906976744186,
          "rank": 59
        },
        "2601.15849v1": {
          "score": 0.011494252873563218,
          "rank": 60
        },
        "2601.16206v1": {
          "score": 0.011363636363636364,
          "rank": 61
        },
        "2601.16008v1": {
          "score": 0.011235955056179775,
          "rank": 62
        },
        "2601.16089v1": {
          "score": 0.011235955056179775,
          "rank": 63
        },
        "2601.15455v1": {
          "score": 0.011111111111111112,
          "rank": 64
        },
        "2601.15160v1": {
          "score": 0.01098901098901099,
          "rank": 65
        },
        "2601.15860v1": {
          "score": 0.010869565217391304,
          "rank": 66
        },
        "2601.15581v1": {
          "score": 0.010752688172043012,
          "rank": 67
        },
        "2601.16086v1": {
          "score": 0.010752688172043012,
          "rank": 68
        },
        "2601.15471v1": {
          "score": 0.010638297872340425,
          "rank": 69
        },
        "2601.15738v1": {
          "score": 0.010526315789473684,
          "rank": 70
        },
        "2601.15952v1": {
          "score": 0.010416666666666666,
          "rank": 71
        },
        "2601.16171v1": {
          "score": 0.010416666666666666,
          "rank": 72
        },
        "2601.15130v1": {
          "score": 0.010309278350515464,
          "rank": 73
        },
        "2601.15790v1": {
          "score": 0.010101010101010102,
          "rank": 74
        },
        "2601.15442v1": {
          "score": 0.010101010101010102,
          "rank": 75
        },
        "2601.15709v1": {
          "score": 0.01,
          "rank": 76
        },
        "2601.15865v1": {
          "score": 0.009900990099009901,
          "rank": 77
        },
        "2601.15722v1": {
          "score": 0.009900990099009901,
          "rank": 78
        },
        "2601.15401v1": {
          "score": 0.00980392156862745,
          "rank": 79
        },
        "2601.15370v1": {
          "score": 0.00980392156862745,
          "rank": 80
        },
        "2601.15889v1": {
          "score": 0.009708737864077669,
          "rank": 81
        },
        "2601.15077v1": {
          "score": 0.009708737864077669,
          "rank": 82
        },
        "2601.15227v1": {
          "score": 0.009615384615384616,
          "rank": 83
        },
        "2601.15580v1": {
          "score": 0.009615384615384616,
          "rank": 84
        },
        "2601.16138v1": {
          "score": 0.009523809523809525,
          "rank": 85
        },
        "2601.15423v1": {
          "score": 0.009523809523809525,
          "rank": 86
        },
        "2601.15989v1": {
          "score": 0.009433962264150943,
          "rank": 87
        },
        "2601.16156v1": {
          "score": 0.009433962264150943,
          "rank": 88
        },
        "2601.16028v1": {
          "score": 0.009345794392523364,
          "rank": 89
        },
        "2601.15483v1": {
          "score": 0.009259259259259259,
          "rank": 90
        },
        "2601.15808v1": {
          "score": 0.009259259259259259,
          "rank": 91
        },
        "2601.15210v2": {
          "score": 0.009174311926605505,
          "rank": 92
        },
        "2601.15100v1": {
          "score": 0.009174311926605505,
          "rank": 93
        },
        "2601.15814v1": {
          "score": 0.00909090909090909,
          "rank": 94
        },
        "2601.15728v1": {
          "score": 0.00909090909090909,
          "rank": 95
        },
        "2601.15838v1": {
          "score": 0.009009009009009009,
          "rank": 96
        },
        "2601.15258v1": {
          "score": 0.009009009009009009,
          "rank": 97
        },
        "2601.15148v1": {
          "score": 0.008928571428571428,
          "rank": 98
        },
        "2601.16107v1": {
          "score": 0.008849557522123894,
          "rank": 99
        },
        "2601.15158v1": {
          "score": 0.008849557522123894,
          "rank": 100
        },
        "2601.15393v1": {
          "score": 0.008771929824561403,
          "rank": 101
        },
        "2601.15487v1": {
          "score": 0.008771929824561403,
          "rank": 102
        },
        "2601.15127v1": {
          "score": 0.008695652173913044,
          "rank": 103
        },
        "2601.15653v1": {
          "score": 0.008620689655172414,
          "rank": 104
        },
        "2601.15551v1": {
          "score": 0.008620689655172414,
          "rank": 105
        },
        "2601.15493v1": {
          "score": 0.008547008547008548,
          "rank": 106
        },
        "2601.16030v1": {
          "score": 0.00847457627118644,
          "rank": 107
        },
        "2601.15871v1": {
          "score": 0.00847457627118644,
          "rank": 108
        },
        "2601.15235v1": {
          "score": 0.008403361344537815,
          "rank": 109
        },
        "2601.15470v1": {
          "score": 0.008333333333333333,
          "rank": 110
        },
        "2601.15703v1": {
          "score": 0.008333333333333333,
          "rank": 111
        },
        "2601.15944v1": {
          "score": 0.008264462809917356,
          "rank": 112
        },
        "2601.15697v1": {
          "score": 0.008264462809917356,
          "rank": 113
        },
        "2601.15597v1": {
          "score": 0.00819672131147541,
          "rank": 114
        },
        "2601.15473v1": {
          "score": 0.00819672131147541,
          "rank": 115
        },
        "2601.15968v1": {
          "score": 0.008130081300813009,
          "rank": 116
        },
        "2601.15434v1": {
          "score": 0.008130081300813009,
          "rank": 117
        },
        "2601.15563v1": {
          "score": 0.008064516129032258,
          "rank": 118
        },
        "2601.16212v1": {
          "score": 0.008,
          "rank": 119
        },
        "2601.15904v1": {
          "score": 0.007936507936507936,
          "rank": 120
        },
        "2601.16195v1": {
          "score": 0.007874015748031496,
          "rank": 121
        },
        "2601.15778v1": {
          "score": 0.0078125,
          "rank": 122
        },
        "2601.15951v1": {
          "score": 0.007751937984496124,
          "rank": 123
        },
        "2601.15761v1": {
          "score": 0.007751937984496124,
          "rank": 124
        },
        "2601.15715v1": {
          "score": 0.007692307692307693,
          "rank": 125
        },
        "2601.15609v1": {
          "score": 0.007692307692307693,
          "rank": 126
        },
        "2601.15177v1": {
          "score": 0.007633587786259542,
          "rank": 127
        },
        "2601.15769v1": {
          "score": 0.007575757575757576,
          "rank": 128
        },
        "2601.15457v1": {
          "score": 0.007518796992481203,
          "rank": 129
        },
        "2601.15603v1": {
          "score": 0.007462686567164179,
          "rank": 130
        },
        "2601.15188v1": {
          "score": 0.007462686567164179,
          "rank": 131
        },
        "2601.16006v1": {
          "score": 0.007407407407407408,
          "rank": 132
        },
        "2601.15758v1": {
          "score": 0.007407407407407408,
          "rank": 133
        },
        "2601.16043v1": {
          "score": 0.007352941176470588,
          "rank": 134
        },
        "2601.15678v1": {
          "score": 0.007352941176470588,
          "rank": 135
        },
        "2601.15528v1": {
          "score": 0.0072992700729927005,
          "rank": 136
        },
        "2601.15892v1": {
          "score": 0.0072992700729927005,
          "rank": 137
        },
        "2601.16180v1": {
          "score": 0.007246376811594203,
          "rank": 138
        },
        "2601.15241v1": {
          "score": 0.007246376811594203,
          "rank": 139
        },
        "2601.16117v1": {
          "score": 0.007194244604316547,
          "rank": 140
        },
        "2601.15165v1": {
          "score": 0.007194244604316547,
          "rank": 141
        },
        "2601.15687v1": {
          "score": 0.007142857142857143,
          "rank": 142
        },
        "2601.15853v1": {
          "score": 0.007142857142857143,
          "rank": 143
        },
        "2601.15481v1": {
          "score": 0.0070921985815602835,
          "rank": 144
        },
        "2601.15378v1": {
          "score": 0.007042253521126761,
          "rank": 145
        },
        "2601.15531v1": {
          "score": 0.007042253521126761,
          "rank": 146
        },
        "2601.16033v1": {
          "score": 0.006993006993006993,
          "rank": 147
        },
        "2601.15417v1": {
          "score": 0.006993006993006993,
          "rank": 148
        },
        "2601.15918v1": {
          "score": 0.006944444444444444,
          "rank": 149
        },
        "2601.15247v1": {
          "score": 0.006944444444444444,
          "rank": 150
        },
        "2601.16076v1": {
          "score": 0.006896551724137931,
          "rank": 151
        },
        "2601.15394v1": {
          "score": 0.006896551724137931,
          "rank": 152
        },
        "2601.15915v1": {
          "score": 0.00684931506849315,
          "rank": 153
        },
        "2601.15168v1": {
          "score": 0.006802721088435374,
          "rank": 154
        },
        "2601.15686v1": {
          "score": 0.006711409395973154,
          "rank": 155
        },
        "2601.15953v1": {
          "score": 0.006711409395973154,
          "rank": 156
        },
        "2601.15539v1": {
          "score": 0.006666666666666667,
          "rank": 157
        },
        "2601.15630v1": {
          "score": 0.006666666666666667,
          "rank": 158
        },
        "2601.15120v2": {
          "score": 0.006622516556291391,
          "rank": 159
        },
        "2601.16079v1": {
          "score": 0.006578947368421052,
          "rank": 160
        },
        "2601.15500v1": {
          "score": 0.006578947368421052,
          "rank": 161
        },
        "2601.16174v1": {
          "score": 0.006535947712418301,
          "rank": 162
        },
        "2601.16055v1": {
          "score": 0.006493506493506494,
          "rank": 163
        },
        "2601.15390v1": {
          "score": 0.006493506493506494,
          "rank": 164
        },
        "2601.15149v1": {
          "score": 0.0064516129032258064,
          "rank": 165
        },
        "2601.15958v1": {
          "score": 0.00641025641025641,
          "rank": 166
        },
        "2601.15252v1": {
          "score": 0.00641025641025641,
          "rank": 167
        },
        "2601.15468v1": {
          "score": 0.006369426751592357,
          "rank": 168
        },
        "2601.15636v1": {
          "score": 0.006369426751592357,
          "rank": 169
        },
        "2601.15688v1": {
          "score": 0.006329113924050633,
          "rank": 170
        },
        "2601.15132v1": {
          "score": 0.006289308176100629,
          "rank": 171
        },
        "2601.15547v1": {
          "score": 0.006289308176100629,
          "rank": 172
        }
      }
    },
    {
      "type": "keyword",
      "tag": "LNS",
      "paper_tag": "keyword:LNS",
      "query_text": "large neighborhood search",
      "sim_scores": {
        "2601.16194v1": {
          "score": 0.03278688524590164,
          "rank": 1
        },
        "2601.16156v1": {
          "score": 0.03200204813108039,
          "rank": 2
        },
        "2601.16086v1": {
          "score": 0.030309988518943745,
          "rank": 3
        },
        "2601.15131v1": {
          "score": 0.027809742999616416,
          "rank": 4
        },
        "2601.16175v1": {
          "score": 0.025384615384615387,
          "rank": 5
        },
        "2601.15561v1": {
          "score": 0.02523465148484382,
          "rank": 6
        },
        "2601.16056v1": {
          "score": 0.025155279503105588,
          "rank": 7
        },
        "2601.15552v1": {
          "score": 0.02487789987789988,
          "rank": 8
        },
        "2601.15992v1": {
          "score": 0.024393743722198307,
          "rank": 9
        },
        "2601.15915v1": {
          "score": 0.023537414965986395,
          "rank": 10
        },
        "2601.15944v1": {
          "score": 0.023122159850307404,
          "rank": 11
        },
        "2601.15127v1": {
          "score": 0.022717198581560284,
          "rank": 12
        },
        "2601.15077v1": {
          "score": 0.022431077694235586,
          "rank": 13
        },
        "2601.15678v1": {
          "score": 0.022246272246272247,
          "rank": 14
        },
        "2601.15860v1": {
          "score": 0.01911764705882353,
          "rank": 15
        },
        "2601.16187v1": {
          "score": 0.01894940948351842,
          "rank": 16
        },
        "2601.15861v1": {
          "score": 0.01833416293346607,
          "rank": 17
        },
        "2601.15471v1": {
          "score": 0.017604617604617605,
          "rank": 18
        },
        "2601.15709v1": {
          "score": 0.017105263157894735,
          "rank": 19
        },
        "2601.15684v1": {
          "score": 0.01702158481819499,
          "rank": 20
        },
        "2601.15170v1": {
          "score": 0.016559278350515464,
          "rank": 21
        },
        "2601.15717v1": {
          "score": 0.016129032258064516,
          "rank": 22
        },
        "2601.15482v1": {
          "score": 0.015873015873015872,
          "rank": 23
        },
        "2601.16091v1": {
          "score": 0.015625,
          "rank": 24
        },
        "2601.15094v1": {
          "score": 0.0152073732718894,
          "rank": 25
        },
        "2601.15092v1": {
          "score": 0.015151515151515152,
          "rank": 26
        },
        "2601.15619v1": {
          "score": 0.014705882352941176,
          "rank": 27
        },
        "2601.15399v1": {
          "score": 0.014705882352941176,
          "rank": 28
        },
        "2601.15931v1": {
          "score": 0.014492753623188406,
          "rank": 29
        },
        "2601.15245v1": {
          "score": 0.014285714285714285,
          "rank": 30
        },
        "2601.16096v1": {
          "score": 0.014084507042253521,
          "rank": 31
        },
        "2601.15636v1": {
          "score": 0.014084507042253521,
          "rank": 32
        },
        "2601.15236v1": {
          "score": 0.014027370478983382,
          "rank": 33
        },
        "2601.15657v1": {
          "score": 0.013962701710310174,
          "rank": 34
        },
        "2601.15146v1": {
          "score": 0.013888888888888888,
          "rank": 35
        },
        "2601.16146v1": {
          "score": 0.0136986301369863,
          "rank": 36
        },
        "2601.15258v1": {
          "score": 0.0136986301369863,
          "rank": 37
        },
        "2601.15727v1": {
          "score": 0.013668696824585057,
          "rank": 38
        },
        "2601.15458v1": {
          "score": 0.013513513513513514,
          "rank": 39
        },
        "2601.15904v1": {
          "score": 0.013513513513513514,
          "rank": 40
        },
        "2601.15531v1": {
          "score": 0.013333333333333334,
          "rank": 41
        },
        "2601.15104v1": {
          "score": 0.013157894736842105,
          "rank": 42
        },
        "2601.15148v1": {
          "score": 0.013157894736842105,
          "rank": 43
        },
        "2601.15821v1": {
          "score": 0.012987012987012988,
          "rank": 44
        },
        "2601.15614v1": {
          "score": 0.01282051282051282,
          "rank": 45
        },
        "2601.15738v1": {
          "score": 0.01282051282051282,
          "rank": 46
        },
        "2601.15612v1": {
          "score": 0.012658227848101266,
          "rank": 47
        },
        "2601.15854v1": {
          "score": 0.0125,
          "rank": 48
        },
        "2601.16083v1": {
          "score": 0.0125,
          "rank": 49
        },
        "2601.15998v1": {
          "score": 0.012345679012345678,
          "rank": 50
        },
        "2601.15864v1": {
          "score": 0.012345679012345678,
          "rank": 51
        },
        "2601.15611v1": {
          "score": 0.012195121951219513,
          "rank": 52
        },
        "2601.16142v1": {
          "score": 0.012195121951219513,
          "rank": 53
        },
        "2601.15486v1": {
          "score": 0.012048192771084338,
          "rank": 54
        },
        "2601.16089v1": {
          "score": 0.012048192771084338,
          "rank": 55
        },
        "2601.15849v1": {
          "score": 0.011904761904761904,
          "rank": 56
        },
        "2601.15422v1": {
          "score": 0.011764705882352941,
          "rank": 57
        },
        "2601.15658v1": {
          "score": 0.011627906976744186,
          "rank": 58
        },
        "2601.15633v1": {
          "score": 0.011494252873563218,
          "rank": 59
        },
        "2601.15505v1": {
          "score": 0.011363636363636364,
          "rank": 60
        },
        "2601.16028v1": {
          "score": 0.011363636363636364,
          "rank": 61
        },
        "2601.15724v1": {
          "score": 0.011235955056179775,
          "rank": 62
        },
        "2601.15178v1": {
          "score": 0.011235955056179775,
          "rank": 63
        },
        "2601.16025v1": {
          "score": 0.011111111111111112,
          "rank": 64
        },
        "2601.15589v1": {
          "score": 0.01098901098901099,
          "rank": 65
        },
        "2601.15853v1": {
          "score": 0.010869565217391304,
          "rank": 66
        },
        "2601.15167v1": {
          "score": 0.010752688172043012,
          "rank": 67
        },
        "2601.15868v1": {
          "score": 0.010638297872340425,
          "rank": 68
        },
        "2601.15487v1": {
          "score": 0.010638297872340425,
          "rank": 69
        },
        "2601.15583v1": {
          "score": 0.010526315789473684,
          "rank": 70
        },
        "2601.15871v1": {
          "score": 0.010416666666666666,
          "rank": 71
        },
        "2601.15950v1": {
          "score": 0.010416666666666666,
          "rank": 72
        },
        "2601.15754v1": {
          "score": 0.010101010101010102,
          "rank": 73
        },
        "2601.15500v1": {
          "score": 0.010101010101010102,
          "rank": 74
        },
        "2601.15210v2": {
          "score": 0.01,
          "rank": 75
        },
        "2601.15518v1": {
          "score": 0.009900990099009901,
          "rank": 76
        },
        "2601.15260v1": {
          "score": 0.00980392156862745,
          "rank": 77
        },
        "2601.15434v1": {
          "score": 0.00980392156862745,
          "rank": 78
        },
        "2601.15938v1": {
          "score": 0.009708737864077669,
          "rank": 79
        },
        "2601.15241v1": {
          "score": 0.009708737864077669,
          "rank": 80
        },
        "2601.16032v1": {
          "score": 0.009615384615384616,
          "rank": 81
        },
        "2601.15124v1": {
          "score": 0.009615384615384616,
          "rank": 82
        },
        "2601.16029v1": {
          "score": 0.009523809523809525,
          "rank": 83
        },
        "2601.16063v1": {
          "score": 0.009523809523809525,
          "rank": 84
        },
        "2601.15816v1": {
          "score": 0.009433962264150943,
          "rank": 85
        },
        "2601.15165v1": {
          "score": 0.009433962264150943,
          "rank": 86
        },
        "2601.15387v1": {
          "score": 0.009345794392523364,
          "rank": 87
        },
        "2601.15580v1": {
          "score": 0.009345794392523364,
          "rank": 88
        },
        "2601.15639v1": {
          "score": 0.009259259259259259,
          "rank": 89
        },
        "2601.15437v1": {
          "score": 0.009174311926605505,
          "rank": 90
        },
        "2601.15673v1": {
          "score": 0.009174311926605505,
          "rank": 91
        },
        "2601.15157v1": {
          "score": 0.00909090909090909,
          "rank": 92
        },
        "2601.15723v1": {
          "score": 0.00909090909090909,
          "rank": 93
        },
        "2601.15635v1": {
          "score": 0.009009009009009009,
          "rank": 94
        },
        "2601.15928v1": {
          "score": 0.009009009009009009,
          "rank": 95
        },
        "2601.15711v1": {
          "score": 0.008928571428571428,
          "rank": 96
        },
        "2601.15478v1": {
          "score": 0.008928571428571428,
          "rank": 97
        },
        "2601.15188v1": {
          "score": 0.008849557522123894,
          "rank": 98
        },
        "2601.15252v1": {
          "score": 0.008849557522123894,
          "rank": 99
        },
        "2601.16027v1": {
          "score": 0.008771929824561403,
          "rank": 100
        },
        "2601.15371v1": {
          "score": 0.008695652173913044,
          "rank": 101
        },
        "2601.15627v1": {
          "score": 0.008695652173913044,
          "rank": 102
        },
        "2601.15138v1": {
          "score": 0.008620689655172414,
          "rank": 103
        },
        "2601.15571v1": {
          "score": 0.008620689655172414,
          "rank": 104
        },
        "2601.15790v1": {
          "score": 0.008547008547008548,
          "rank": 105
        },
        "2601.15440v1": {
          "score": 0.00847457627118644,
          "rank": 106
        },
        "2601.16208v1": {
          "score": 0.008403361344537815,
          "rank": 107
        },
        "2601.15690v1": {
          "score": 0.008403361344537815,
          "rank": 108
        },
        "2601.15742v1": {
          "score": 0.008333333333333333,
          "rank": 109
        },
        "2601.16195v1": {
          "score": 0.008264462809917356,
          "rank": 110
        },
        "2601.16022v1": {
          "score": 0.008264462809917356,
          "rank": 111
        },
        "2601.15779v1": {
          "score": 0.00819672131147541,
          "rank": 112
        },
        "2601.16038v1": {
          "score": 0.008130081300813009,
          "rank": 113
        },
        "2601.15488v1": {
          "score": 0.008064516129032258,
          "rank": 114
        },
        "2601.15829v1": {
          "score": 0.008,
          "rank": 115
        },
        "2601.15218v1": {
          "score": 0.008,
          "rank": 116
        },
        "2601.15975v1": {
          "score": 0.007936507936507936,
          "rank": 117
        },
        "2601.16072v1": {
          "score": 0.007936507936507936,
          "rank": 118
        },
        "2601.15912v1": {
          "score": 0.007874015748031496,
          "rank": 119
        },
        "2601.16144v1": {
          "score": 0.007874015748031496,
          "rank": 120
        },
        "2601.15645v1": {
          "score": 0.0078125,
          "rank": 121
        },
        "2601.15249v2": {
          "score": 0.0078125,
          "rank": 122
        },
        "2601.16110v1": {
          "score": 0.007751937984496124,
          "rank": 123
        },
        "2601.15984v1": {
          "score": 0.007751937984496124,
          "rank": 124
        },
        "2601.16111v1": {
          "score": 0.007692307692307693,
          "rank": 125
        },
        "2601.15640v1": {
          "score": 0.007692307692307693,
          "rank": 126
        },
        "2601.15876v1": {
          "score": 0.007633587786259542,
          "rank": 127
        },
        "2601.15758v1": {
          "score": 0.007575757575757576,
          "rank": 128
        },
        "2601.15098v1": {
          "score": 0.007518796992481203,
          "rank": 129
        },
        "2601.15398v1": {
          "score": 0.007518796992481203,
          "rank": 130
        },
        "2601.15114v1": {
          "score": 0.007462686567164179,
          "rank": 131
        },
        "2601.16171v1": {
          "score": 0.007462686567164179,
          "rank": 132
        },
        "2601.15485v1": {
          "score": 0.007407407407407408,
          "rank": 133
        },
        "2601.15714v1": {
          "score": 0.007407407407407408,
          "rank": 134
        },
        "2601.15423v1": {
          "score": 0.007352941176470588,
          "rank": 135
        },
        "2601.15722v1": {
          "score": 0.0072992700729927005,
          "rank": 136
        },
        "2601.16199v1": {
          "score": 0.007246376811594203,
          "rank": 137
        },
        "2601.15457v1": {
          "score": 0.007246376811594203,
          "rank": 138
        },
        "2601.16045v1": {
          "score": 0.007194244604316547,
          "rank": 139
        },
        "2601.16158v1": {
          "score": 0.007194244604316547,
          "rank": 140
        },
        "2601.15120v2": {
          "score": 0.007142857142857143,
          "rank": 141
        },
        "2601.16212v1": {
          "score": 0.0070921985815602835,
          "rank": 142
        },
        "2601.15141v1": {
          "score": 0.007042253521126761,
          "rank": 143
        },
        "2601.15751v1": {
          "score": 0.007042253521126761,
          "rank": 144
        },
        "2601.16041v1": {
          "score": 0.006993006993006993,
          "rank": 145
        },
        "2601.15411v1": {
          "score": 0.006993006993006993,
          "rank": 146
        },
        "2601.15403v1": {
          "score": 0.006944444444444444,
          "rank": 147
        },
        "2601.15593v1": {
          "score": 0.006944444444444444,
          "rank": 148
        },
        "2601.15366v1": {
          "score": 0.006896551724137931,
          "rank": 149
        },
        "2601.15726v1": {
          "score": 0.006896551724137931,
          "rank": 150
        },
        "2601.15863v1": {
          "score": 0.00684931506849315,
          "rank": 151
        },
        "2601.15663v1": {
          "score": 0.00684931506849315,
          "rank": 152
        },
        "2601.15460v1": {
          "score": 0.006802721088435374,
          "rank": 153
        },
        "2601.15671v1": {
          "score": 0.006802721088435374,
          "rank": 154
        },
        "2601.15793v1": {
          "score": 0.006756756756756757,
          "rank": 155
        },
        "2601.15999v1": {
          "score": 0.006756756756756757,
          "rank": 156
        },
        "2601.16099v1": {
          "score": 0.006711409395973154,
          "rank": 157
        },
        "2601.15601v1": {
          "score": 0.006711409395973154,
          "rank": 158
        },
        "2601.15439v1": {
          "score": 0.006666666666666667,
          "rank": 159
        },
        "2601.15470v1": {
          "score": 0.006666666666666667,
          "rank": 160
        },
        "2601.15578v1": {
          "score": 0.006622516556291391,
          "rank": 161
        },
        "2601.15620v1": {
          "score": 0.006622516556291391,
          "rank": 162
        },
        "2601.16008v1": {
          "score": 0.006578947368421052,
          "rank": 163
        },
        "2601.15153v1": {
          "score": 0.006578947368421052,
          "rank": 164
        },
        "2601.15879v1": {
          "score": 0.006535947712418301,
          "rank": 165
        },
        "2601.15126v1": {
          "score": 0.006535947712418301,
          "rank": 166
        },
        "2601.15382v1": {
          "score": 0.006493506493506494,
          "rank": 167
        },
        "2601.15232v1": {
          "score": 0.0064516129032258064,
          "rank": 168
        },
        "2601.15585v1": {
          "score": 0.00641025641025641,
          "rank": 169
        },
        "2601.15432v1": {
          "score": 0.00641025641025641,
          "rank": 170
        },
        "2601.15194v1": {
          "score": 0.006369426751592357,
          "rank": 171
        },
        "2601.15139v1": {
          "score": 0.006329113924050633,
          "rank": 172
        },
        "2601.15091v1": {
          "score": 0.006289308176100629,
          "rank": 173
        },
        "2601.15495v1": {
          "score": 0.006289308176100629,
          "rank": 174
        },
        "2601.15390v1": {
          "score": 0.00625,
          "rank": 175
        }
      }
    }
  ]
}