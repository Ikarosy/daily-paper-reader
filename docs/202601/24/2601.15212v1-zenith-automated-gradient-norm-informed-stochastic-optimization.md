# ZENITH: Automated Gradient Norm Informed Stochastic Optimization
# ZENITH：梯度范数感知的自动化随机优化

**Authors**: Dhrubo Saha \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15212v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 7.0 \
**Evidence**: 利用训练历史的时间演化进行自动优化 \
**TLDR**: 引入 ZENITH 优化器，利用梯度范数演化自动调整学习率。

---

## Abstract
Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

## 摘要
训练深度计算机视觉模型通常需要人工监督或对学习率（LR）调度进行超参数调优。虽然现有的自适应优化器能够自动调度学习率，但它们往往面临计算和内存开销大、与正则化不兼容以及学习率选择并非最优等问题。在这项工作中，我们提出了 ZENITH（基于范数感知训练历史的零开销演化）优化器，它利用梯度范数的时间演化来调整学习率。涵盖 6 种 CNN 架构和 6 个基准测试的图像分类实验表明，与基准方法相比，ZENITH 在更短的实际运行时间（wall-clock time）内实现了更高的测试准确率。此外，在 MS COCO 数据集上使用 R-CNN 系列模型进行的物体检测、关键点检测和实例分割任务中，ZENITH 也取得了更优的平均精度均值（mAP）。最后，它与正则化的兼容性进一步提升了模型的泛化能力。

---

## 速览摘要（自动生成）

**问题**：深度学习模型训练通常需要繁琐的学习率手动调优，且现有自适应优化器存在计算开销大、与正则化不兼容等问题。
**方法**：提出 ZENITH 优化器，通过梯度范数的时间演化信息自动调整学习率，实现零额外开销的自适应优化。
**结论**：在图像分类、目标检测等多种视觉任务中，ZENITH 相比基准方法在更短时间内实现了更高的准确率和更好的泛化性能。
