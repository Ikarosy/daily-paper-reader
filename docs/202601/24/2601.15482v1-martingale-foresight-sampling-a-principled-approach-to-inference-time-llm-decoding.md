# Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding
# 鞅前瞻采样：一种规范的大语言模型推理阶段解码方法

**Authors**: Huayu Li, ZhengXiao He, Siyuan Tian, Jinghao Wen, Ao Li \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15482v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">LNS</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: LLM 解码中原则性的搜索空间剪枝和路径评估 \
**TLDR**: 提出鞅前瞻采样，为 LLM 解码提供有理论依据的最优搜索。

---

## Abstract
Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

## 摘要
大语言模型（LLM）中的标准自回归解码本质上是短视的，由于其逐标记（token-by-token）生成过程，往往无法找到全局最优的推理路径。虽然像前瞻采样（foresight sampling）这样的推理阶段策略试图通过模拟未来步骤来缓解这一问题，但它们通常依赖于启发式方法来评估路径价值和剪枝搜索空间。本文介绍了鞅前瞻采样（MFS），这是一个将 LLM 解码重新表述为识别最优随机过程问题的规范框架。通过将推理路径的质量建模为随机过程，我们利用鞅理论设计了一种具有理论基础的算法。我们的方法用概率论原理取代了启发式机制：步骤估值源自 Doob 分解定理（Doob Decomposition Theorem），用于衡量路径的可预测优势；路径选择利用可选停止理论（Optional Stopping Theory）对次优候选路径进行规范化剪枝；基于鞅收敛定理（Martingale Convergence Theorem）的自适应停止规则在路径质量被证明收敛时终止探索。在六个推理基准测试上的实验表明，MFS 在准确率上超越了现有最先进的方法，同时显著提高了计算效率。代码将发布于 https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling。

---

## 速览摘要（自动生成）

**问题**：传统的自回归解码具有短视性，难以找到全局最优推理路径，且现有的前瞻采样方法多依赖启发式规则而缺乏理论支撑。
**方法**：提出鞅前瞻采样（MFS）框架，利用概率论中的鞅理论（如Doob分解和可选停止定理）来实现路径评估、剪枝和自适应停止。
**结论**：在六个推理基准测试中，MFS 在准确率和计算效率上均显著优于现有的最先进方法。
